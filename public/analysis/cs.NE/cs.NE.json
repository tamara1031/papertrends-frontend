{
  "topics": {
    "data": {
      "0": {
        "name": "0_optimization_algorithm_algorithms_problems",
        "keywords": [
          [
            "optimization",
            0.025405335303770628
          ],
          [
            "algorithm",
            0.022958319180110914
          ],
          [
            "algorithms",
            0.02021246414256602
          ],
          [
            "problems",
            0.019684426324044064
          ],
          [
            "problem",
            0.017668988950747696
          ],
          [
            "objective",
            0.01662115925628273
          ],
          [
            "solutions",
            0.01211526084831502
          ],
          [
            "Optimization",
            0.01203659233889522
          ],
          [
            "evolutionary",
            0.011804363052575907
          ],
          [
            "performance",
            0.011426658796194901
          ]
        ],
        "count": 1728
      },
      "1": {
        "name": "1_learning_agents_agent_reinforcement",
        "keywords": [
          [
            "learning",
            0.020980429379424553
          ],
          [
            "agents",
            0.016669726015325417
          ],
          [
            "agent",
            0.014107192886755753
          ],
          [
            "reinforcement",
            0.012837833571287524
          ],
          [
            "RL",
            0.012696774793171332
          ],
          [
            "reinforcement learning",
            0.012683023853257328
          ],
          [
            "policy",
            0.01217625828801907
          ],
          [
            "environments",
            0.010974727814925011
          ],
          [
            "algorithms",
            0.01086210401961204
          ],
          [
            "control",
            0.010765550174553001
          ]
        ],
        "count": 779
      },
      "2": {
        "name": "2_SNNs_Spiking_SNN_spiking",
        "keywords": [
          [
            "SNNs",
            0.03605460050573913
          ],
          [
            "Spiking",
            0.02522480381513593
          ],
          [
            "SNN",
            0.02357613270737594
          ],
          [
            "spiking",
            0.02348100881652873
          ],
          [
            "spike",
            0.018625093817897585
          ],
          [
            "Neural",
            0.016877560172081592
          ],
          [
            "neural",
            0.016856666400069147
          ],
          [
            "networks",
            0.016809291418907295
          ],
          [
            "temporal",
            0.016593417128413192
          ],
          [
            "Networks",
            0.015608013221223373
          ]
        ],
        "count": 504
      },
      "3": {
        "name": "3_neuromorphic_hardware_energy_computing",
        "keywords": [
          [
            "neuromorphic",
            0.03206780947585828
          ],
          [
            "hardware",
            0.025929069263323577
          ],
          [
            "energy",
            0.018439799050848117
          ],
          [
            "computing",
            0.017860366942563443
          ],
          [
            "neural",
            0.015437565443339114
          ],
          [
            "Neuromorphic",
            0.014265559533889308
          ],
          [
            "SNN",
            0.013512653743923015
          ],
          [
            "devices",
            0.012297709201468334
          ],
          [
            "neuron",
            0.012282093470253152
          ],
          [
            "networks",
            0.01216196413269266
          ]
        ],
        "count": 414
      },
      "4": {
        "name": "4_learning_neural_networks_network",
        "keywords": [
          [
            "learning",
            0.025845304559317602
          ],
          [
            "neural",
            0.021737830795436647
          ],
          [
            "networks",
            0.02121997946726547
          ],
          [
            "network",
            0.017052443528043016
          ],
          [
            "brain",
            0.0166232061671359
          ],
          [
            "memory",
            0.015946435157840964
          ],
          [
            "neural networks",
            0.012526203906206209
          ],
          [
            "biological",
            0.012227411738854187
          ],
          [
            "recurrent",
            0.011823127059236544
          ],
          [
            "dynamics",
            0.011115743451748523
          ]
        ],
        "count": 397
      },
      "5": {
        "name": "5_LLM_LLMs_evolutionary_symbolic",
        "keywords": [
          [
            "LLM",
            0.0189343801189919
          ],
          [
            "LLMs",
            0.018700579674103237
          ],
          [
            "evolutionary",
            0.013825145000653394
          ],
          [
            "symbolic",
            0.013695139310476306
          ],
          [
            "search",
            0.013363858714164616
          ],
          [
            "programming",
            0.012418090029933616
          ],
          [
            "regression",
            0.01222057046284362
          ],
          [
            "genetic",
            0.012052299609294121
          ],
          [
            "selection",
            0.01167331089449087
          ],
          [
            "symbolic regression",
            0.011089389877476954
          ]
        ],
        "count": 376
      },
      "6": {
        "name": "6_activation_functions_networks_neural",
        "keywords": [
          [
            "activation",
            0.036759141553694974
          ],
          [
            "functions",
            0.03126728909990551
          ],
          [
            "networks",
            0.029397124678172674
          ],
          [
            "neural",
            0.025911638761551732
          ],
          [
            "function",
            0.023693425105091058
          ],
          [
            "activation functions",
            0.023292478553975877
          ],
          [
            "ReLU",
            0.022200036970964055
          ],
          [
            "neural networks",
            0.02098914801321658
          ],
          [
            "network",
            0.018667032734448873
          ],
          [
            "activation function",
            0.014912802468605435
          ]
        ],
        "count": 356
      },
      "7": {
        "name": "7_adversarial_attacks_data_models",
        "keywords": [
          [
            "adversarial",
            0.03200290727922101
          ],
          [
            "attacks",
            0.021006680986727127
          ],
          [
            "data",
            0.01737184921127641
          ],
          [
            "models",
            0.016586564793122757
          ],
          [
            "attack",
            0.015170550597365707
          ],
          [
            "image",
            0.014950808795720071
          ],
          [
            "model",
            0.013968275358925275
          ],
          [
            "training",
            0.013438686430396498
          ],
          [
            "generative",
            0.012143858747671068
          ],
          [
            "Adversarial",
            0.01202875752342712
          ]
        ],
        "count": 330
      },
      "8": {
        "name": "8_NAS_search_architecture_architectures",
        "keywords": [
          [
            "NAS",
            0.03395519317397671
          ],
          [
            "search",
            0.028164296424924063
          ],
          [
            "architecture",
            0.021386134334510275
          ],
          [
            "architectures",
            0.01840434801661622
          ],
          [
            "Architecture",
            0.017332007188378882
          ],
          [
            "Neural",
            0.016831001051053163
          ],
          [
            "neural",
            0.016209676897940048
          ],
          [
            "Search",
            0.015056524659189378
          ],
          [
            "network",
            0.01448096390507068
          ],
          [
            "performance",
            0.01352001563167874
          ]
        ],
        "count": 329
      },
      "9": {
        "name": "9_pruning_network_training_networks",
        "keywords": [
          [
            "pruning",
            0.030622866253380777
          ],
          [
            "network",
            0.01726674935706737
          ],
          [
            "training",
            0.017169319429993578
          ],
          [
            "networks",
            0.017000857300659224
          ],
          [
            "neural",
            0.015748113549744543
          ],
          [
            "accuracy",
            0.014992402406285072
          ],
          [
            "memory",
            0.014790253685378436
          ],
          [
            "inference",
            0.014282196267236822
          ],
          [
            "performance",
            0.013140085308814173
          ],
          [
            "hardware",
            0.013101434662703618
          ]
        ],
        "count": 218
      },
      "10": {
        "name": "10_neural_equations_PDE_differential",
        "keywords": [
          [
            "neural",
            0.021875800952092826
          ],
          [
            "equations",
            0.021292930618639586
          ],
          [
            "PDE",
            0.017468852435300886
          ],
          [
            "differential",
            0.01639646021602782
          ],
          [
            "PINNs",
            0.015802803595087546
          ],
          [
            "model",
            0.015431046584033561
          ],
          [
            "network",
            0.015010492390291176
          ],
          [
            "differential equations",
            0.014998530345375651
          ],
          [
            "equation",
            0.014274234421369459
          ],
          [
            "Physics",
            0.013725288350551049
          ]
        ],
        "count": 159
      },
      "11": {
        "name": "11_images_medical_data_disease",
        "keywords": [
          [
            "images",
            0.016429152078054766
          ],
          [
            "medical",
            0.01483964527915941
          ],
          [
            "data",
            0.014555532766937341
          ],
          [
            "disease",
            0.013841157298671261
          ],
          [
            "model",
            0.013805388616062663
          ],
          [
            "segmentation",
            0.013608385490865274
          ],
          [
            "deep",
            0.013358027120668829
          ],
          [
            "learning",
            0.01332385032509623
          ],
          [
            "accuracy",
            0.01310337687529582
          ],
          [
            "models",
            0.013035194866649679
          ]
        ],
        "count": 147
      },
      "12": {
        "name": "12_series_data_forecasting_time series",
        "keywords": [
          [
            "series",
            0.026295178170762226
          ],
          [
            "data",
            0.025626429856799308
          ],
          [
            "forecasting",
            0.02522682888621324
          ],
          [
            "time series",
            0.02346630706284734
          ],
          [
            "time",
            0.02118452029635045
          ],
          [
            "model",
            0.018861788353981487
          ],
          [
            "anomaly",
            0.016449619971993717
          ],
          [
            "detection",
            0.015315653589930913
          ],
          [
            "prediction",
            0.01529071337258022
          ],
          [
            "models",
            0.015147457769986689
          ]
        ],
        "count": 147
      },
      "13": {
        "name": "13_reservoir_RC_Reservoir_chaotic",
        "keywords": [
          [
            "reservoir",
            0.06930462856107307
          ],
          [
            "RC",
            0.03713515956177025
          ],
          [
            "Reservoir",
            0.029735898514086718
          ],
          [
            "chaotic",
            0.024493959738729847
          ],
          [
            "reservoir computing",
            0.022389889942403908
          ],
          [
            "time",
            0.022282696882230984
          ],
          [
            "systems",
            0.020953621552461773
          ],
          [
            "computing",
            0.020689606388696307
          ],
          [
            "dynamical",
            0.01972596069678729
          ],
          [
            "series",
            0.019696050925035024
          ]
        ],
        "count": 133
      },
      "14": {
        "name": "14_graph_Graph_graphs_GNNs",
        "keywords": [
          [
            "graph",
            0.08355631407376496
          ],
          [
            "Graph",
            0.03720035912000985
          ],
          [
            "graphs",
            0.02615621598696836
          ],
          [
            "GNNs",
            0.02479697777574137
          ],
          [
            "node",
            0.022819002084284588
          ],
          [
            "learning",
            0.019201440362033834
          ],
          [
            "networks",
            0.018834595440803143
          ],
          [
            "GNN",
            0.017405750167045486
          ],
          [
            "neural",
            0.01735903386101938
          ],
          [
            "graph neural",
            0.016213261533715575
          ]
        ],
        "count": 121
      },
      "15": {
        "name": "15_attention_language_Transformer_models",
        "keywords": [
          [
            "attention",
            0.028156308006384377
          ],
          [
            "language",
            0.026061333231286815
          ],
          [
            "Transformer",
            0.02525827645551536
          ],
          [
            "models",
            0.021090489066392958
          ],
          [
            "Attention",
            0.01596504705675177
          ],
          [
            "Transformers",
            0.015496050511550362
          ],
          [
            "text",
            0.014195749846986603
          ],
          [
            "word",
            0.013919427134718694
          ],
          [
            "model",
            0.013482722342148978
          ],
          [
            "tasks",
            0.012946937154869899
          ]
        ],
        "count": 109
      }
    },
    "correlations": [
      [
        1.0,
        -0.6876671107606086,
        -0.7423246520699698,
        -0.7275077931372513,
        -0.705829597455353,
        -0.7194102267491607,
        -0.6788234804653246,
        -0.7113001763586931,
        -0.6587133332335928,
        -0.7309419038638325,
        -0.7287479616309233,
        -0.6555249504484344,
        -0.6644668223511723,
        -0.7518182150336387,
        -0.7263389222348153,
        -0.7135159623648234
      ],
      [
        -0.6876671107606086,
        1.0,
        -0.7204360959156648,
        -0.7246368959335057,
        -0.5613742021095676,
        -0.7482666939410425,
        -0.7060388052616746,
        -0.7347545126792867,
        -0.714714406525079,
        -0.7205838787342215,
        -0.738549175717872,
        -0.7354726178632474,
        -0.7198661738590751,
        -0.7513020921548204,
        -0.7434645613421633,
        -0.729715081718898
      ],
      [
        -0.7423246520699698,
        -0.7204360959156648,
        1.0,
        -0.09049348021504694,
        -0.4601522364193451,
        -0.7567043805418583,
        -0.4836219896791759,
        -0.701369639160779,
        -0.655909456180326,
        -0.5524621453955302,
        -0.6203715586530627,
        -0.7259063076051396,
        -0.6909780552843318,
        -0.73906763772674,
        -0.6621128384863739,
        -0.705034411298627
      ],
      [
        -0.7275077931372513,
        -0.7246368959335057,
        -0.09049348021504694,
        1.0,
        -0.47440756163440784,
        -0.7551662506647888,
        -0.5043496072746593,
        -0.7064763489989777,
        -0.6225095376542102,
        -0.5270936106360085,
        -0.5516313643905839,
        -0.7226691331609966,
        -0.6909446594692749,
        -0.7287835809548335,
        -0.6675674972848831,
        -0.7042667604993542
      ],
      [
        -0.705829597455353,
        -0.5613742021095676,
        -0.4601522364193451,
        -0.47440756163440784,
        1.0,
        -0.7504174393850127,
        -0.16245650683546375,
        -0.6713847140549514,
        -0.5689516665142929,
        -0.3188512154242354,
        -0.4351443765212116,
        -0.6876723830374378,
        -0.6537572716205603,
        -0.6908605268458358,
        -0.6315317491434813,
        -0.6897734777036044
      ],
      [
        -0.7194102267491607,
        -0.7482666939410425,
        -0.7567043805418583,
        -0.7551662506647888,
        -0.7504174393850127,
        1.0,
        -0.7366475489176221,
        -0.74006719297851,
        -0.7315027331992965,
        -0.7491101542841991,
        -0.7433868770418186,
        -0.746747477465294,
        -0.7411435368158015,
        -0.7590318559492983,
        -0.7505991327272354,
        -0.5516102689779206
      ],
      [
        -0.6788234804653246,
        -0.7060388052616746,
        -0.4836219896791759,
        -0.5043496072746593,
        -0.16245650683546375,
        -0.7366475489176221,
        1.0,
        -0.6691026178216006,
        -0.5687660326601329,
        -0.24880721395784372,
        -0.44359443552680805,
        -0.6910656417716974,
        -0.6757020347203262,
        -0.7161979971994268,
        -0.6385527406181597,
        -0.6959926637811975
      ],
      [
        -0.7113001763586931,
        -0.7347545126792867,
        -0.701369639160779,
        -0.7064763489989777,
        -0.6713847140549514,
        -0.74006719297851,
        -0.6691026178216006,
        1.0,
        -0.7074706119581895,
        -0.6843180106951285,
        -0.700712601062673,
        -0.6935273601133684,
        -0.49996782308746246,
        -0.7485016580023214,
        -0.7348097490741241,
        -0.4653911812095605
      ],
      [
        -0.6587133332335928,
        -0.714714406525079,
        -0.655909456180326,
        -0.6225095376542102,
        -0.5689516665142929,
        -0.7315027331992965,
        -0.5687660326601329,
        -0.7074706119581895,
        1.0,
        -0.5502305324062123,
        -0.5720877830466318,
        -0.7116930668452484,
        -0.6991318487612919,
        -0.7459469009873387,
        -0.6643422904579984,
        -0.717815122755856
      ],
      [
        -0.7309419038638325,
        -0.7205838787342215,
        -0.5524621453955302,
        -0.5270936106360085,
        -0.3188512154242354,
        -0.7491101542841991,
        -0.24880721395784372,
        -0.6843180106951285,
        -0.5502305324062123,
        1.0,
        -0.357504930126992,
        -0.7236984821634048,
        -0.7038427250735801,
        -0.7373311952990869,
        -0.6184678656420101,
        -0.7165805095828922
      ],
      [
        -0.7287479616309233,
        -0.738549175717872,
        -0.6203715586530627,
        -0.5516313643905839,
        -0.4351443765212116,
        -0.7433868770418186,
        -0.44359443552680805,
        -0.700712601062673,
        -0.5720877830466318,
        -0.357504930126992,
        1.0,
        -0.7056296977517393,
        -0.6957236992538058,
        -0.7054700122472706,
        -0.6294495372765383,
        -0.7284066272434433
      ],
      [
        -0.6555249504484344,
        -0.7354726178632474,
        -0.7259063076051396,
        -0.7226691331609966,
        -0.6876723830374378,
        -0.746747477465294,
        -0.6910656417716974,
        -0.6935273601133684,
        -0.7116930668452484,
        -0.7236984821634048,
        -0.7056296977517393,
        1.0,
        -0.6755259821597802,
        -0.7500947999414057,
        -0.7435366763252746,
        -0.7144264175041539
      ],
      [
        -0.6644668223511723,
        -0.7198661738590751,
        -0.6909780552843318,
        -0.6909446594692749,
        -0.6537572716205603,
        -0.7411435368158015,
        -0.6757020347203262,
        -0.49996782308746246,
        -0.6991318487612919,
        -0.7038427250735801,
        -0.6957236992538058,
        -0.6755259821597802,
        1.0,
        -0.5993361448092731,
        -0.7241852823614262,
        -0.6721308173871339
      ],
      [
        -0.7518182150336387,
        -0.7513020921548204,
        -0.73906763772674,
        -0.7287835809548335,
        -0.6908605268458358,
        -0.7590318559492983,
        -0.7161979971994268,
        -0.7485016580023214,
        -0.7459469009873387,
        -0.7373311952990869,
        -0.7054700122472706,
        -0.7500947999414057,
        -0.5993361448092731,
        1.0,
        -0.7513518724408321,
        -0.7504653063693139
      ],
      [
        -0.7263389222348153,
        -0.7434645613421633,
        -0.6621128384863739,
        -0.6675674972848831,
        -0.6315317491434813,
        -0.7505991327272354,
        -0.6385527406181597,
        -0.7348097490741241,
        -0.6643422904579984,
        -0.6184678656420101,
        -0.6294495372765383,
        -0.7435366763252746,
        -0.7241852823614262,
        -0.7513518724408321,
        1.0,
        -0.7320240578593958
      ],
      [
        -0.7135159623648234,
        -0.729715081718898,
        -0.705034411298627,
        -0.7042667604993542,
        -0.6897734777036044,
        -0.5516102689779206,
        -0.6959926637811975,
        -0.4653911812095605,
        -0.717815122755856,
        -0.7165805095828922,
        -0.7284066272434433,
        -0.7144264175041539,
        -0.6721308173871339,
        -0.7504653063693139,
        -0.7320240578593958,
        1.0
      ]
    ],
    "series": {
      "2020-01": [
        32,
        1,
        9,
        1,
        7,
        2,
        22,
        2,
        4,
        4,
        3,
        1,
        10,
        2,
        8,
        5
      ],
      "2020-02": [
        58,
        3,
        8,
        3,
        8,
        0,
        27,
        4,
        6,
        3,
        0,
        2,
        12,
        2,
        9,
        5
      ],
      "2020-03": [
        50,
        9,
        14,
        10,
        5,
        0,
        25,
        8,
        8,
        2,
        2,
        1,
        15,
        2,
        2,
        3
      ],
      "2020-04": [
        70,
        7,
        6,
        4,
        10,
        2,
        24,
        6,
        16,
        2,
        4,
        4,
        15,
        6,
        2,
        8
      ],
      "2020-05": [
        46,
        6,
        9,
        5,
        12,
        2,
        19,
        4,
        14,
        1,
        1,
        6,
        10,
        2,
        5,
        6
      ],
      "2020-06": [
        59,
        6,
        13,
        7,
        26,
        1,
        42,
        7,
        9,
        3,
        0,
        2,
        20,
        6,
        8,
        8
      ],
      "2020-07": [
        48,
        5,
        12,
        4,
        10,
        1,
        20,
        6,
        11,
        4,
        2,
        3,
        12,
        1,
        5,
        4
      ],
      "2020-08": [
        30,
        3,
        5,
        7,
        5,
        0,
        15,
        2,
        9,
        1,
        2,
        0,
        15,
        5,
        4,
        3
      ],
      "2020-09": [
        33,
        4,
        12,
        6,
        4,
        1,
        16,
        3,
        8,
        2,
        3,
        2,
        6,
        4,
        5,
        2
      ],
      "2020-10": [
        56,
        3,
        16,
        2,
        14,
        1,
        30,
        4,
        7,
        4,
        0,
        1,
        13,
        5,
        7,
        7
      ],
      "2020-11": [
        33,
        5,
        10,
        4,
        7,
        0,
        26,
        3,
        11,
        2,
        3,
        2,
        9,
        1,
        4,
        7
      ],
      "2020-12": [
        37,
        1,
        3,
        2,
        8,
        2,
        19,
        6,
        11,
        1,
        3,
        1,
        10,
        5,
        3,
        6
      ],
      "2021-01": [
        33,
        3,
        2,
        1,
        7,
        0,
        18,
        6,
        6,
        2,
        2,
        1,
        12,
        3,
        2,
        4
      ],
      "2021-02": [
        56,
        5,
        14,
        3,
        6,
        3,
        23,
        3,
        4,
        2,
        0,
        0,
        15,
        3,
        6,
        1
      ],
      "2021-03": [
        34,
        6,
        9,
        3,
        8,
        2,
        22,
        5,
        8,
        1,
        2,
        4,
        7,
        3,
        5,
        7
      ],
      "2021-04": [
        56,
        2,
        8,
        5,
        9,
        0,
        10,
        2,
        6,
        0,
        3,
        1,
        10,
        3,
        6,
        6
      ],
      "2021-05": [
        35,
        7,
        13,
        5,
        3,
        0,
        21,
        4,
        7,
        2,
        3,
        2,
        9,
        4,
        5,
        6
      ],
      "2021-06": [
        38,
        7,
        14,
        7,
        13,
        1,
        16,
        6,
        10,
        3,
        3,
        0,
        17,
        1,
        9,
        7
      ],
      "2021-07": [
        33,
        2,
        9,
        4,
        7,
        5,
        16,
        4,
        11,
        0,
        1,
        1,
        7,
        2,
        4,
        2
      ],
      "2021-08": [
        33,
        4,
        7,
        4,
        2,
        4,
        10,
        2,
        8,
        0,
        0,
        3,
        5,
        6,
        6,
        1
      ],
      "2021-09": [
        37,
        3,
        11,
        5,
        6,
        0,
        20,
        6,
        5,
        0,
        1,
        3,
        8,
        1,
        3,
        9
      ],
      "2021-10": [
        51,
        4,
        11,
        2,
        6,
        2,
        8,
        3,
        4,
        0,
        0,
        1,
        13,
        4,
        10,
        5
      ],
      "2021-11": [
        32,
        2,
        10,
        6,
        5,
        1,
        18,
        3,
        8,
        0,
        0,
        1,
        8,
        2,
        6,
        6
      ],
      "2021-12": [
        37,
        2,
        8,
        1,
        2,
        1,
        15,
        4,
        9,
        0,
        1,
        1,
        4,
        3,
        3,
        6
      ],
      "2022-01": [
        43,
        2,
        11,
        2,
        6,
        0,
        10,
        2,
        6,
        3,
        0,
        0,
        15,
        5,
        4,
        1
      ],
      "2022-02": [
        42,
        4,
        10,
        6,
        7,
        2,
        16,
        3,
        8,
        2,
        0,
        3,
        10,
        0,
        1,
        7
      ],
      "2022-03": [
        45,
        6,
        16,
        5,
        7,
        2,
        20,
        3,
        10,
        0,
        0,
        2,
        8,
        2,
        9,
        2
      ],
      "2022-04": [
        61,
        7,
        12,
        4,
        10,
        8,
        20,
        1,
        6,
        1,
        3,
        3,
        18,
        2,
        3,
        3
      ],
      "2022-05": [
        41,
        4,
        21,
        4,
        13,
        3,
        21,
        6,
        7,
        0,
        0,
        0,
        11,
        4,
        8,
        4
      ],
      "2022-06": [
        35,
        8,
        15,
        4,
        12,
        3,
        26,
        2,
        8,
        1,
        0,
        2,
        14,
        5,
        4,
        5
      ],
      "2022-07": [
        29,
        2,
        13,
        5,
        5,
        0,
        14,
        3,
        9,
        2,
        1,
        1,
        6,
        4,
        6,
        1
      ],
      "2022-08": [
        39,
        6,
        9,
        3,
        10,
        1,
        17,
        4,
        3,
        0,
        3,
        1,
        9,
        1,
        7,
        5
      ],
      "2022-09": [
        29,
        5,
        5,
        6,
        7,
        3,
        17,
        4,
        7,
        1,
        3,
        2,
        9,
        2,
        5,
        4
      ],
      "2022-10": [
        43,
        3,
        15,
        3,
        9,
        1,
        19,
        3,
        7,
        1,
        2,
        1,
        13,
        1,
        9,
        7
      ],
      "2022-11": [
        51,
        5,
        18,
        4,
        6,
        0,
        14,
        4,
        8,
        0,
        1,
        0,
        12,
        3,
        5,
        3
      ],
      "2022-12": [
        26,
        2,
        11,
        4,
        10,
        1,
        14,
        0,
        6,
        0,
        3,
        0,
        8,
        3,
        3,
        3
      ],
      "2023-01": [
        28,
        4,
        7,
        5,
        13,
        1,
        14,
        0,
        9,
        0,
        0,
        2,
        3,
        2,
        5,
        4
      ],
      "2023-02": [
        42,
        5,
        16,
        4,
        5,
        3,
        15,
        1,
        11,
        3,
        4,
        0,
        14,
        4,
        10,
        10
      ],
      "2023-03": [
        48,
        9,
        15,
        7,
        5,
        2,
        21,
        3,
        7,
        0,
        0,
        0,
        6,
        1,
        4,
        8
      ],
      "2023-04": [
        51,
        6,
        24,
        5,
        10,
        2,
        25,
        4,
        5,
        2,
        3,
        0,
        7,
        1,
        9,
        3
      ],
      "2023-05": [
        54,
        9,
        27,
        1,
        14,
        5,
        26,
        3,
        13,
        1,
        2,
        2,
        8,
        3,
        10,
        4
      ],
      "2023-06": [
        36,
        6,
        16,
        9,
        7,
        3,
        17,
        1,
        4,
        0,
        1,
        0,
        9,
        3,
        7,
        5
      ],
      "2023-07": [
        24,
        1,
        16,
        2,
        7,
        3,
        11,
        1,
        4,
        1,
        3,
        0,
        10,
        6,
        6,
        7
      ],
      "2023-08": [
        31,
        4,
        19,
        2,
        9,
        1,
        17,
        2,
        6,
        0,
        5,
        1,
        6,
        4,
        3,
        6
      ],
      "2023-09": [
        27,
        3,
        16,
        5,
        12,
        5,
        14,
        3,
        5,
        1,
        2,
        0,
        9,
        2,
        1,
        4
      ],
      "2023-10": [
        36,
        2,
        13,
        11,
        10,
        5,
        14,
        1,
        9,
        0,
        0,
        1,
        16,
        2,
        12,
        7
      ],
      "2023-11": [
        27,
        5,
        19,
        4,
        8,
        1,
        24,
        1,
        7,
        0,
        2,
        0,
        8,
        0,
        4,
        3
      ],
      "2023-12": [
        37,
        4,
        15,
        7,
        11,
        2,
        18,
        4,
        6,
        0,
        4,
        0,
        17,
        7,
        7,
        4
      ],
      "2024-01": [
        57,
        1,
        20,
        7,
        3,
        4,
        17,
        0,
        9,
        0,
        1,
        0,
        10,
        5,
        6,
        7
      ],
      "2024-02": [
        65,
        10,
        21,
        6,
        12,
        11,
        32,
        4,
        5,
        0,
        2,
        2,
        10,
        1,
        5,
        7
      ],
      "2024-03": [
        42,
        1,
        14,
        3,
        5,
        9,
        13,
        2,
        14,
        2,
        0,
        1,
        8,
        4,
        9,
        6
      ],
      "2024-04": [
        63,
        2,
        23,
        7,
        5,
        8,
        11,
        2,
        5,
        0,
        3,
        0,
        10,
        1,
        15,
        5
      ],
      "2024-05": [
        52,
        6,
        17,
        8,
        9,
        7,
        23,
        0,
        7,
        3,
        1,
        1,
        11,
        6,
        12,
        11
      ],
      "2024-06": [
        49,
        2,
        23,
        4,
        7,
        12,
        15,
        3,
        3,
        2,
        6,
        4,
        12,
        9,
        9,
        8
      ],
      "2024-07": [
        42,
        5,
        22,
        8,
        12,
        8,
        15,
        6,
        7,
        1,
        2,
        0,
        12,
        5,
        7,
        4
      ],
      "2024-08": [
        34,
        2,
        22,
        8,
        5,
        3,
        16,
        3,
        4,
        1,
        3,
        2,
        10,
        3,
        5,
        4
      ],
      "2024-09": [
        28,
        2,
        14,
        8,
        10,
        5,
        24,
        2,
        6,
        0,
        1,
        0,
        8,
        1,
        7,
        8
      ],
      "2024-10": [
        49,
        2,
        23,
        3,
        13,
        8,
        21,
        4,
        9,
        1,
        2,
        0,
        11,
        1,
        6,
        6
      ],
      "2024-11": [
        50,
        6,
        22,
        6,
        9,
        4,
        22,
        0,
        6,
        0,
        1,
        1,
        9,
        3,
        6,
        6
      ],
      "2024-12": [
        47,
        1,
        19,
        6,
        5,
        8,
        17,
        2,
        3,
        0,
        1,
        2,
        11,
        1,
        12,
        6
      ],
      "2025-01": [
        60,
        2,
        11,
        5,
        11,
        11,
        11,
        3,
        4,
        1,
        3,
        1,
        8,
        1,
        7,
        3
      ],
      "2025-02": [
        34,
        6,
        18,
        6,
        9,
        6,
        7,
        1,
        3,
        0,
        4,
        1,
        6,
        0,
        6,
        7
      ],
      "2025-03": [
        39,
        5,
        23,
        4,
        8,
        7,
        11,
        0,
        5,
        0,
        4,
        1,
        3,
        3,
        1,
        7
      ],
      "2025-04": [
        50,
        9,
        13,
        2,
        5,
        11,
        14,
        1,
        13,
        0,
        1,
        0,
        4,
        5,
        8,
        5
      ],
      "2025-05": [
        64,
        7,
        26,
        7,
        7,
        12,
        18,
        3,
        9,
        1,
        2,
        0,
        7,
        4,
        6,
        14
      ],
      "2025-06": [
        36,
        5,
        33,
        4,
        6,
        5,
        19,
        5,
        4,
        1,
        0,
        0,
        6,
        4,
        9,
        8
      ],
      "2025-07": [
        39,
        3,
        16,
        7,
        8,
        6,
        18,
        3,
        2,
        0,
        3,
        1,
        9,
        3,
        4,
        6
      ],
      "2025-08": [
        36,
        5,
        20,
        5,
        5,
        5,
        9,
        2,
        7,
        1,
        5,
        0,
        7,
        5,
        5,
        6
      ],
      "2025-09": [
        18,
        0,
        7,
        1,
        2,
        2,
        3,
        2,
        1,
        1,
        1,
        0,
        1,
        0,
        0,
        1
      ]
    },
    "papers": {
      "0": [
        {
          "title": "A Novel Pareto-optimal Ranking Method for Comparing Multi-objective Optimization Algorithms",
          "year": "2024-11",
          "abstract": "As the interest in multi- and many-objective optimization algorithms grows,\nthe performance comparison of these algorithms becomes increasingly important.\nA large number of performance indicators for multi-objective optimization\nalgorithms have been introduced, each of which evaluates these algorithms based\non a certain aspect. Therefore, assessing the quality of multi-objective\nresults using multiple indicators is essential to guarantee that the evaluation\nconsiders all quality perspectives. This paper proposes a novel multi-metric\ncomparison method to rank the performance of multi-/ many-objective\noptimization algorithms based on a set of performance indicators. We utilize\nthe Pareto optimality concept (i.e., non-dominated sorting algorithm) to create\nthe rank levels of algorithms by simultaneously considering multiple\nperformance indicators as criteria/objectives. As a result, four different\ntechniques are proposed to rank algorithms based on their contribution at each\nPareto level. This method allows researchers to utilize a set of existing/newly\ndeveloped performance metrics to adequately assess/rank multi-/many-objective\nalgorithms. The proposed methods are scalable and can accommodate in its\ncomprehensive scheme any newly introduced metric. The method was applied to\nrank 10 competing algorithms in the 2018 CEC competition solving 15\nmany-objective test problems. The Pareto-optimal ranking was conducted based on\n10 well-known multi-objective performance indicators and the results were\ncompared to the final ranks reported by the competition, which were based on\nthe inverted generational distance (IGD) and hypervolume indicator (HV)\nmeasures. The techniques suggested in this paper have broad applications in\nscience and engineering, particularly in areas where multiple metrics are used\nfor comparisons. Examples include machine learning and data mining.",
          "arxiv_id": "2411.17999v1"
        },
        {
          "title": "An Effective and Efficient Evolutionary Algorithm for Many-Objective Optimization",
          "year": "2022-05",
          "abstract": "In evolutionary multiobjective optimization, effectiveness refers to how an\nevolutionary algorithm performs in terms of converging its solutions into the\nPareto front and also diversifying them over the front. This is not an easy\njob, particularly for optimization problems with more than three objectives,\ndubbed many-objective optimization problems. In such problems, classic\nPareto-based algorithms fail to provide sufficient selection pressure towards\nthe Pareto front, whilst recently developed algorithms, such as\ndecomposition-based ones, may struggle to maintain a set of well-distributed\nsolutions on certain problems (e.g., those with irregular Pareto fronts).\nAnother issue in some many-objective optimizers is rapidly increasing\ncomputational requirement with the number of objectives, such as\nhypervolume-based algorithms and shift-based density estimation (SDE) methods.\nIn this paper, we aim to address this problem and develop an effective and\nefficient evolutionary algorithm (E3A) that can handle various many-objective\nproblems. In E3A, inspired by SDE, a novel population maintenance method is\nproposed to select high-quality solutions in the environmental selection\nprocedure. We conduct extensive experiments and show that E3A performs better\nthan 11 state-of-the-art many-objective evolutionary algorithms in quickly\nfinding a set of well-converged and well-diversified solutions.",
          "arxiv_id": "2205.15884v2"
        },
        {
          "title": "Rank-Based Learning and Local Model Based Evolutionary Algorithm for High-Dimensional Expensive Multi-Objective Problems",
          "year": "2023-04",
          "abstract": "Surrogate-assisted evolutionary algorithms have been widely developed to\nsolve complex and computationally expensive multi-objective optimization\nproblems in recent years. However, when dealing with high-dimensional\noptimization problems, the performance of these surrogate-assisted\nmulti-objective evolutionary algorithms deteriorate drastically. In this work,\na novel Classifier-assisted rank-based learning and Local Model based\nmulti-objective Evolutionary Algorithm (CLMEA) is proposed for high-dimensional\nexpensive multi-objective optimization problems. The proposed algorithm\nconsists of three parts: classifier-assisted rank-based learning,\nhypervolume-based non-dominated search, and local search in the relatively\nsparse objective space. Specifically, a probabilistic neural network is built\nas classifier to divide the offspring into a number of ranks. The offspring in\ndifferent ranks uses rank-based learning strategy to generate more promising\nand informative candidates for real function evaluations. Then, radial basis\nfunction networks are built as surrogates to approximate the objective\nfunctions. After searching non-dominated solutions assisted by the surrogate\nmodel, the candidates with higher hypervolume improvement are selected for real\nevaluations. Subsequently, in order to maintain the diversity of solutions, the\nmost uncertain sample point from the non-dominated solutions measured by the\ncrowding distance is selected as the guided parent to further infill in the\nuncertain region of the front. The experimental results of benchmark problems\nand a real-world application on geothermal reservoir heat extraction\noptimization demonstrate that the proposed algorithm shows superior performance\ncompared with the state-of-the-art surrogate-assisted multi-objective\nevolutionary algorithms. The source code for this work is available at\nhttps://github.com/JellyChen7/CLMEA.",
          "arxiv_id": "2304.09444v4"
        }
      ],
      "1": [
        {
          "title": "Evolving Hierarchical Memory-Prediction Machines in Multi-Task Reinforcement Learning",
          "year": "2021-06",
          "abstract": "A fundamental aspect of behaviour is the ability to encode salient features\nof experience in memory and use these memories, in combination with current\nsensory information, to predict the best action for each situation such that\nlong-term objectives are maximized. The world is highly dynamic, and\nbehavioural agents must generalize across a variety of environments and\nobjectives over time. This scenario can be modeled as a partially-observable\nmulti-task reinforcement learning problem. We use genetic programming to evolve\nhighly-generalized agents capable of operating in six unique environments from\nthe control literature, including OpenAI's entire Classic Control suite. This\nrequires the agent to support discrete and continuous actions simultaneously.\nNo task-identification sensor inputs are provided, thus agents must identify\ntasks from the dynamics of state variables alone and define control policies\nfor each task. We show that emergent hierarchical structure in the evolving\nprograms leads to multi-task agents that succeed by performing a temporal\ndecomposition and encoding of the problem environments in memory. The resulting\nagents are competitive with task-specific agents in all six environments.\nFurthermore, the hierarchical structure of programs allows for dynamic run-time\ncomplexity, which results in relatively efficient operation.",
          "arxiv_id": "2106.12659v1"
        },
        {
          "title": "Accelerating Model-Based Reinforcement Learning with State-Space World Models",
          "year": "2025-02",
          "abstract": "Reinforcement learning (RL) is a powerful approach for robot learning.\nHowever, model-free RL (MFRL) requires a large number of environment\ninteractions to learn successful control policies. This is due to the noisy RL\ntraining updates and the complexity of robotic systems, which typically involve\nhighly non-linear dynamics and noisy sensor signals. In contrast, model-based\nRL (MBRL) not only trains a policy but simultaneously learns a world model that\ncaptures the environment's dynamics and rewards. The world model can either be\nused for planning, for data collection, or to provide first-order policy\ngradients for training. Leveraging a world model significantly improves sample\nefficiency compared to model-free RL. However, training a world model alongside\nthe policy increases the computational complexity, leading to longer training\ntimes that are often intractable for complex real-world scenarios. In this\nwork, we propose a new method for accelerating model-based RL using state-space\nworld models. Our approach leverages state-space models (SSMs) to parallelize\nthe training of the dynamics model, which is typically the main computational\nbottleneck. Additionally, we propose an architecture that provides privileged\ninformation to the world model during training, which is particularly relevant\nfor partially observable environments. We evaluate our method in several\nreal-world agile quadrotor flight tasks, involving complex dynamics, for both\nfully and partially observable environments. We demonstrate a significant\nspeedup, reducing the world model training time by up to 10 times, and the\noverall MBRL training time by up to 4 times. This benefit comes without\ncompromising performance, as our method achieves similar sample efficiency and\ntask rewards to state-of-the-art MBRL methods.",
          "arxiv_id": "2502.20168v1"
        },
        {
          "title": "Lineage Evolution Reinforcement Learning",
          "year": "2020-09",
          "abstract": "We propose a general agent population learning system, and on this basis, we\npropose lineage evolution reinforcement learning algorithm. Lineage evolution\nreinforcement learning is a kind of derivative algorithm which accords with the\ngeneral agent population learning system. We take the agents in DQN and its\nrelated variants as the basic agents in the population, and add the selection,\nmutation and crossover modules in the genetic algorithm to the reinforcement\nlearning algorithm. In the process of agent evolution, we refer to the\ncharacteristics of natural genetic behavior, add lineage factor to ensure the\nretention of potential performance of agent, and comprehensively consider the\ncurrent performance and lineage value when evaluating the performance of agent.\nWithout changing the parameters of the original reinforcement learning\nalgorithm, lineage evolution reinforcement learning can optimize different\nreinforcement learning algorithms. Our experiments show that the idea of\nevolution with lineage improves the performance of original reinforcement\nlearning algorithm in some games in Atari 2600.",
          "arxiv_id": "2010.14616v1"
        }
      ],
      "2": [
        {
          "title": "MSAT: Biologically Inspired Multi-Stage Adaptive Threshold for Conversion of Spiking Neural Networks",
          "year": "2023-03",
          "abstract": "Spiking Neural Networks (SNNs) can do inference with low power consumption\ndue to their spike sparsity. ANN-SNN conversion is an efficient way to achieve\ndeep SNNs by converting well-trained Artificial Neural Networks (ANNs).\nHowever, the existing methods commonly use constant threshold for conversion,\nwhich prevents neurons from rapidly delivering spikes to deeper layers and\ncauses high time delay. In addition, the same response for different inputs may\nresult in information loss during the information transmission. Inspired by the\nbiological model mechanism, we propose a multi-stage adaptive threshold (MSAT).\nSpecifically, for each neuron, the dynamic threshold varies with firing history\nand input properties and is positively correlated with the average membrane\npotential and negatively correlated with the rate of depolarization. The\nself-adaptation to membrane potential and input allows a timely adjustment of\nthe threshold to fire spike faster and transmit more information. Moreover, we\nanalyze the Spikes of Inactivated Neurons error which is pervasive in early\ntime steps and propose spike confidence accordingly as a measurement of\nconfidence about the neurons that correctly deliver spikes. We use such spike\nconfidence in early time steps to determine whether to elicit spike to\nalleviate this error. Combined with the proposed method, we examine the\nperformance on non-trivial datasets CIFAR-10, CIFAR-100, and ImageNet. We also\nconduct sentiment classification and speech recognition experiments on the IDBM\nand Google speech commands datasets respectively. Experiments show\nnear-lossless and lower latency ANN-SNN conversion. To the best of our\nknowledge, this is the first time to build a biologically inspired multi-stage\nadaptive threshold for converted SNN, with comparable performance to\nstate-of-the-art methods while improving energy efficiency.",
          "arxiv_id": "2303.13080v1"
        },
        {
          "title": "Optimal Conversion of Conventional Artificial Neural Networks to Spiking Neural Networks",
          "year": "2021-02",
          "abstract": "Spiking neural networks (SNNs) are biology-inspired artificial neural\nnetworks (ANNs) that comprise of spiking neurons to process asynchronous\ndiscrete signals. While more efficient in power consumption and inference speed\non the neuromorphic hardware, SNNs are usually difficult to train directly from\nscratch with spikes due to the discreteness. As an alternative, many efforts\nhave been devoted to converting conventional ANNs into SNNs by copying the\nweights from ANNs and adjusting the spiking threshold potential of neurons in\nSNNs. Researchers have designed new SNN architectures and conversion algorithms\nto diminish the conversion error. However, an effective conversion should\naddress the difference between the SNN and ANN architectures with an efficient\napproximation \\DSK{of} the loss function, which is missing in the field. In\nthis work, we analyze the conversion error by recursive reduction to layer-wise\nsummation and propose a novel strategic pipeline that transfers the weights to\nthe target SNN by combining threshold balance and soft-reset mechanisms. This\npipeline enables almost no accuracy loss between the converted SNNs and\nconventional ANNs with only $\\sim1/10$ of the typical SNN simulation time. Our\nmethod is promising to get implanted onto embedded platforms with better\nsupport of SNNs with limited energy and memory.",
          "arxiv_id": "2103.00476v1"
        },
        {
          "title": "Optimal ANN-SNN Conversion for High-accuracy and Ultra-low-latency Spiking Neural Networks",
          "year": "2023-03",
          "abstract": "Spiking Neural Networks (SNNs) have gained great attraction due to their\ndistinctive properties of low power consumption and fast inference on\nneuromorphic hardware. As the most effective method to get deep SNNs, ANN-SNN\nconversion has achieved comparable performance as ANNs on large-scale datasets.\nDespite this, it requires long time-steps to match the firing rates of SNNs to\nthe activation of ANNs. As a result, the converted SNN suffers severe\nperformance degradation problems with short time-steps, which hamper the\npractical application of SNNs. In this paper, we theoretically analyze ANN-SNN\nconversion error and derive the estimated activation function of SNNs. Then we\npropose the quantization clip-floor-shift activation function to replace the\nReLU activation function in source ANNs, which can better approximate the\nactivation function of SNNs. We prove that the expected conversion error\nbetween SNNs and ANNs is zero, enabling us to achieve high-accuracy and\nultra-low-latency SNNs. We evaluate our method on CIFAR-10/100 and ImageNet\ndatasets, and show that it outperforms the state-of-the-art ANN-SNN and\ndirectly trained SNNs in both accuracy and time-steps. To the best of our\nknowledge, this is the first time to explore high-performance ANN-SNN\nconversion with ultra-low latency (4 time-steps). Code is available at\nhttps://github.com/putshua/SNN\\_conversion\\_QCFS",
          "arxiv_id": "2303.04347v1"
        }
      ],
      "3": [
        {
          "title": "On the Role of System Software in Energy Management of Neuromorphic Computing",
          "year": "2021-03",
          "abstract": "Neuromorphic computing systems such as DYNAPs and Loihi have recently been\nintroduced to the computing community to improve performance and energy\nefficiency of machine learning programs, especially those that are implemented\nusing Spiking Neural Network (SNN). The role of a system software for\nneuromorphic systems is to cluster a large machine learning model (e.g., with\nmany neurons and synapses) and map these clusters to the computing resources of\nthe hardware. In this work, we formulate the energy consumption of a\nneuromorphic hardware, considering the power consumed by neurons and synapses,\nand the energy consumed in communicating spikes on the interconnect. Based on\nsuch formulation, we first evaluate the role of a system software in managing\nthe energy consumption of neuromorphic systems. Next, we formulate a simple\nheuristic-based mapping approach to place the neurons and synapses onto the\ncomputing resources to reduce energy consumption. We evaluate our approach with\n10 machine learning applications and demonstrate that the proposed mapping\napproach leads to a significant reduction of energy consumption of neuromorphic\ncomputing systems.",
          "arxiv_id": "2103.12231v1"
        },
        {
          "title": "Cryogenic Neuromorphic Hardware",
          "year": "2022-03",
          "abstract": "The revolution in artificial intelligence (AI) brings up an enormous storage\nand data processing requirement. Large power consumption and hardware overhead\nhave become the main challenges for building next-generation AI hardware. To\nmitigate this, Neuromorphic computing has drawn immense attention due to its\nexcellent capability for data processing with very low power consumption. While\nrelentless research has been underway for years to minimize the power\nconsumption in neuromorphic hardware, we are still a long way off from reaching\nthe energy efficiency of the human brain. Furthermore, design complexity and\nprocess variation hinder the large-scale implementation of current neuromorphic\nplatforms. Recently, the concept of implementing neuromorphic computing systems\nin cryogenic temperature has garnered intense interest thanks to their\nexcellent speed and power metric. Several cryogenic devices can be engineered\nto work as neuromorphic primitives with ultra-low demand for power. Here we\ncomprehensively review the cryogenic neuromorphic hardware. We classify the\nexisting cryogenic neuromorphic hardware into several hierarchical categories\nand sketch a comparative analysis based on key performance metrics. Our\nanalysis concisely describes the operation of the associated circuit topology\nand outlines the advantages and challenges encountered by the state-of-the-art\ntechnology platforms. Finally, we provide insights to circumvent these\nchallenges for the future progression of research.",
          "arxiv_id": "2204.07503v2"
        },
        {
          "title": "Bridging Quantized Artificial Neural Networks and Neuromorphic Hardware",
          "year": "2025-05",
          "abstract": "Neuromorphic hardware aims to leverage distributed computing and event-driven\ncircuit design to achieve an energy-efficient AI system. The name\n\"neuromorphic\" is derived from its spiking and local computing nature, which\nmimics the fundamental activity of an animal's nervous system. In neuromorphic\nhardware, neurons, i.e., computing cores use single-bit, event-driven data\n(called spikes) for inter-communication, which differs substantially from\nconventional hardware. To leverage the advantages of neuromorphic hardware and\nimplement a computing model, the conventional approach is to build spiking\nneural networks (SNNs). SNNs replace the nonlinearity part of artificial neural\nnetworks (ANNs) in the realm of deep learning with spiking neurons, where the\nspiking neuron mimics the basic behavior of bio-neurons. However, there is\nstill a performance gap between SNNs and their ANN counterparts. In this paper,\nwe explore a new way to map computing models onto neuromorphic hardware. We\npropose a Spiking-Driven ANN (SDANN) framework that directly implements\nquantized ANN on hardware, eliminating the need for tuning the trainable\nparameters or any performance degradation. With the power of quantized ANN, our\nSDANN ensures a lower bound of implementation performance on neuromorphic\nhardware. To address the limitation of bit width support on hardware, we\npropose bias calibration and scaled integration methods. Experiments on various\ntasks demonstrate that our SDANN achieves exactly the same accuracy as the\nquantized ANN. Beyond toy examples and software implementation, we successfully\ndeployed and validated our spiking models on real neuromorphic hardware,\ndemonstrating the feasibility of the SDANN framework.",
          "arxiv_id": "2505.12221v2"
        }
      ],
      "4": [
        {
          "title": "Signal Propagation: A Framework for Learning and Inference In a Forward Pass",
          "year": "2022-04",
          "abstract": "We propose a new learning framework, signal propagation (sigprop), for\npropagating a learning signal and updating neural network parameters via a\nforward pass, as an alternative to backpropagation. In sigprop, there is only\nthe forward path for inference and learning. So, there are no structural or\ncomputational constraints necessary for learning to take place, beyond the\ninference model itself, such as feedback connectivity, weight transport, or a\nbackward pass, which exist under backpropagation based approaches. That is,\nsigprop enables global supervised learning with only a forward path. This is\nideal for parallel training of layers or modules. In biology, this explains how\nneurons without feedback connections can still receive a global learning\nsignal. In hardware, this provides an approach for global supervised learning\nwithout backward connectivity. Sigprop by construction has compatibility with\nmodels of learning in the brain and in hardware than backpropagation, including\nalternative approaches relaxing learning constraints. We also demonstrate that\nsigprop is more efficient in time and memory than they are. To further explain\nthe behavior of sigprop, we provide evidence that sigprop provides useful\nlearning signals in context to backpropagation. To further support relevance to\nbiological and hardware learning, we use sigprop to train continuous time\nneural networks with Hebbian updates, and train spiking neural networks with\nonly the voltage or with biologically and hardware compatible surrogate\nfunctions.",
          "arxiv_id": "2204.01723v2"
        },
        {
          "title": "The Influence of Initial Connectivity on Biologically Plausible Learning",
          "year": "2024-10",
          "abstract": "Understanding how the brain learns can be advanced by investigating\nbiologically plausible learning rules -- those that obey known biological\nconstraints, such as locality, to serve as valid brain learning models. Yet,\nmany studies overlook the role of architecture and initial synaptic\nconnectivity in such models. Building on insights from deep learning, where\ninitialization profoundly affects learning dynamics, we ask a key but\nunderexplored neuroscience question: how does initial synaptic connectivity\nshape learning in neural circuits? To investigate this, we train recurrent\nneural networks (RNNs), which are widely used for brain modeling, with\nbiologically plausible learning rules. Our findings reveal that initial weight\nmagnitude significantly influences the learning performance of such rules,\nmirroring effects previously observed in training with backpropagation through\ntime (BPTT). By examining the maximum Lyapunov exponent before and after\ntraining, we uncovered the greater demands that certain initialization schemes\nplace on training to achieve desired information propagation properties.\nConsequently, we extended the recently proposed gradient flossing method, which\nregularizes the Lyapunov exponents, to biologically plausible learning and\nobserved an improvement in learning performance. To our knowledge, we are the\nfirst to examine the impact of initialization on biologically plausible\nlearning rules for RNNs and to subsequently propose a biologically plausible\nremedy. Such an investigation can lead to neuroscientific predictions about the\ninfluence of initial connectivity on learning dynamics and performance, as well\nas guide neuromorphic design.",
          "arxiv_id": "2410.11164v3"
        },
        {
          "title": "Unsupervised representation learning with Hebbian synaptic and structural plasticity in brain-like feedforward neural networks",
          "year": "2024-06",
          "abstract": "Neural networks that can capture key principles underlying brain computation\noffer exciting new opportunities for developing artificial intelligence and\nbrain-like computing algorithms. Such networks remain biologically plausible\nwhile leveraging localized forms of synaptic learning rules and modular network\narchitecture found in the neocortex. Compared to backprop-driven deep learning\napproches, they provide more suitable models for deployment of neuromorphic\nhardware and have greater potential for scalability on large-scale computing\nclusters. The development of such brain-like neural networks depends on having\na learning procedure that can build effective internal representations from\ndata. In this work, we introduce and evaluate a brain-like neural network model\ncapable of unsupervised representation learning. It builds on the Bayesian\nConfidence Propagation Neural Network (BCPNN), which has earlier been\nimplemented as abstract as well as biophyscially detailed recurrent attractor\nneural networks explaining various cortical associative memory phenomena. Here\nwe developed a feedforward BCPNN model to perform representation learning by\nincorporating a range of brain-like attributes derived from neocortical\ncircuits such as cortical columns, divisive normalization, Hebbian synaptic\nplasticity, structural plasticity, sparse activity, and sparse patchy\nconnectivity. The model was tested on a diverse set of popular machine learning\nbenchmarks: grayscale images (MNIST, F-MNIST), RGB natural images (SVHN,\nCIFAR-10), QSAR (MUV, HIV), and malware detection (EMBER). The performance of\nthe model when using a linear classifier to predict the class labels fared\ncompetitively with conventional multi-layer perceptrons and other\nstate-of-the-art brain-like neural networks.",
          "arxiv_id": "2406.04733v2"
        }
      ],
      "5": [
        {
          "title": "Large Language Models as Surrogate Models in Evolutionary Algorithms: A Preliminary Study",
          "year": "2024-06",
          "abstract": "Large Language Models (LLMs) have achieved significant progress across\nvarious fields and have exhibited strong potential in evolutionary computation,\nsuch as generating new solutions and automating algorithm design.\nSurrogate-assisted selection is a core step in evolutionary algorithms to solve\nexpensive optimization problems by reducing the number of real evaluations.\nTraditionally, this has relied on conventional machine learning methods,\nleveraging historical evaluated evaluations to predict the performance of new\nsolutions. In this work, we propose a novel surrogate model based purely on LLM\ninference capabilities, eliminating the need for training. Specifically, we\nformulate model-assisted selection as a classification and regression problem,\nutilizing LLMs to directly evaluate the quality of new solutions based on\nhistorical data. This involves predicting whether a solution is good or bad, or\napproximating its value. This approach is then integrated into evolutionary\nalgorithms, termed LLM-assisted EA (LAEA). Detailed experiments compared the\nvisualization results of 2D data from 9 mainstream LLMs, as well as their\nperformance on optimization problems. The experimental results demonstrate that\nLLMs have significant potential as surrogate models in evolutionary\ncomputation, achieving performance comparable to traditional surrogate models\nonly using inference. This work offers new insights into the application of\nLLMs in evolutionary computation. Code is available at:\nhttps://github.com/hhyqhh/LAEA.git",
          "arxiv_id": "2406.10675v1"
        },
        {
          "title": "Evolving Code with A Large Language Model",
          "year": "2024-01",
          "abstract": "Algorithms that use Large Language Models (LLMs) to evolve code arrived on\nthe Genetic Programming (GP) scene very recently. We present LLM GP, a\nformalized LLM-based evolutionary algorithm designed to evolve code. Like GP,\nit uses evolutionary operators, but its designs and implementations of those\noperators radically differ from GP's because they enlist an LLM, using\nprompting and the LLM's pre-trained pattern matching and sequence completion\ncapability. We also present a demonstration-level variant of LLM GP and share\nits code. By addressing algorithms that range from the formal to hands-on, we\ncover design and LLM-usage considerations as well as the scientific challenges\nthat arise when using an LLM for genetic programming.",
          "arxiv_id": "2401.07102v1"
        },
        {
          "title": "LLM-Meta-SR: In-Context Learning for Evolving Selection Operators in Symbolic Regression",
          "year": "2025-05",
          "abstract": "Large language models (LLMs) have revolutionized algorithm development, yet\ntheir application in symbolic regression, where algorithms automatically\ndiscover symbolic expressions from data, remains constrained and is typically\ndesigned manually by human experts. In this paper, we propose a meta learning\nframework that enables LLMs to automatically design selection operators for\nevolutionary symbolic regression algorithms. We first identify two key\nlimitations in existing LLM-based algorithm evolution techniques: a lack of\nsemantic guidance and code bloat. The absence of semantic awareness can lead to\nineffective exchange of useful code components, and bloat results in\nunnecessarily complex components, both of which can reduce the interpretability\nof the designed algorithm or hinder evolutionary learning progress. To address\nthese issues, we enhance the LLM-based evolution framework for meta symbolic\nregression with two key innovations: a complementary, semantics-aware selection\noperator and bloat control. Additionally, we embed domain knowledge into the\nprompt, enabling the LLM to generate more effective and contextually relevant\nselection operators. Our experimental results on symbolic regression benchmarks\nshow that LLMs can devise selection operators that outperform nine\nexpert-designed baselines, achieving state-of-the-art performance. Moreover,\nthe evolved operator can further improve the state-of-the-art symbolic\nregression algorithm, achieving the best performance among 26 symbolic\nregression and machine learning algorithms across 116 regression datasets. This\ndemonstrates that LLMs can exceed expert-level algorithm design for symbolic\nregression.",
          "arxiv_id": "2505.18602v2"
        }
      ],
      "6": [
        {
          "title": "Deeper Learning with CoLU Activation",
          "year": "2021-12",
          "abstract": "In neural networks, non-linearity is introduced by activation functions. One\ncommonly used activation function is Rectified Linear Unit (ReLU). ReLU has\nbeen a popular choice as an activation but has flaws. State-of-the-art\nfunctions like Swish and Mish are now gaining attention as a better choice as\nthey combat many flaws presented by other activation functions. CoLU is an\nactivation function similar to Swish and Mish in properties. It is defined as\nf(x)=x/(1-xe^-(x+e^x)). It is smooth, continuously differentiable, unbounded\nabove, bounded below, non-saturating, and non-monotonic. Based on experiments\ndone with CoLU with different activation functions, it is observed that CoLU\nusually performs better than other functions on deeper neural networks. While\ntraining different neural networks on MNIST on an incrementally increasing\nnumber of convolutional layers, CoLU retained the highest accuracy for more\nlayers. On a smaller network with 8 convolutional layers, CoLU had the highest\nmean accuracy, closely followed by ReLU. On VGG-13 trained on Fashion-MNIST,\nCoLU had a 4.20% higher accuracy than Mish and 3.31% higher accuracy than ReLU.\nOn ResNet-9 trained on Cifar-10, CoLU had 0.05% higher accuracy than Swish,\n0.09% higher accuracy than Mish, and 0.29% higher accuracy than ReLU. It is\nobserved that activation functions may behave better than other activation\nfunctions based on different factors including the number of layers, types of\nlayers, number of parameters, learning rate, optimizer, etc. Further research\ncan be done on these factors and activation functions for more optimal\nactivation functions and more knowledge on their behavior.",
          "arxiv_id": "2112.12078v1"
        },
        {
          "title": "ErfReLU: Adaptive Activation Function for Deep Neural Network",
          "year": "2023-06",
          "abstract": "Recent research has found that the activation function (AF) selected for\nadding non-linearity into the output can have a big impact on how effectively\ndeep learning networks perform. Developing activation functions that can adapt\nsimultaneously with learning is a need of time. Researchers recently started\ndeveloping activation functions that can be trained throughout the learning\nprocess, known as trainable, or adaptive activation functions (AAF). Research\non AAF that enhance the outcomes is still in its early stages. In this paper, a\nnovel activation function 'ErfReLU' has been developed based on the erf\nfunction and ReLU. This function exploits the ReLU and the error function (erf)\nto its advantage. State of art activation functions like Sigmoid, ReLU, Tanh,\nand their properties have been briefly explained. Adaptive activation functions\nlike Tanhsoft1, Tanhsoft2, Tanhsoft3, TanhLU, SAAF, ErfAct, Pserf, Smish, and\nSerf have also been described. Lastly, performance analysis of 9 trainable\nactivation functions along with the proposed one namely Tanhsoft1, Tanhsoft2,\nTanhsoft3, TanhLU, SAAF, ErfAct, Pserf, Smish, and Serf has been shown by\napplying these activation functions in MobileNet, VGG16, and ResNet models on\nCIFAR-10, MNIST, and FMNIST benchmark datasets.",
          "arxiv_id": "2306.01822v1"
        },
        {
          "title": "Data-aware customization of activation functions reduces neural network error",
          "year": "2023-01",
          "abstract": "Activation functions play critical roles in neural networks, yet current\noff-the-shelf neural networks pay little attention to the specific choice of\nactivation functions used. Here we show that data-aware customization of\nactivation functions can result in striking reductions in neural network error.\nWe first give a simple linear algebraic explanation of the role of activation\nfunctions in neural networks; then, through connection with the\nDiaconis-Shahshahani Approximation Theorem, we propose a set of criteria for\ngood activation functions. As a case study, we consider regression tasks with a\npartially exchangeable target function, \\emph{i.e.} $f(u,v,w)=f(v,u,w)$ for\n$u,v\\in \\mathbb{R}^d$ and $w\\in \\mathbb{R}^k$, and prove that for such a target\nfunction, using an even activation function in at least one of the layers\nguarantees that the prediction preserves partial exchangeability for best\nperformance. Since even activation functions are seldom used in practice, we\ndesigned the ``seagull'' even activation function $\\log(1+x^2)$ according to\nour criteria. Empirical testing on over two dozen 9-25 dimensional examples\nwith different local smoothness, curvature, and degree of exchangeability\nrevealed that a simple substitution with the ``seagull'' activation function in\nan already-refined neural network can lead to an order-of-magnitude reduction\nin error. This improvement was most pronounced when the activation function\nsubstitution was applied to the layer in which the exchangeable variables are\nconnected for the first time. While the improvement is greatest for\nlow-dimensional data, experiments on the CIFAR10 image classification dataset\nshowed that use of ``seagull'' can reduce error even for high-dimensional\ncases. These results collectively highlight the potential of customizing\nactivation functions as a general approach to improve neural network\nperformance.",
          "arxiv_id": "2301.06635v1"
        }
      ],
      "7": [
        {
          "title": "Attacking the Spike: On the Transferability and Security of Spiking Neural Networks to Adversarial Examples",
          "year": "2022-09",
          "abstract": "Spiking neural networks (SNNs) have attracted much attention for their high\nenergy efficiency and for recent advances in their classification performance.\nHowever, unlike traditional deep learning approaches, the analysis and study of\nthe robustness of SNNs to adversarial examples remain relatively\nunderdeveloped. In this work, we focus on advancing the adversarial attack side\nof SNNs and make three major contributions. First, we show that successful\nwhite-box adversarial attacks on SNNs are highly dependent on the underlying\nsurrogate gradient technique, even in the case of adversarially trained SNNs.\nSecond, using the best surrogate gradient technique, we analyze the\ntransferability of adversarial attacks on SNNs and other state-of-the-art\narchitectures like Vision Transformers (ViTs) and Big Transfer Convolutional\nNeural Networks (CNNs). We demonstrate that the adversarial examples created by\nnon-SNN architectures are not misclassified often by SNNs. Third, due to the\nlack of an ubiquitous white-box attack that is effective across both the SNN\nand CNN/ViT domains, we develop a new white-box attack, the Auto Self-Attention\nGradient Attack (Auto-SAGA). Our novel attack generates adversarial examples\ncapable of fooling both SNN and non-SNN models simultaneously. Auto-SAGA is as\nmuch as $91.1\\%$ more effective on SNN/ViT model ensembles and provides a\n$3\\times$ boost in attack effectiveness on adversarially trained SNN ensembles\ncompared to conventional white-box attacks like Auto-PGD. Our experiments and\nanalyses are broad and rigorous covering three datasets (CIFAR-10, CIFAR-100\nand ImageNet), five different white-box attacks and nineteen classifier models\n(seven for each CIFAR dataset and five models for ImageNet).",
          "arxiv_id": "2209.03358v3"
        },
        {
          "title": "Protecting Feed-Forward Networks from Adversarial Attacks Using Predictive Coding",
          "year": "2024-10",
          "abstract": "An adversarial example is a modified input image designed to cause a Machine\nLearning (ML) model to make a mistake; these perturbations are often invisible\nor subtle to human observers and highlight vulnerabilities in a model's ability\nto generalize from its training data. Several adversarial attacks can create\nsuch examples, each with a different perspective, effectiveness, and\nperceptibility of changes. Conversely, defending against such adversarial\nattacks improves the robustness of ML models in image processing and other\ndomains of deep learning. Most defence mechanisms require either a level of\nmodel awareness, changes to the model, or access to a comprehensive set of\nadversarial examples during training, which is impractical. Another option is\nto use an auxiliary model in a preprocessing manner without changing the\nprimary model. This study presents a practical and effective solution -- using\npredictive coding networks (PCnets) as an auxiliary step for adversarial\ndefence. By seamlessly integrating PCnets into feed-forward networks as a\npreprocessing step, we substantially bolster resilience to adversarial\nperturbations. Our experiments on MNIST and CIFAR10 demonstrate the remarkable\neffectiveness of PCnets in mitigating adversarial examples with about 82% and\n65% improvements in robustness, respectively. The PCnet, trained on a small\nsubset of the dataset, leverages its generative nature to effectively counter\nadversarial efforts, reverting perturbed images closer to their original forms.\nThis innovative approach holds promise for enhancing the security and\nreliability of neural network classifiers in the face of the escalating threat\nof adversarial attacks.",
          "arxiv_id": "2411.00222v1"
        },
        {
          "title": "On the Adversarial Robustness of Spiking Neural Networks Trained by Local Learning",
          "year": "2025-04",
          "abstract": "Recent research has shown the vulnerability of Spiking Neural Networks (SNNs)\nunder adversarial examples that are nearly indistinguishable from clean data in\nthe context of frame-based and event-based information. The majority of these\nstudies are constrained in generating adversarial examples using\nBackpropagation Through Time (BPTT), a gradient-based method which lacks\nbiological plausibility. In contrast, local learning methods, which relax many\nof BPTT's constraints, remain under-explored in the context of adversarial\nattacks. To address this problem, we examine adversarial robustness in SNNs\nthrough the framework of four types of training algorithms. We provide an\nin-depth analysis of the ineffectiveness of gradient-based adversarial attacks\nto generate adversarial instances in this scenario. To overcome these\nlimitations, we introduce a hybrid adversarial attack paradigm that leverages\nthe transferability of adversarial instances. The proposed hybrid approach\ndemonstrates superior performance, outperforming existing adversarial attack\nmethods. Furthermore, the generalizability of the method is assessed under\nmulti-step adversarial attacks, adversarial attacks in black-box FGSM\nscenarios, and within the non-spiking domain.",
          "arxiv_id": "2504.08897v2"
        }
      ],
      "8": [
        {
          "title": "Towards Less Constrained Macro-Neural Architecture Search",
          "year": "2022-03",
          "abstract": "Networks found with Neural Architecture Search (NAS) achieve state-of-the-art\nperformance in a variety of tasks, out-performing human-designed networks.\nHowever, most NAS methods heavily rely on human-defined assumptions that\nconstrain the search: architecture's outer-skeletons, number of layers,\nparameter heuristics and search spaces. Additionally, common search spaces\nconsist of repeatable modules (cells) instead of fully exploring the\narchitecture's search space by designing entire architectures (macro-search).\nImposing such constraints requires deep human expertise and restricts the\nsearch to pre-defined settings. In this paper, we propose LCMNAS, a method that\npushes NAS to less constrained search spaces by performing macro-search without\nrelying on pre-defined heuristics or bounded search spaces. LCMNAS introduces\nthree components for the NAS pipeline: i) a method that leverages information\nabout well-known architectures to autonomously generate complex search spaces\nbased on Weighted Directed Graphs with hidden properties, ii) an evolutionary\nsearch strategy that generates complete architectures from scratch, and iii) a\nmixed-performance estimation approach that combines information about\narchitectures at initialization stage and lower fidelity estimates to infer\ntheir trainability and capacity to model complex functions. We present\nexperiments in 13 different data sets showing that LCMNAS is capable of\ngenerating both cell and macro-based architectures with minimal GPU computation\nand state-of-the-art results. More, we conduct extensive studies on the\nimportance of different NAS components in both cell and macro-based settings.\nCode for reproducibility is public at https://github.com/VascoLopes/LCMNAS.",
          "arxiv_id": "2203.05508v2"
        },
        {
          "title": "A Pairwise Comparison Relation-assisted Multi-objective Evolutionary Neural Architecture Search Method with Multi-population Mechanism",
          "year": "2024-07",
          "abstract": "Neural architecture search (NAS) enables researchers to automatically explore\nvast search spaces and find efficient neural networks. But NAS suffers from a\nkey bottleneck, i.e., numerous architectures need to be evaluated during the\nsearch process, which requires a lot of computing resources and time. In order\nto improve the efficiency of NAS, a series of methods have been proposed to\nreduce the evaluation time of neural architectures. However, they are not\nefficient enough and still only focus on the accuracy of architectures. In\naddition to the classification accuracy, more efficient and smaller network\narchitectures are required in real-world applications. To address the above\nproblems, we propose the SMEM-NAS, a pairwise comparison relation-assisted\nmulti-objective evolutionary algorithm based on a multi-population mechanism.\nIn the SMEM-NAS, a surrogate model is constructed based on pairwise comparison\nrelations to predict the accuracy ranking of architectures, rather than the\nabsolute accuracy. Moreover, two populations cooperate with each other in the\nsearch process, i.e., a main population guides the evolution, while a vice\npopulation expands the diversity. Our method aims to provide high-performance\nmodels that take into account multiple optimization objectives. We conduct a\nseries of experiments on the CIFAR-10, CIFAR-100 and ImageNet datasets to\nverify its effectiveness. With only a single GPU searching for 0.17 days,\ncompetitive architectures can be found by SMEM-NAS which achieves 78.91%\naccuracy with the MAdds of 570M on the ImageNet. This work makes a significant\nadvance in the important field of NAS. Our code is publicly available at\nhttps://github.com/ccz-enas/SMEM-NAS.",
          "arxiv_id": "2407.15600v2"
        },
        {
          "title": "ADWPNAS: Architecture-Driven Weight Prediction for Neural Architecture Search",
          "year": "2020-03",
          "abstract": "How to discover and evaluate the true strength of models quickly and\naccurately is one of the key challenges in Neural Architecture Search (NAS). To\ncope with this problem, we propose an Architecture-Driven Weight Prediction\n(ADWP) approach for neural architecture search (NAS). In our approach, we first\ndesign an architecture-intensive search space and then train a HyperNetwork by\ninputting stochastic encoding architecture parameters. In the trained\nHyperNetwork, weights of convolution kernels can be well predicted for neural\narchitectures in the search space. Consequently, the target architectures can\nbe evaluated efficiently without any finetuning, thus enabling us to search\nfortheoptimalarchitectureinthespaceofgeneralnetworks (macro-search). Through\nreal experiments, we evaluate the performance of the models discovered by the\nproposed AD-WPNAS and results show that one search procedure can be completed\nin 4.0 GPU hours on CIFAR-10. Moreover, the discovered model obtains a test\nerror of 2.41% with only 1.52M parameters which is superior to the best\nexisting models.",
          "arxiv_id": "2003.01335v1"
        }
      ],
      "9": [
        {
          "title": "Gradual Channel Pruning while Training using Feature Relevance Scores for Convolutional Neural Networks",
          "year": "2020-02",
          "abstract": "The enormous inference cost of deep neural networks can be scaled down by\nnetwork compression. Pruning is one of the predominant approaches used for deep\nnetwork compression. However, existing pruning techniques have one or more of\nthe following limitations: 1) Additional energy cost on top of the compute\nheavy training stage due to pruning and fine-tuning stages, 2) Layer-wise\npruning based on the statistics of a particular, ignoring the effect of error\npropagation in the network, 3) Lack of an efficient estimate for determining\nthe important channels globally, 4) Unstructured pruning requires specialized\nhardware for effective use. To address all the above issues, we present a\nsimple-yet-effective gradual channel pruning while training methodology using a\nnovel data-driven metric referred to as feature relevance score. The proposed\ntechnique gets rid of the additional retraining cycles by pruning the least\nimportant channels in a structured fashion at fixed intervals during the actual\ntraining phase. Feature relevance scores help in efficiently evaluating the\ncontribution of each channel towards the discriminative power of the network.\nWe demonstrate the effectiveness of the proposed methodology on architectures\nsuch as VGG and ResNet using datasets such as CIFAR-10, CIFAR-100 and ImageNet,\nand successfully achieve significant model compression while trading off less\nthan $1\\%$ accuracy. Notably on CIFAR-10 dataset trained on ResNet-110, our\napproach achieves $2.4\\times$ compression and a $56\\%$ reduction in FLOPs with\nan accuracy drop of $0.01\\%$ compared to the unpruned network.",
          "arxiv_id": "2002.09958v2"
        },
        {
          "title": "Integrating Pruning with Quantization for Efficient Deep Neural Networks Compression",
          "year": "2025-09",
          "abstract": "Deep Neural Networks (DNNs) have achieved significant advances in a wide\nrange of applications. However, their deployment on resource-constrained\ndevices remains a challenge due to the large number of layers and parameters,\nwhich result in considerable computational and memory demands. To address this\nissue, pruning and quantization are two widely used compression techniques,\ncommonly applied individually in most studies to reduce model size and enhance\nprocessing speed. Nevertheless, combining these two techniques can yield even\ngreater compression benefits. Effectively integrating pruning and quantization\nto harness their complementary advantages poses a challenging task, primarily\ndue to their potential impact on model accuracy and the complexity of jointly\noptimizing both processes. In this paper, we propose two approaches that\nintegrate similarity-based filter pruning with Adaptive Power-of-Two (APoT)\nquantization to achieve higher compression efficiency while preserving model\naccuracy. In the first approach, pruning and quantization are applied\nsimultaneously during training. In the second approach, pruning is performed\nfirst to remove less important parameters, followed by quantization of the\npruned model using low-bit representations. Experimental results demonstrate\nthat our proposed approaches achieve effective model compression with minimal\naccuracy degradation, making them well-suited for deployment on devices with\nlimited computational resources.",
          "arxiv_id": "2509.04244v1"
        },
        {
          "title": "EDropout: Energy-Based Dropout and Pruning of Deep Neural Networks",
          "year": "2020-06",
          "abstract": "Dropout is a well-known regularization method by sampling a sub-network from\na larger deep neural network and training different sub-networks on different\nsubsets of the data. Inspired by the dropout concept, we propose EDropout as an\nenergy-based framework for pruning neural networks in classification tasks. In\nthis approach, a set of binary pruning state vectors (population) represents a\nset of corresponding sub-networks from an arbitrary provided original neural\nnetwork. An energy loss function assigns a scalar energy loss value to each\npruning state. The energy-based model stochastically evolves the population to\nfind states with lower energy loss. The best pruning state is then selected and\napplied to the original network. Similar to dropout, the kept weights are\nupdated using backpropagation in a probabilistic model. The energy-based model\nagain searches for better pruning states and the cycle continuous. Indeed, this\nprocedure is in fact switching between the energy model, which manages the\npruning states, and the probabilistic model, which updates the temporarily\nunpruned weights, in each iteration. The population can dynamically converge to\na pruning state. This can be interpreted as dropout leading to pruning the\nnetwork. From an implementation perspective, EDropout can prune typical neural\nnetworks without modification of the network architecture. We evaluated the\nproposed method on different flavours of ResNets, AlexNet, and SqueezeNet on\nthe Kuzushiji, Fashion, CIFAR-10, CIFAR-100, and Flowers datasets, and compared\nthe pruning rate and classification performance of the models. On average the\nnetworks trained with EDropout achieved a pruning rate of more than $50\\%$ of\nthe trainable parameters with approximately $<5\\%$ and $<1\\%$ drop of Top-1 and\nTop-5 classification accuracy, respectively.",
          "arxiv_id": "2006.04270v5"
        }
      ],
      "10": [
        {
          "title": "A Dimension-Augmented Physics-Informed Neural Network (DaPINN) with High Level Accuracy and Efficiency",
          "year": "2022-10",
          "abstract": "Physics-informed neural networks (PINNs) have been widely applied in\ndifferent fields due to their effectiveness in solving partial differential\nequations (PDEs). However, the accuracy and efficiency of PINNs need to be\nconsiderably improved for scientific and commercial use. To address this issue,\nwe systematically propose a novel dimension-augmented physics-informed neural\nnetwork (DaPINN), which simultaneously and significantly improves the accuracy\nand efficiency of the PINN. In the DaPINN model, we introduce inductive bias in\nthe neural network to enhance network generalizability by adding a special\nregularization term to the loss function. Furthermore, we manipulate the\nnetwork input dimension by inserting additional sample features and\nincorporating the expanded dimensionality in the loss function. Moreover, we\nverify the effectiveness of power series augmentation, Fourier series\naugmentation and replica augmentation, in both forward and backward problems.\nIn most experiments, the error of DaPINN is 1$\\sim$2 orders of magnitude lower\nthan that of PINN. The results show that the DaPINN outperforms the original\nPINN in terms of both accuracy and efficiency with a reduced dependence on the\nnumber of sample points. We also discuss the complexity of the DaPINN and its\ncompatibility with other methods.",
          "arxiv_id": "2210.13212v1"
        },
        {
          "title": "Efficient Discrete Physics-informed Neural Networks for Addressing Evolutionary Partial Differential Equations",
          "year": "2023-12",
          "abstract": "Physics-informed neural networks (PINNs) have shown promising potential for\nsolving partial differential equations (PDEs) using deep learning. However,\nPINNs face training difficulties for evolutionary PDEs, particularly for\ndynamical systems whose solutions exhibit multi-scale or turbulent behavior\nover time. The reason is that PINNs may violate the temporal causality property\nsince all the temporal features in the PINNs loss are trained simultaneously.\nThis paper proposes to use implicit time differencing schemes to enforce\ntemporal causality, and use transfer learning to sequentially update the PINNs\nin space as surrogates for PDE solutions in different time frames. The evolving\nPINNs are better able to capture the varying complexities of the evolutionary\nequations, while only requiring minor updates between adjacent time frames. Our\nmethod is theoretically proven to be convergent if the time step is small and\neach PINN in different time frames is well-trained. In addition, we provide\nstate-of-the-art (SOTA) numerical results for a variety of benchmarks for which\nexisting PINNs formulations may fail or be inefficient. We demonstrate that the\nproposed method improves the accuracy of PINNs approximation for evolutionary\nPDEs and improves efficiency by a factor of 4-40x.",
          "arxiv_id": "2312.14608v1"
        },
        {
          "title": "Discovering Physics-Informed Neural Networks Model for Solving Partial Differential Equations through Evolutionary Computation",
          "year": "2024-05",
          "abstract": "In recent years, the researches about solving partial differential equations\n(PDEs) based on artificial neural network have attracted considerable\nattention. In these researches, the neural network models are usually designed\ndepend on human experience or trial and error. Despite the emergence of several\nmodel searching methods, these methods primarily concentrate on optimizing the\nhyperparameters of fully connected neural network model based on the framework\nof physics-informed neural networks (PINNs), and the corresponding search\nspaces are relatively restricted, thereby limiting the exploration of superior\nmodels. This article proposes an evolutionary computation method aimed at\ndiscovering the PINNs model with higher approximation accuracy and faster\nconvergence rate. In addition to searching the numbers of layers and neurons\nper hidden layer, this method concurrently explores the optimal shortcut\nconnections between the layers and the novel parametric activation functions\nexpressed by the binary trees. In evolution, the strategy about dynamic\npopulation size and training epochs (DPSTE) is adopted, which significantly\nincreases the number of models to be explored and facilitates the discovery of\nmodels with fast convergence rate. In experiments, the performance of different\nmodels that are searched through Bayesian optimization, random search and\nevolution is compared in solving Klein-Gordon, Burgers, and Lam\\'e equations.\nThe experimental results affirm that the models discovered by the proposed\nevolutionary computation method generally exhibit superior approximation\naccuracy and convergence rate, and these models also show commendable\ngeneralization performance with respect to the source term, initial and\nboundary conditions, equation coefficient and computational domain. The\ncorresponding code is available at\nhttps://github.com/MathBon/Discover-PINNs-Model.",
          "arxiv_id": "2405.11208v1"
        }
      ],
      "11": [
        {
          "title": "Deep Learning Neural Network for Lung Cancer Classification: Enhanced Optimization Function",
          "year": "2022-08",
          "abstract": "Background and Purpose: Convolutional neural network is widely used for image\nrecognition in the medical area at nowadays. However, overall accuracy in\npredicting lung tumor is low and the processing time is high as the error\noccurred while reconstructing the CT image. The aim of this work is to increase\nthe overall prediction accuracy along with reducing processing time by using\nmultispace image in pooling layer of convolution neural network. Methodology:\nThe proposed method has the autoencoder system to improve the overall accuracy,\nand to predict lung cancer by using multispace image in pooling layer of\nconvolution neural network and Adam Algorithm for optimization. First, the CT\nimages were pre-processed by feeding image to the convolution filter and down\nsampled by using max pooling. Then, features are extracted using the\nautoencoder model based on convolutional neural network and multispace image\nreconstruction technique is used to reduce error while reconstructing the image\nwhich then results improved accuracy to predict lung nodule. Finally, the\nreconstructed images are taken as input for SoftMax classifier to classify the\nCT images. Results: The state-of-art and proposed solutions were processed in\nPython Tensor Flow and It provides significant increase in accuracy in\nclassification of lung cancer to 99.5 from 98.9 and decrease in processing time\nfrom 10 frames/second to 12 seconds/second. Conclusion: The proposed solution\nprovides high classification accuracy along with less processing time compared\nto the state of art. For future research, large dataset can be implemented, and\nlow pixel image can be processed to evaluate the classification",
          "arxiv_id": "2208.06353v1"
        },
        {
          "title": "Coronavirus (COVID-19) Classification using Deep Features Fusion and Ranking Technique",
          "year": "2020-04",
          "abstract": "Coronavirus (COVID-19) emerged towards the end of 2019. World Health\nOrganization (WHO) was identified it as a global epidemic. Consensus occurred\nin the opinion that using Computerized Tomography (CT) techniques for early\ndiagnosis of pandemic disease gives both fast and accurate results. It was\nstated by expert radiologists that COVID-19 displays different behaviours in CT\nimages. In this study, a novel method was proposed as fusing and ranking deep\nfeatures to detect COVID-19 in early phase. 16x16 (Subset-1) and 32x32\n(Subset-2) patches were obtained from 150 CT images to generate sub-datasets.\nWithin the scope of the proposed method, 3000 patch images have been labelled\nas CoVID-19 and No finding for using in training and testing phase. Feature\nfusion and ranking method have been applied in order to increase the\nperformance of the proposed method. Then, the processed data was classified\nwith a Support Vector Machine (SVM). According to other pre-trained\nConvolutional Neural Network (CNN) models used in transfer learning, the\nproposed method shows high performance on Subset-2 with 98.27% accuracy, 98.93%\nsensitivity, 97.60% specificity, 97.63% precision, 98.28% F1-score and 96.54%\nMatthews Correlation Coefficient (MCC) metrics.",
          "arxiv_id": "2004.03698v1"
        },
        {
          "title": "Virtual vs. Reality: External Validation of COVID-19 Classifiers using XCAT Phantoms for Chest Computed Tomography",
          "year": "2022-03",
          "abstract": "Research studies of artificial intelligence models in medical imaging have\nbeen hampered by poor generalization. This problem has been especially\nconcerning over the last year with numerous applications of deep learning for\nCOVID-19 diagnosis. Virtual imaging trials (VITs) could provide a solution for\nobjective evaluation of these models. In this work utilizing the VITs, we\ncreated the CVIT-COVID dataset including 180 virtually imaged computed\ntomography (CT) images from simulated COVID-19 and normal phantom models under\ndifferent COVID-19 morphology and imaging properties. We evaluated the\nperformance of an open-source, deep-learning model from the University of\nWaterloo trained with multi-institutional data and an in-house model trained\nwith the open clinical dataset called MosMed. We further validated the model's\nperformance against open clinical data of 305 CT images to understand virtual\nvs. real clinical data performance. The open-source model was published with\nnearly perfect performance on the original Waterloo dataset but showed a\nconsistent performance drop in external testing on another clinical dataset\n(AUC=0.77) and our simulated CVIT-COVID dataset (AUC=0.55). The in-house model\nachieved an AUC of 0.87 while testing on the internal test set (MosMed test\nset). However, performance dropped to an AUC of 0.65 and 0.69 when evaluated on\nclinical and our simulated CVIT-COVID dataset. The VIT framework offered\ncontrol over imaging conditions, allowing us to show there was no change in\nperformance as CT exposure was changed from 28.5 to 57 mAs. The VIT framework\nalso provided voxel-level ground truth, revealing that performance of in-house\nmodel was much higher at AUC=0.87 for diffuse COVID-19 infection size >2.65%\nlung volume versus AUC=0.52 for focal disease with <2.65% volume. The virtual\nimaging framework enabled these uniquely rigorous analyses of model\nperformance.",
          "arxiv_id": "2203.03074v1"
        }
      ],
      "12": [
        {
          "title": "CARLA: Self-supervised Contrastive Representation Learning for Time Series Anomaly Detection",
          "year": "2023-08",
          "abstract": "One main challenge in time series anomaly detection (TSAD) is the lack of\nlabelled data in many real-life scenarios. Most of the existing anomaly\ndetection methods focus on learning the normal behaviour of unlabelled time\nseries in an unsupervised manner. The normal boundary is often defined tightly,\nresulting in slight deviations being classified as anomalies, consequently\nleading to a high false positive rate and a limited ability to generalise\nnormal patterns. To address this, we introduce a novel end-to-end\nself-supervised ContrAstive Representation Learning approach for time series\nAnomaly detection (CARLA). While existing contrastive learning methods assume\nthat augmented time series windows are positive samples and temporally distant\nwindows are negative samples, we argue that these assumptions are limited as\naugmentation of time series can transform them to negative samples, and a\ntemporally distant window can represent a positive sample. Our contrastive\napproach leverages existing generic knowledge about time series anomalies and\ninjects various types of anomalies as negative samples. Therefore, CARLA not\nonly learns normal behaviour but also learns deviations indicating anomalies.\nIt creates similar representations for temporally closed windows and distinct\nones for anomalies. Additionally, it leverages the information about\nrepresentations' neighbours through a self-supervised approach to classify\nwindows based on their nearest/furthest neighbours to further enhance the\nperformance of anomaly detection. In extensive tests on seven major real-world\ntime series anomaly detection datasets, CARLA shows superior performance over\nstate-of-the-art self-supervised and unsupervised TSAD methods. Our research\nshows the potential of contrastive representation learning to advance time\nseries anomaly detection.",
          "arxiv_id": "2308.09296v4"
        },
        {
          "title": "MAD: Self-Supervised Masked Anomaly Detection Task for Multivariate Time Series",
          "year": "2022-05",
          "abstract": "In this paper, we introduce Masked Anomaly Detection (MAD), a general\nself-supervised learning task for multivariate time series anomaly detection.\nWith the increasing availability of sensor data from industrial systems, being\nable to detecting anomalies from streams of multivariate time series data is of\nsignificant importance. Given the scarcity of anomalies in real-world\napplications, the majority of literature has been focusing on modeling\nnormality. The learned normal representations can empower anomaly detection as\nthe model has learned to capture certain key underlying data regularities. A\ntypical formulation is to learn a predictive model, i.e., use a window of time\nseries data to predict future data values. In this paper, we propose an\nalternative self-supervised learning task. By randomly masking a portion of the\ninputs and training a model to estimate them using the remaining ones, MAD is\nan improvement over the traditional left-to-right next step prediction (NSP)\ntask. Our experimental results demonstrate that MAD can achieve better anomaly\ndetection rates over traditional NSP approaches when using exactly the same\nneural network (NN) base models, and can be modified to run as fast as NSP\nmodels during test time on the same hardware, thus making it an ideal upgrade\nfor many existing NSP-based NN anomaly detection models.",
          "arxiv_id": "2205.02100v1"
        },
        {
          "title": "Online Evolutionary Neural Architecture Search for Multivariate Non-Stationary Time Series Forecasting",
          "year": "2023-02",
          "abstract": "Time series forecasting (TSF) is one of the most important tasks in data\nscience given the fact that accurate time series (TS) predictive models play a\nmajor role across a wide variety of domains including finance, transportation,\nhealth care, and power systems. Real-world utilization of machine learning (ML)\ntypically involves (pre-)training models on collected, historical data and then\napplying them to unseen data points. However, in real-world applications, time\nseries data streams are usually non-stationary and trained ML models usually,\nover time, face the problem of data or concept drift.\n  To address this issue, models must be periodically retrained or redesigned,\nwhich takes significant human and computational resources. Additionally,\nhistorical data may not even exist to re-train or re-design model with. As a\nresult, it is highly desirable that models are designed and trained in an\nonline fashion. This work presents the Online NeuroEvolution-based Neural\nArchitecture Search (ONE-NAS) algorithm, which is a novel neural architecture\nsearch method capable of automatically designing and dynamically training\nrecurrent neural networks (RNNs) for online forecasting tasks. Without any\npre-training, ONE-NAS utilizes populations of RNNs that are continuously\nupdated with new network structures and weights in response to new multivariate\ninput data. ONE-NAS is tested on real-world, large-scale multivariate wind\nturbine data as well as the univariate Dow Jones Industrial Average (DJIA)\ndataset. Results demonstrate that ONE-NAS outperforms traditional statistical\ntime series forecasting methods, including online linear regression, fixed long\nshort-term memory (LSTM) and gated recurrent unit (GRU) models trained online,\nas well as state-of-the-art, online ARIMA strategies.",
          "arxiv_id": "2302.10347v1"
        }
      ],
      "13": [
        {
          "title": "Oscillations enhance time-series prediction in reservoir computing with feedback",
          "year": "2024-06",
          "abstract": "Reservoir computing, a machine learning framework used for modeling the\nbrain, can predict temporal data with little observations and minimal\ncomputational resources. However, it is difficult to accurately reproduce the\nlong-term target time series because the reservoir system becomes unstable.\nThis predictive capability is required for a wide variety of time-series\nprocessing, including predictions of motor timing and chaotic dynamical\nsystems. This study proposes oscillation-driven reservoir computing (ODRC) with\nfeedback, where oscillatory signals are fed into a reservoir network to\nstabilize the network activity and induce complex reservoir dynamics. The ODRC\ncan reproduce long-term target time series more accurately than conventional\nreservoir computing methods in a motor timing and chaotic time-series\nprediction tasks. Furthermore, it generates a time series similar to the target\nin the unexperienced period, that is, it can learn the abstract generative\nrules from limited observations. Given these significant improvements made by\nthe simple and computationally inexpensive implementation, the ODRC would serve\nas a practical model of various time series data. Moreover, we will discuss\nbiological implications of the ODRC, considering it as a model of neural\noscillations and their cerebellar processors.",
          "arxiv_id": "2406.02867v1"
        },
        {
          "title": "Reservoir Computing Using Complex Systems",
          "year": "2022-12",
          "abstract": "Reservoir Computing is an emerging machine learning framework which is a\nversatile option for utilising physical systems for computation. In this paper,\nwe demonstrate how a single node reservoir, made of a simple electronic\ncircuit, can be employed for computation and explore the available options to\nimprove the computational capability of the physical reservoirs. We build a\nreservoir computing system using a memristive chaotic oscillator as the\nreservoir. We choose two of the available hyperparameters to find the optimal\nworking regime for the reservoir, resulting in two reservoir versions. We\ncompare the performance of both the reservoirs in a set of three non-temporal\ntasks: approximating two non-chaotic polynomials and a chaotic trajectory of\nthe Lorenz time series. We also demonstrate how the dynamics of the physical\nsystem plays a direct role in the reservoir's hyperparameters and hence in the\nreservoir's prediction ability.",
          "arxiv_id": "2212.11141v1"
        },
        {
          "title": "Stochastic Reservoir Computers",
          "year": "2024-05",
          "abstract": "Reservoir computing is a form of machine learning that utilizes nonlinear\ndynamical systems to perform complex tasks in a cost-effective manner when\ncompared to typical neural networks. Many recent advancements in reservoir\ncomputing, in particular quantum reservoir computing, make use of reservoirs\nthat are inherently stochastic. However, the theoretical justification for\nusing these systems has not yet been well established. In this paper, we\ninvestigate the universality of stochastic reservoir computers, in which we use\na stochastic system for reservoir computing using the probabilities of each\nreservoir state as the readout instead of the states themselves. In stochastic\nreservoir computing, the number of distinct states of the entire reservoir\ncomputer can potentially scale exponentially with the size of the reservoir\nhardware, offering the advantage of compact device size. We prove that classes\nof stochastic echo state networks, and therefore the class of all stochastic\nreservoir computers, are universal approximating classes. We also investigate\nthe performance of two practical examples of stochastic reservoir computers in\nclassification and chaotic time series prediction. While shot noise is a\nlimiting factor in the performance of stochastic reservoir computing, we show\nsignificantly improved performance compared to a deterministic reservoir\ncomputer with similar hardware in cases where the effects of noise are small.",
          "arxiv_id": "2405.12382v2"
        }
      ],
      "14": [
        {
          "title": "Graph Rewriting for Graph Neural Networks",
          "year": "2023-05",
          "abstract": "Given graphs as input, Graph Neural Networks (GNNs) support the inference of\nnodes, edges, attributes, or graph properties. Graph Rewriting investigates the\nrule-based manipulation of graphs to model complex graph transformations. We\npropose that, therefore, (i) graph rewriting subsumes GNNs and could serve as\nformal model to study and compare them, and (ii) the representation of GNNs as\ngraph rewrite systems can help to design and analyse GNNs, their architectures\nand algorithms. Hence we propose Graph Rewriting Neural Networks (GReNN) as\nboth novel semantic foundation and engineering discipline for GNNs. We develop\na case study reminiscent of a Message Passing Neural Network realised as a\nGroove graph rewriting model and explore its incremental operation in response\nto dynamic updates.",
          "arxiv_id": "2305.18632v1"
        },
        {
          "title": "SpeqNets: Sparsity-aware Permutation-equivariant Graph Networks",
          "year": "2022-03",
          "abstract": "While (message-passing) graph neural networks have clear limitations in\napproximating permutation-equivariant functions over graphs or general\nrelational data, more expressive, higher-order graph neural networks do not\nscale to large graphs. They either operate on $k$-order tensors or consider all\n$k$-node subgraphs, implying an exponential dependence on $k$ in memory\nrequirements, and do not adapt to the sparsity of the graph. By introducing new\nheuristics for the graph isomorphism problem, we devise a class of universal,\npermutation-equivariant graph networks, which, unlike previous architectures,\noffer a fine-grained control between expressivity and scalability and adapt to\nthe sparsity of the graph. These architectures lead to vastly reduced\ncomputation times compared to standard higher-order graph networks in the\nsupervised node- and graph-level classification and regression regime while\nsignificantly improving over standard graph neural network and graph kernel\narchitectures in terms of predictive performance.",
          "arxiv_id": "2203.13913v3"
        },
        {
          "title": "Get Rid of Suspended Animation Problem: Deep Diffusive Neural Network on Graph Semi-Supervised Classification",
          "year": "2020-01",
          "abstract": "Existing graph neural networks may suffer from the \"suspended animation\nproblem\" when the model architecture goes deep. Meanwhile, for some graph\nlearning scenarios, e.g., nodes with text/image attributes or graphs with\nlong-distance node correlations, deep graph neural networks will be necessary\nfor effective graph representation learning. In this paper, we propose a new\ngraph neural network, namely DIFNET (Graph Diffusive Neural Network), for graph\nrepresentation learning and node classification. DIFNET utilizes both neural\ngates and graph residual learning for node hidden state modeling, and includes\nan attention mechanism for node neighborhood information diffusion. Extensive\nexperiments will be done in this paper to compare DIFNET against several\nstate-of-the-art graph neural network models. The experimental results can\nillustrate both the learning performance advantages and effectiveness of\nDIFNET, especially in addressing the \"suspended animation problem\".",
          "arxiv_id": "2001.07922v1"
        }
      ],
      "15": [
        {
          "title": "Leave No Context Behind: Efficient Infinite Context Transformers with Infini-attention",
          "year": "2024-04",
          "abstract": "This work introduces an efficient method to scale Transformer-based Large\nLanguage Models (LLMs) to infinitely long inputs with bounded memory and\ncomputation. A key component in our proposed approach is a new attention\ntechnique dubbed Infini-attention. The Infini-attention incorporates a\ncompressive memory into the vanilla attention mechanism and builds in both\nmasked local attention and long-term linear attention mechanisms in a single\nTransformer block. We demonstrate the effectiveness of our approach on\nlong-context language modeling benchmarks, 1M sequence length passkey context\nblock retrieval and 500K length book summarization tasks with 1B and 8B LLMs.\nOur approach introduces minimal bounded memory parameters and enables fast\nstreaming inference for LLMs.",
          "arxiv_id": "2404.07143v2"
        },
        {
          "title": "Convolution-enhanced Evolving Attention Networks",
          "year": "2022-12",
          "abstract": "Attention-based neural networks, such as Transformers, have become ubiquitous\nin numerous applications, including computer vision, natural language\nprocessing, and time-series analysis. In all kinds of attention networks, the\nattention maps are crucial as they encode semantic dependencies between input\ntokens. However, most existing attention networks perform modeling or reasoning\nbased on representations , wherein the attention maps of different layers are\nlearned separately without explicit interactions. In this paper, we propose a\nnovel and generic evolving attention mechanism, which directly models the\nevolution of inter-token relationships through a chain of residual\nconvolutional modules. The major motivations are twofold. On the one hand, the\nattention maps in different layers share transferable knowledge, thus adding a\nresidual connection can facilitate the information flow of inter-token\nrelationships across layers. On the other hand, there is naturally an\nevolutionary trend among attention maps at different abstraction levels, so it\nis beneficial to exploit a dedicated convolution-based module to capture this\nprocess. Equipped with the proposed mechanism, the convolution-enhanced\nevolving attention networks achieve superior performance in various\napplications, including time-series representation, natural language\nunderstanding, machine translation, and image classification. Especially on\ntime-series representation tasks, Evolving Attention-enhanced Dilated\nConvolutional (EA-DC-) Transformer outperforms state-of-the-art models\nsignificantly, achieving an average of 17% improvement compared to the best\nSOTA. To the best of our knowledge, this is the first work that explicitly\nmodels the layer-wise evolution of attention maps. Our implementation is\navailable at https://github.com/pkuyym/EvolvingAttention.",
          "arxiv_id": "2212.08330v2"
        },
        {
          "title": "Memory Transformer",
          "year": "2020-06",
          "abstract": "Transformer-based models have achieved state-of-the-art results in many\nnatural language processing tasks. The self-attention architecture allows\ntransformer to combine information from all elements of a sequence into\ncontext-aware representations. However, information about the context is stored\nmostly in the same element-wise representations. This might limit the\nprocessing of properties related to the sequence as a whole more difficult.\nAdding trainable memory to selectively store local as well as global\nrepresentations of a sequence is a promising direction to improve the\nTransformer model. Memory-augmented neural networks (MANNs) extend traditional\nneural architectures with general-purpose memory for representations. MANNs\nhave demonstrated the capability to learn simple algorithms like Copy or\nReverse and can be successfully trained via backpropagation on diverse tasks\nfrom question answering to language modeling outperforming RNNs and LSTMs of\ncomparable complexity. In this work, we propose and study few extensions of the\nTransformer baseline (1) by adding memory tokens to store non-local\nrepresentations, (2) creating memory bottleneck for the global information, (3)\ncontrolling memory update with dedicated layer. We evaluate these memory\naugmented Transformers and demonstrate that presence of memory positively\ncorrelates with the model performance for machine translation and language\nmodelling tasks. Augmentation of pre-trained masked language model with memory\ntokens shows mixed results for tasks from GLUE benchmark. Visualization of\nattention patterns over the memory suggest that it improves the model's ability\nto process a global context.",
          "arxiv_id": "2006.11527v2"
        }
      ]
    }
  },
  "metadata": {
    "lastUpdated": "2025-09-25T19:41:30Z",
    "dataVersion": "0.0.2",
    "period": {
      "start": "2020-01",
      "end": "2025-09"
    }
  }
}