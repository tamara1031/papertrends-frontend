{
  "topics": {
    "data": {
      "0": {
        "name": "0_students_learning_education_student",
        "keywords": [
          [
            "students",
            0.033651390851473686
          ],
          [
            "learning",
            0.025232044284483834
          ],
          [
            "education",
            0.01807026132564623
          ],
          [
            "student",
            0.017925043522791815
          ],
          [
            "AI",
            0.01427385712951573
          ],
          [
            "educational",
            0.013742957478219416
          ],
          [
            "programming",
            0.011039462913692052
          ],
          [
            "course",
            0.010776863922762388
          ],
          [
            "study",
            0.010489326221734884
          ],
          [
            "teaching",
            0.009337055964558649
          ]
        ],
        "count": 2021
      },
      "1": {
        "name": "1_media_social_news_social media",
        "keywords": [
          [
            "media",
            0.023370288893242035
          ],
          [
            "social",
            0.02160409479683222
          ],
          [
            "news",
            0.019733633950074055
          ],
          [
            "social media",
            0.018082234495861743
          ],
          [
            "content",
            0.016915634044413593
          ],
          [
            "users",
            0.014990352957800804
          ],
          [
            "online",
            0.01476621165725551
          ],
          [
            "Twitter",
            0.01385176539973085
          ],
          [
            "misinformation",
            0.012864965711528516
          ],
          [
            "political",
            0.012407598602952083
          ]
        ],
        "count": 1389
      },
      "2": {
        "name": "2_data_urban_mobility_traffic",
        "keywords": [
          [
            "data",
            0.019887054967004613
          ],
          [
            "urban",
            0.019311595795764216
          ],
          [
            "mobility",
            0.015839176368587917
          ],
          [
            "traffic",
            0.01116188440297206
          ],
          [
            "model",
            0.010276212338603085
          ],
          [
            "spatial",
            0.00950300041092012
          ],
          [
            "study",
            0.00903350121911851
          ],
          [
            "time",
            0.00838171783245895
          ],
          [
            "cities",
            0.007969842324483676
          ],
          [
            "transportation",
            0.007467437050137554
          ]
        ],
        "count": 1299
      },
      "3": {
        "name": "3_fairness_fair_bias_Fairness",
        "keywords": [
          [
            "fairness",
            0.047250846568852305
          ],
          [
            "fair",
            0.01483778013788295
          ],
          [
            "bias",
            0.01471221804182077
          ],
          [
            "Fairness",
            0.013859825295133509
          ],
          [
            "learning",
            0.013433113557964053
          ],
          [
            "algorithmic",
            0.012740940763135805
          ],
          [
            "decision",
            0.01270034744269678
          ],
          [
            "data",
            0.011818102479165876
          ],
          [
            "model",
            0.011183260571616886
          ],
          [
            "algorithms",
            0.010608557477621629
          ]
        ],
        "count": 1272
      },
      "4": {
        "name": "4_AI_systems_risks_ethical",
        "keywords": [
          [
            "AI",
            0.06322784635847088
          ],
          [
            "systems",
            0.020224319588694164
          ],
          [
            "risks",
            0.014038094810345025
          ],
          [
            "ethical",
            0.012890717722782129
          ],
          [
            "governance",
            0.012813981610291911
          ],
          [
            "risk",
            0.011731219601150587
          ],
          [
            "human",
            0.011409206484234938
          ],
          [
            "intelligence",
            0.01130732813802192
          ],
          [
            "safety",
            0.011154514631643783
          ],
          [
            "ethics",
            0.01074659807182237
          ]
        ],
        "count": 1092
      },
      "5": {
        "name": "5_LLMs_language_models_LLM",
        "keywords": [
          [
            "LLMs",
            0.03303463201290916
          ],
          [
            "language",
            0.021057548609851685
          ],
          [
            "models",
            0.020348104228925214
          ],
          [
            "LLM",
            0.01782885510405756
          ],
          [
            "Language",
            0.01579876727626868
          ],
          [
            "human",
            0.014514516080731505
          ],
          [
            "Large",
            0.014261459922167131
          ],
          [
            "language models",
            0.013930345640905126
          ],
          [
            "Models",
            0.013167988901996245
          ],
          [
            "bias",
            0.012544699326384651
          ]
        ],
        "count": 1047
      },
      "6": {
        "name": "6_healthcare_health_clinical_data",
        "keywords": [
          [
            "healthcare",
            0.019192841692206628
          ],
          [
            "health",
            0.018677635011830906
          ],
          [
            "clinical",
            0.018494904505913554
          ],
          [
            "data",
            0.017876784011293362
          ],
          [
            "patient",
            0.015578682128901445
          ],
          [
            "medical",
            0.015224612586919825
          ],
          [
            "patients",
            0.014309097087417445
          ],
          [
            "model",
            0.012037686635969021
          ],
          [
            "learning",
            0.01203018403822783
          ],
          [
            "AI",
            0.011792445454821663
          ]
        ],
        "count": 686
      },
      "7": {
        "name": "7_privacy_security_data_cyber",
        "keywords": [
          [
            "privacy",
            0.02747171579474821
          ],
          [
            "security",
            0.023500918901252173
          ],
          [
            "data",
            0.02268735163221424
          ],
          [
            "cyber",
            0.017483125392372557
          ],
          [
            "cybersecurity",
            0.012780856161958348
          ],
          [
            "online",
            0.011806834472476583
          ],
          [
            "information",
            0.011164722081822547
          ],
          [
            "research",
            0.010983567895529782
          ],
          [
            "users",
            0.010397849717357101
          ],
          [
            "digital",
            0.010181106599411991
          ]
        ],
        "count": 561
      },
      "8": {
        "name": "8_blockchain_Blockchain_digital_decentralized",
        "keywords": [
          [
            "blockchain",
            0.04329394961052582
          ],
          [
            "Blockchain",
            0.022301692811520134
          ],
          [
            "digital",
            0.014352419219664354
          ],
          [
            "decentralized",
            0.013356933962506349
          ],
          [
            "technology",
            0.01302805723662675
          ],
          [
            "transactions",
            0.011553275435521537
          ],
          [
            "contracts",
            0.011502344362366579
          ],
          [
            "Bitcoin",
            0.011045977845012808
          ],
          [
            "NFT",
            0.010703072953138779
          ],
          [
            "data",
            0.01017704072042896
          ]
        ],
        "count": 495
      },
      "9": {
        "name": "9_AI_generative_Generative_models",
        "keywords": [
          [
            "AI",
            0.04431364182515224
          ],
          [
            "generative",
            0.03332193570447003
          ],
          [
            "Generative",
            0.02313840901982052
          ],
          [
            "models",
            0.014547616878532914
          ],
          [
            "creative",
            0.01254294533869796
          ],
          [
            "art",
            0.012379541679749976
          ],
          [
            "content",
            0.010268260097826906
          ],
          [
            "human",
            0.009558142849790213
          ],
          [
            "copyright",
            0.009439894924592839
          ],
          [
            "creativity",
            0.009292508694763656
          ]
        ],
        "count": 344
      },
      "10": {
        "name": "10_images_image_models_face",
        "keywords": [
          [
            "images",
            0.03170419201450568
          ],
          [
            "image",
            0.028521064439168995
          ],
          [
            "models",
            0.023657554740413055
          ],
          [
            "face",
            0.018834593337239053
          ],
          [
            "bias",
            0.0161715177603732
          ],
          [
            "biases",
            0.014283832935737796
          ],
          [
            "datasets",
            0.013354339859818768
          ],
          [
            "recognition",
            0.013200991132216924
          ],
          [
            "facial",
            0.012820679614182559
          ],
          [
            "model",
            0.012696414204573354
          ]
        ],
        "count": 292
      },
      "11": {
        "name": "11_research_computing_carbon_technology",
        "keywords": [
          [
            "research",
            0.016809793317284726
          ],
          [
            "computing",
            0.015516859039136419
          ],
          [
            "carbon",
            0.014770441898545409
          ],
          [
            "technology",
            0.013519896319969221
          ],
          [
            "digital",
            0.013431462522073058
          ],
          [
            "energy",
            0.012911200234019215
          ],
          [
            "study",
            0.010789259968060334
          ],
          [
            "data",
            0.01042173806655859
          ],
          [
            "design",
            0.010147925852023591
          ],
          [
            "paper",
            0.010013856463854385
          ]
        ],
        "count": 263
      },
      "12": {
        "name": "12_health_LLMs_mental_mental health",
        "keywords": [
          [
            "health",
            0.027055759563193872
          ],
          [
            "LLMs",
            0.024752701835539657
          ],
          [
            "mental",
            0.02139639956117771
          ],
          [
            "mental health",
            0.020526945377905392
          ],
          [
            "medical",
            0.018884807795110477
          ],
          [
            "LLM",
            0.013897671817166639
          ],
          [
            "clinical",
            0.013518992435109446
          ],
          [
            "healthcare",
            0.013184025161492407
          ],
          [
            "language",
            0.013115651830901822
          ],
          [
            "models",
            0.012946822266670642
          ]
        ],
        "count": 218
      },
      "13": {
        "name": "13_privacy_data_FL_fairness",
        "keywords": [
          [
            "privacy",
            0.04953350127232037
          ],
          [
            "data",
            0.03279734746982002
          ],
          [
            "FL",
            0.024817677175816347
          ],
          [
            "fairness",
            0.0241711387483087
          ],
          [
            "DP",
            0.021425371756535323
          ],
          [
            "learning",
            0.021047528572237614
          ],
          [
            "Federated",
            0.0204689526913353
          ],
          [
            "federated",
            0.019384860160674814
          ],
          [
            "federated learning",
            0.01659544251855735
          ],
          [
            "model",
            0.015902026859202206
          ]
        ],
        "count": 199
      },
      "14": {
        "name": "14_VR_Metaverse_virtual_Reality",
        "keywords": [
          [
            "VR",
            0.046820772371821626
          ],
          [
            "Metaverse",
            0.035929364621249564
          ],
          [
            "virtual",
            0.029053151125764152
          ],
          [
            "Reality",
            0.025849741260701897
          ],
          [
            "reality",
            0.02479827748638848
          ],
          [
            "metaverse",
            0.022388414749472372
          ],
          [
            "immersive",
            0.019526715495990093
          ],
          [
            "Virtual",
            0.016907766568280507
          ],
          [
            "AR",
            0.015501614944506035
          ],
          [
            "technologies",
            0.014446416639272795
          ]
        ],
        "count": 184
      },
      "15": {
        "name": "15_energy_electricity_data_consumption",
        "keywords": [
          [
            "energy",
            0.04607610365806681
          ],
          [
            "electricity",
            0.018098507332775172
          ],
          [
            "data",
            0.017854874477856737
          ],
          [
            "consumption",
            0.015808503512001942
          ],
          [
            "The",
            0.013578367801674497
          ],
          [
            "grid",
            0.013513987579588905
          ],
          [
            "demand",
            0.013461383966640983
          ],
          [
            "smart",
            0.012058416282890902
          ],
          [
            "power",
            0.011694405871930772
          ],
          [
            "Energy",
            0.01125195843401932
          ]
        ],
        "count": 182
      },
      "16": {
        "name": "16_contact_tracing_contact tracing_privacy",
        "keywords": [
          [
            "contact",
            0.07301629758491088
          ],
          [
            "tracing",
            0.06947169641047603
          ],
          [
            "contact tracing",
            0.06586841516831693
          ],
          [
            "privacy",
            0.034863048125848686
          ],
          [
            "Contact",
            0.0226667207662651
          ],
          [
            "app",
            0.022072186248939342
          ],
          [
            "apps",
            0.020488838474984197
          ],
          [
            "Tracing",
            0.017513662791182678
          ],
          [
            "Bluetooth",
            0.015705706574423706
          ],
          [
            "pandemic",
            0.015154654559885565
          ]
        ],
        "count": 161
      },
      "17": {
        "name": "17_research_scientific_citations_papers",
        "keywords": [
          [
            "research",
            0.029479403822763033
          ],
          [
            "scientific",
            0.020900541528585146
          ],
          [
            "citations",
            0.01755144520086309
          ],
          [
            "papers",
            0.017198972779194393
          ],
          [
            "researchers",
            0.01620795034649559
          ],
          [
            "science",
            0.015830821854297836
          ],
          [
            "academic",
            0.015530394507238228
          ],
          [
            "citation",
            0.015365237384051867
          ],
          [
            "software",
            0.014761585297152192
          ],
          [
            "authors",
            0.014705853909458569
          ]
        ],
        "count": 155
      },
      "18": {
        "name": "18_XAI_explanations_AI_explainability",
        "keywords": [
          [
            "XAI",
            0.05152447973275958
          ],
          [
            "explanations",
            0.03763585736942267
          ],
          [
            "AI",
            0.032784651590973775
          ],
          [
            "explainability",
            0.02502398573754455
          ],
          [
            "explanation",
            0.02082140084839284
          ],
          [
            "systems",
            0.01733362864516732
          ],
          [
            "Explainable",
            0.015791945055785416
          ],
          [
            "explainable",
            0.01556133639937306
          ],
          [
            "decision",
            0.015434355726574454
          ],
          [
            "human",
            0.014367180725776509
          ]
        ],
        "count": 145
      }
    },
    "correlations": [
      [
        1.0,
        -0.7423394486399117,
        -0.7295501222356315,
        -0.7298981160178131,
        -0.7134784964781637,
        -0.7117674414888724,
        -0.7326138500772659,
        -0.7417253398481043,
        -0.7574041164895178,
        -0.6855863044651582,
        -0.7408951563500152,
        -0.7223298092490302,
        -0.7264715622792544,
        -0.6731850610736565,
        -0.7401161142660023,
        -0.7527900881571761,
        -0.7170868959561943,
        -0.7331933750006598,
        -0.7381536591989288
      ],
      [
        -0.7423394486399117,
        1.0,
        -0.5810380613526129,
        -0.7195297706543053,
        -0.7361912747976573,
        -0.7185889197373826,
        -0.7294367657400349,
        -0.7302876172940369,
        -0.7572713789358054,
        -0.7337558709916389,
        -0.7188311432757301,
        -0.726498774367738,
        -0.707132245715467,
        -0.7245114398288501,
        -0.7546819003154555,
        -0.7482052486734231,
        -0.5438001225762501,
        -0.7285231692576408,
        -0.7465102471944869
      ],
      [
        -0.7295501222356315,
        -0.5810380613526129,
        1.0,
        -0.7094229031050905,
        -0.7345796766175923,
        -0.7340465669152981,
        -0.49832450039277776,
        -0.5083899489420378,
        -0.7473931517934362,
        -0.743531825821373,
        -0.7261177698767081,
        -0.5344876200740459,
        -0.718126709205434,
        -0.5213391071909562,
        -0.7483609463380687,
        -0.5444044083592758,
        -0.27740279602003626,
        -0.7404094575281366,
        -0.7389611623526295
      ],
      [
        -0.7298981160178131,
        -0.7195297706543053,
        -0.7094229031050905,
        1.0,
        -0.6962411329509266,
        -0.7061725289343799,
        -0.5715898761305848,
        -0.7119377642736051,
        -0.7610675784659486,
        -0.7228217684033906,
        -0.7002683633585469,
        -0.7305104752243317,
        -0.7287236728472051,
        -0.5028356295341008,
        -0.7587057363453438,
        -0.7283569137734172,
        -0.7450515217540504,
        -0.7391832928350972,
        -0.6514672410322186
      ],
      [
        -0.7134784964781637,
        -0.7361912747976573,
        -0.7345796766175923,
        -0.6962411329509266,
        1.0,
        -0.673922070235913,
        -0.7070096415773603,
        -0.7160911780805496,
        -0.7541583757154919,
        -0.1731500857762838,
        -0.7105318581023186,
        -0.7147027103588885,
        -0.6928712481340114,
        -0.7000497471371804,
        -0.7479718865722986,
        -0.7285940822168016,
        -0.7504075806524919,
        -0.7215045132372453,
        -0.41757595668609404
      ],
      [
        -0.7117674414888724,
        -0.7185889197373826,
        -0.7340465669152981,
        -0.7061725289343799,
        -0.673922070235913,
        1.0,
        -0.7271336969232276,
        -0.7321218273306233,
        -0.7632334588573377,
        -0.6579980561002091,
        -0.5487189633854297,
        -0.7291856432547104,
        0.1044012604572841,
        -0.7167646773106017,
        -0.7587513555426026,
        -0.7403392509926696,
        -0.7487304017513493,
        -0.7266779417415374,
        -0.7127373216544856
      ],
      [
        -0.7326138500772659,
        -0.7294367657400349,
        -0.49832450039277776,
        -0.5715898761305848,
        -0.7070096415773603,
        -0.7271336969232276,
        1.0,
        -0.47894578443144054,
        -0.7479302807749307,
        -0.7242343848614987,
        -0.7114827042716395,
        -0.7146564893387848,
        -0.6191220625991609,
        -0.30251043852673337,
        -0.7567041987591057,
        -0.5316685215514381,
        -0.7183944963359323,
        -0.7340236429504972,
        -0.7205561704139715
      ],
      [
        -0.7417253398481043,
        -0.7302876172940369,
        -0.5083899489420378,
        -0.7119377642736051,
        -0.7160911780805496,
        -0.7321218273306233,
        -0.47894578443144054,
        1.0,
        -0.7293298451205394,
        -0.7292721471958226,
        -0.7301511805784948,
        -0.7154933650724637,
        -0.7321267896873321,
        -0.20249652666998494,
        -0.7459316657638628,
        -0.5142200692382031,
        -0.6901075039729778,
        -0.730663008435437,
        -0.738748086956745
      ],
      [
        -0.7574041164895178,
        -0.7572713789358054,
        -0.7473931517934362,
        -0.7610675784659486,
        -0.7541583757154919,
        -0.7632334588573377,
        -0.7479302807749307,
        -0.7293298451205394,
        1.0,
        -0.7603740513764857,
        -0.7627351017872226,
        -0.7353138350484978,
        -0.7609013965194381,
        -0.7402384330389844,
        -0.7388639218084387,
        -0.7393299244849207,
        -0.74925435421562,
        -0.7550670933695947,
        -0.7618942384051081
      ],
      [
        -0.6855863044651582,
        -0.7337558709916389,
        -0.743531825821373,
        -0.7228217684033906,
        -0.1731500857762838,
        -0.6579980561002091,
        -0.7242343848614987,
        -0.7292721471958226,
        -0.7603740513764857,
        1.0,
        -0.6787954427192014,
        -0.7309043218064538,
        -0.6817363328094075,
        -0.7155495970844683,
        -0.750936837032233,
        -0.7402487495060199,
        -0.7547292961031401,
        -0.7308290629251031,
        -0.4907422824481242
      ],
      [
        -0.7408951563500152,
        -0.7188311432757301,
        -0.7261177698767081,
        -0.7002683633585469,
        -0.7105318581023186,
        -0.5487189633854297,
        -0.7114827042716395,
        -0.7301511805784948,
        -0.7627351017872226,
        -0.6787954427192014,
        1.0,
        -0.7361681875321924,
        -0.7155594961327227,
        -0.711593267111235,
        -0.7577520620380984,
        -0.7417169750347318,
        -0.7371513782516392,
        -0.7414666824386424,
        -0.7330211984916599
      ],
      [
        -0.7223298092490302,
        -0.726498774367738,
        -0.5344876200740459,
        -0.7305104752243317,
        -0.7147027103588885,
        -0.7291856432547104,
        -0.7146564893387848,
        -0.7154933650724637,
        -0.7353138350484978,
        -0.7309043218064538,
        -0.7361681875321924,
        1.0,
        -0.7344872924093122,
        -0.7247251100810999,
        -0.743302842861308,
        -0.7139794955728835,
        -0.7448054344922765,
        -0.10920754391742948,
        -0.7378798810705345
      ],
      [
        -0.7264715622792544,
        -0.707132245715467,
        -0.718126709205434,
        -0.7287236728472051,
        -0.6928712481340114,
        0.1044012604572841,
        -0.6191220625991609,
        -0.7321267896873321,
        -0.7609013965194381,
        -0.6817363328094075,
        -0.7155594961327227,
        -0.7344872924093122,
        1.0,
        -0.720195492877133,
        -0.7550689493092743,
        -0.74112305076405,
        -0.7313428309104953,
        -0.7331007514924314,
        -0.7241783052091462
      ],
      [
        -0.6731850610736565,
        -0.7245114398288501,
        -0.5213391071909562,
        -0.5028356295341008,
        -0.7000497471371804,
        -0.7167646773106017,
        -0.30251043852673337,
        -0.20249652666998494,
        -0.7402384330389844,
        -0.7155495970844683,
        -0.711593267111235,
        -0.7247251100810999,
        -0.720195492877133,
        1.0,
        -0.7478542244067866,
        -0.5398373823011392,
        -0.6747624378537986,
        -0.7309644014414758,
        -0.7210146752997693
      ],
      [
        -0.7401161142660023,
        -0.7546819003154555,
        -0.7483609463380687,
        -0.7587057363453438,
        -0.7479718865722986,
        -0.7587513555426026,
        -0.7567041987591057,
        -0.7459316657638628,
        -0.7388639218084387,
        -0.750936837032233,
        -0.7577520620380984,
        -0.743302842861308,
        -0.7550689493092743,
        -0.7478542244067866,
        1.0,
        -0.7528729434392406,
        -0.7571652640062434,
        -0.7493298056260744,
        -0.7579695523544487
      ],
      [
        -0.7527900881571761,
        -0.7482052486734231,
        -0.5444044083592758,
        -0.7283569137734172,
        -0.7285940822168016,
        -0.7403392509926696,
        -0.5316685215514381,
        -0.5142200692382031,
        -0.7393299244849207,
        -0.7402487495060199,
        -0.7417169750347318,
        -0.7139794955728835,
        -0.74112305076405,
        -0.5398373823011392,
        -0.7528729434392406,
        1.0,
        -0.7452384297915282,
        -0.7455444926287795,
        -0.740542941786787
      ],
      [
        -0.7170868959561943,
        -0.5438001225762501,
        -0.27740279602003626,
        -0.7450515217540504,
        -0.7504075806524919,
        -0.7487304017513493,
        -0.7183944963359323,
        -0.6901075039729778,
        -0.74925435421562,
        -0.7547292961031401,
        -0.7371513782516392,
        -0.7448054344922765,
        -0.7313428309104953,
        -0.6747624378537986,
        -0.7571652640062434,
        -0.7452384297915282,
        1.0,
        -0.7473343191289978,
        -0.7562956580087614
      ],
      [
        -0.7331933750006598,
        -0.7285231692576408,
        -0.7404094575281366,
        -0.7391832928350972,
        -0.7215045132372453,
        -0.7266779417415374,
        -0.7340236429504972,
        -0.730663008435437,
        -0.7550670933695947,
        -0.7308290629251031,
        -0.7414666824386424,
        -0.10920754391742948,
        -0.7331007514924314,
        -0.7309644014414758,
        -0.7493298056260744,
        -0.7455444926287795,
        -0.7473343191289978,
        1.0,
        -0.7454333419003225
      ],
      [
        -0.7381536591989288,
        -0.7465102471944869,
        -0.7389611623526295,
        -0.6514672410322186,
        -0.41757595668609404,
        -0.7127373216544856,
        -0.7205561704139715,
        -0.738748086956745,
        -0.7618942384051081,
        -0.4907422824481242,
        -0.7330211984916599,
        -0.7378798810705345,
        -0.7241783052091462,
        -0.7210146752997693,
        -0.7579695523544487,
        -0.740542941786787,
        -0.7562956580087614,
        -0.7454333419003225,
        1.0
      ]
    ],
    "series": {
      "2020-01": [
        54,
        19,
        3,
        14,
        19,
        1,
        3,
        3,
        4,
        0,
        4,
        2,
        1,
        6,
        1,
        3,
        1,
        5,
        1
      ],
      "2020-02": [
        37,
        8,
        4,
        10,
        13,
        1,
        5,
        2,
        7,
        1,
        1,
        4,
        0,
        11,
        4,
        3,
        3,
        0,
        5
      ],
      "2020-03": [
        40,
        12,
        4,
        11,
        8,
        1,
        6,
        6,
        3,
        1,
        3,
        2,
        1,
        14,
        3,
        1,
        11,
        7,
        2
      ],
      "2020-04": [
        53,
        16,
        5,
        15,
        9,
        4,
        6,
        4,
        4,
        3,
        6,
        4,
        9,
        13,
        2,
        3,
        32,
        10,
        1
      ],
      "2020-05": [
        89,
        25,
        11,
        13,
        11,
        5,
        6,
        4,
        4,
        0,
        4,
        1,
        4,
        14,
        3,
        6,
        58,
        4,
        1
      ],
      "2020-06": [
        88,
        12,
        7,
        30,
        19,
        1,
        3,
        7,
        7,
        1,
        8,
        3,
        6,
        19,
        5,
        12,
        40,
        3,
        4
      ],
      "2020-07": [
        77,
        19,
        4,
        18,
        22,
        2,
        8,
        9,
        7,
        2,
        11,
        4,
        10,
        21,
        2,
        12,
        38,
        6,
        4
      ],
      "2020-08": [
        79,
        18,
        6,
        15,
        23,
        0,
        2,
        7,
        3,
        1,
        3,
        2,
        4,
        10,
        1,
        6,
        39,
        2,
        2
      ],
      "2020-09": [
        60,
        10,
        4,
        21,
        20,
        4,
        6,
        7,
        8,
        1,
        9,
        4,
        5,
        21,
        1,
        7,
        27,
        8,
        1
      ],
      "2020-10": [
        73,
        16,
        5,
        21,
        16,
        3,
        4,
        7,
        3,
        0,
        5,
        1,
        4,
        16,
        3,
        5,
        23,
        8,
        0
      ],
      "2020-11": [
        66,
        13,
        5,
        18,
        12,
        1,
        6,
        5,
        5,
        0,
        10,
        2,
        6,
        13,
        4,
        3,
        25,
        0,
        4
      ],
      "2020-12": [
        47,
        13,
        3,
        15,
        15,
        1,
        1,
        3,
        1,
        2,
        7,
        1,
        5,
        16,
        1,
        3,
        25,
        7,
        5
      ],
      "2021-01": [
        69,
        28,
        5,
        19,
        22,
        3,
        7,
        5,
        7,
        0,
        3,
        1,
        2,
        11,
        7,
        1,
        24,
        8,
        3
      ],
      "2021-02": [
        63,
        17,
        5,
        21,
        14,
        1,
        8,
        2,
        10,
        1,
        8,
        1,
        3,
        3,
        3,
        5,
        12,
        4,
        2
      ],
      "2021-03": [
        55,
        15,
        2,
        13,
        14,
        3,
        1,
        4,
        6,
        0,
        7,
        1,
        1,
        12,
        1,
        1,
        22,
        8,
        6
      ],
      "2021-04": [
        57,
        19,
        7,
        17,
        17,
        0,
        3,
        3,
        3,
        0,
        4,
        0,
        2,
        7,
        2,
        1,
        20,
        10,
        1
      ],
      "2021-05": [
        63,
        17,
        4,
        31,
        22,
        0,
        0,
        4,
        4,
        1,
        7,
        1,
        2,
        14,
        4,
        5,
        19,
        4,
        0
      ],
      "2021-06": [
        49,
        17,
        5,
        29,
        20,
        3,
        4,
        6,
        4,
        1,
        10,
        1,
        5,
        20,
        3,
        1,
        20,
        6,
        8
      ],
      "2021-07": [
        63,
        20,
        4,
        19,
        14,
        1,
        6,
        5,
        8,
        1,
        7,
        2,
        2,
        11,
        3,
        1,
        11,
        3,
        7
      ],
      "2021-08": [
        80,
        18,
        5,
        16,
        15,
        2,
        5,
        4,
        2,
        0,
        3,
        5,
        3,
        13,
        4,
        3,
        26,
        11,
        8
      ],
      "2021-09": [
        44,
        21,
        4,
        24,
        19,
        5,
        2,
        2,
        5,
        1,
        8,
        1,
        2,
        14,
        1,
        0,
        12,
        2,
        5
      ],
      "2021-10": [
        50,
        14,
        5,
        31,
        16,
        6,
        1,
        5,
        0,
        0,
        6,
        1,
        4,
        17,
        4,
        4,
        15,
        4,
        6
      ],
      "2021-11": [
        42,
        18,
        5,
        17,
        25,
        2,
        2,
        5,
        2,
        2,
        5,
        0,
        2,
        8,
        3,
        5,
        19,
        3,
        2
      ],
      "2021-12": [
        39,
        12,
        5,
        15,
        17,
        2,
        0,
        3,
        6,
        1,
        7,
        0,
        3,
        10,
        2,
        2,
        15,
        2,
        3
      ],
      "2022-01": [
        56,
        8,
        5,
        15,
        18,
        0,
        1,
        7,
        7,
        0,
        7,
        3,
        2,
        17,
        4,
        1,
        11,
        3,
        0
      ],
      "2022-02": [
        62,
        15,
        3,
        29,
        18,
        2,
        1,
        5,
        2,
        1,
        6,
        1,
        2,
        7,
        3,
        2,
        20,
        2,
        1
      ],
      "2022-03": [
        59,
        18,
        5,
        17,
        7,
        3,
        5,
        5,
        8,
        1,
        4,
        2,
        1,
        7,
        7,
        2,
        8,
        2,
        1
      ],
      "2022-04": [
        62,
        12,
        2,
        17,
        16,
        2,
        3,
        0,
        6,
        1,
        5,
        2,
        0,
        11,
        2,
        2,
        8,
        2,
        4
      ],
      "2022-05": [
        58,
        15,
        4,
        34,
        25,
        8,
        1,
        6,
        4,
        3,
        11,
        1,
        2,
        14,
        2,
        6,
        8,
        5,
        5
      ],
      "2022-06": [
        51,
        16,
        0,
        29,
        28,
        10,
        4,
        2,
        2,
        1,
        5,
        1,
        4,
        17,
        4,
        5,
        16,
        9,
        2
      ],
      "2022-07": [
        59,
        17,
        6,
        30,
        12,
        3,
        9,
        2,
        6,
        1,
        6,
        0,
        7,
        18,
        2,
        5,
        8,
        5,
        3
      ],
      "2022-08": [
        47,
        16,
        3,
        32,
        16,
        4,
        3,
        6,
        1,
        0,
        5,
        0,
        2,
        22,
        3,
        4,
        6,
        3,
        5
      ],
      "2022-09": [
        42,
        10,
        4,
        31,
        15,
        7,
        3,
        4,
        6,
        3,
        6,
        1,
        2,
        10,
        4,
        3,
        8,
        5,
        3
      ],
      "2022-10": [
        53,
        21,
        5,
        27,
        16,
        0,
        2,
        6,
        4,
        3,
        12,
        1,
        3,
        10,
        8,
        8,
        11,
        5,
        3
      ],
      "2022-11": [
        54,
        17,
        3,
        27,
        21,
        7,
        2,
        0,
        7,
        2,
        8,
        3,
        4,
        16,
        4,
        3,
        13,
        6,
        5
      ],
      "2022-12": [
        76,
        11,
        0,
        19,
        14,
        4,
        2,
        7,
        4,
        1,
        7,
        4,
        1,
        16,
        4,
        7,
        9,
        3,
        4
      ],
      "2023-01": [
        59,
        19,
        4,
        21,
        18,
        10,
        2,
        4,
        5,
        2,
        9,
        3,
        2,
        13,
        7,
        7,
        7,
        4,
        1
      ],
      "2023-02": [
        39,
        23,
        4,
        25,
        19,
        9,
        4,
        7,
        3,
        4,
        5,
        1,
        1,
        19,
        3,
        3,
        3,
        5,
        7
      ],
      "2023-03": [
        64,
        13,
        2,
        38,
        34,
        16,
        5,
        5,
        7,
        5,
        9,
        0,
        3,
        14,
        10,
        5,
        10,
        11,
        5
      ],
      "2023-04": [
        53,
        21,
        2,
        28,
        28,
        24,
        4,
        3,
        3,
        9,
        7,
        3,
        5,
        11,
        6,
        6,
        7,
        2,
        3
      ],
      "2023-05": [
        74,
        28,
        6,
        54,
        50,
        24,
        5,
        6,
        6,
        17,
        12,
        3,
        2,
        25,
        4,
        6,
        5,
        5,
        4
      ],
      "2023-06": [
        67,
        14,
        5,
        40,
        40,
        28,
        10,
        7,
        9,
        16,
        5,
        1,
        3,
        22,
        4,
        8,
        3,
        7,
        7
      ],
      "2023-07": [
        65,
        14,
        3,
        30,
        42,
        30,
        1,
        4,
        5,
        8,
        9,
        2,
        3,
        18,
        5,
        3,
        2,
        8,
        2
      ],
      "2023-08": [
        56,
        17,
        5,
        31,
        23,
        26,
        0,
        16,
        6,
        13,
        9,
        1,
        2,
        16,
        2,
        3,
        7,
        5,
        5
      ],
      "2023-09": [
        68,
        10,
        10,
        27,
        27,
        33,
        4,
        6,
        1,
        12,
        11,
        1,
        5,
        16,
        1,
        6,
        7,
        5,
        4
      ],
      "2023-10": [
        69,
        25,
        5,
        22,
        26,
        45,
        0,
        7,
        5,
        13,
        15,
        2,
        2,
        16,
        7,
        2,
        7,
        6,
        3
      ],
      "2023-11": [
        75,
        11,
        7,
        27,
        33,
        33,
        4,
        4,
        1,
        18,
        17,
        1,
        4,
        15,
        5,
        2,
        1,
        1,
        2
      ],
      "2023-12": [
        79,
        23,
        5,
        31,
        30,
        38,
        5,
        4,
        8,
        13,
        12,
        1,
        3,
        21,
        4,
        2,
        6,
        2,
        4
      ],
      "2024-01": [
        71,
        26,
        2,
        26,
        47,
        40,
        2,
        2,
        5,
        22,
        12,
        2,
        6,
        13,
        4,
        7,
        5,
        9,
        4
      ],
      "2024-02": [
        100,
        25,
        8,
        32,
        55,
        66,
        3,
        3,
        5,
        17,
        15,
        2,
        6,
        23,
        1,
        8,
        12,
        5,
        4
      ],
      "2024-03": [
        99,
        22,
        8,
        30,
        43,
        60,
        2,
        6,
        3,
        29,
        13,
        1,
        4,
        18,
        4,
        11,
        9,
        3,
        7
      ],
      "2024-04": [
        72,
        17,
        7,
        33,
        46,
        39,
        2,
        4,
        8,
        23,
        6,
        1,
        6,
        12,
        2,
        3,
        6,
        3,
        5
      ],
      "2024-05": [
        81,
        21,
        7,
        24,
        46,
        56,
        3,
        5,
        5,
        23,
        13,
        3,
        2,
        25,
        4,
        6,
        8,
        8,
        7
      ],
      "2024-06": [
        80,
        16,
        5,
        33,
        41,
        64,
        2,
        1,
        5,
        18,
        10,
        3,
        7,
        17,
        3,
        3,
        11,
        1,
        3
      ],
      "2024-07": [
        88,
        24,
        3,
        28,
        51,
        67,
        2,
        6,
        8,
        22,
        20,
        2,
        7,
        14,
        6,
        10,
        6,
        5,
        5
      ],
      "2024-08": [
        73,
        17,
        5,
        15,
        45,
        47,
        0,
        2,
        3,
        15,
        13,
        0,
        3,
        12,
        2,
        4,
        8,
        6,
        6
      ],
      "2024-09": [
        74,
        16,
        4,
        20,
        45,
        49,
        6,
        4,
        3,
        11,
        8,
        4,
        5,
        20,
        2,
        5,
        7,
        5,
        5
      ],
      "2024-10": [
        88,
        23,
        2,
        25,
        70,
        86,
        2,
        12,
        8,
        26,
        16,
        2,
        5,
        31,
        4,
        8,
        6,
        8,
        6
      ],
      "2024-11": [
        66,
        19,
        5,
        18,
        60,
        58,
        2,
        6,
        1,
        23,
        9,
        3,
        9,
        14,
        7,
        7,
        5,
        4,
        0
      ],
      "2024-12": [
        86,
        16,
        9,
        26,
        49,
        55,
        3,
        7,
        8,
        31,
        14,
        4,
        12,
        10,
        4,
        9,
        3,
        8,
        5
      ],
      "2025-01": [
        85,
        27,
        1,
        19,
        74,
        61,
        1,
        11,
        4,
        20,
        6,
        6,
        10,
        13,
        5,
        6,
        6,
        7,
        8
      ],
      "2025-02": [
        103,
        21,
        3,
        20,
        75,
        102,
        5,
        7,
        3,
        30,
        7,
        6,
        10,
        18,
        3,
        9,
        7,
        10,
        2
      ],
      "2025-03": [
        74,
        20,
        2,
        17,
        89,
        92,
        2,
        4,
        7,
        33,
        10,
        1,
        5,
        16,
        5,
        4,
        13,
        6,
        1
      ],
      "2025-04": [
        64,
        18,
        2,
        14,
        88,
        79,
        5,
        8,
        6,
        34,
        11,
        1,
        10,
        16,
        3,
        8,
        4,
        4,
        9
      ],
      "2025-05": [
        106,
        24,
        6,
        19,
        87,
        118,
        2,
        2,
        4,
        42,
        11,
        5,
        1,
        29,
        4,
        4,
        5,
        3,
        8
      ],
      "2025-06": [
        97,
        13,
        8,
        27,
        62,
        110,
        2,
        4,
        3,
        19,
        9,
        1,
        7,
        13,
        1,
        7,
        2,
        7,
        4
      ],
      "2025-07": [
        88,
        19,
        7,
        16,
        78,
        74,
        4,
        6,
        4,
        26,
        15,
        1,
        8,
        11,
        5,
        5,
        5,
        6,
        0
      ],
      "2025-08": [
        83,
        12,
        2,
        18,
        95,
        94,
        2,
        7,
        0,
        33,
        12,
        5,
        10,
        17,
        4,
        9,
        5,
        4,
        5
      ],
      "2025-09": [
        49,
        10,
        2,
        12,
        32,
        52,
        1,
        3,
        1,
        16,
        5,
        1,
        4,
        8,
        1,
        4,
        2,
        1,
        3
      ]
    },
    "papers": {
      "0": [
        {
          "title": "Combining Gamification and Intelligent Tutoring Systems in a Serious Game for Engineering Education",
          "year": "2023-05",
          "abstract": "We provide ongoing results from the development of a personalized learning\nsystem integrated into a serious game. Given limited instructor resources, the\nuse of computerized systems to help tutor students offers a way to provide\nhigher quality education and to improve educational efficacy. Personalized\nlearning systems like the one proposed in this paper offer an accessible\nsolution. Furthermore, by combining such a system with a serious game, students\nare further engaged in interacting with the system. The proposed learning\nsystem combines expert-driven structure and lesson planning with computational\nintelligence methods and gamification to provide students with a fun and\neducational experience. As the project is ongoing from past years, numerous\ndesign iterations have been made on the system based on feedback from students\nand classroom observations. Using computational intelligence, the system\nadaptively provides support to students based on data collected from both their\nin-game actions and by estimating their emotional state from webcam images. For\nour evaluation, we focus on student data gathered from in-classroom testing in\nrelevant courses, with both educational efficacy, results and student\nobservations. To demonstrate the effect of our proposed system, students in an\nearly electrical engineering course were instructed to interact with the system\nin place of a standard lab assignment. The system would then measure and help\nthem improve their background knowledge before allowing them to complete the\nlab assignment. As they played through the game, we observed their interactions\nwith the system to gather insights for future work. Additionally, we\ndemonstrate the system's educational efficacy through pre-post-test results\nfrom students who played the game with and without the personalized learning\nsystem.",
          "arxiv_id": "2305.16568v1"
        },
        {
          "title": "DK-PRACTICE: An Intelligent Educational Platform for Personalized Learning Content Recommendations Based on Students Knowledge State",
          "year": "2024-12",
          "abstract": "This study introduces DK-PRACTICE (Dynamic Knowledge Prediction and\nEducational Content Recommendation System), an intelligent online platform that\nleverages machine learning to provide personalized learning recommendations\nbased on student knowledge state. Students participate in a short, adaptive\nassessment using the question-and-answer method regarding key concepts in a\nspecific knowledge domain. The system dynamically selects the next question for\neach student based on the correctness and accuracy of their previous answers.\nAfter the test is completed, DK-PRACTICE analyzes students' interaction history\nto recommend learning materials to empower the student's knowledge state in\nidentified knowledge gaps. Both question selection and learning material\nrecommendations are based on machine learning models trained using anonymized\ndata from a real learning environment. To provide self-assessment and monitor\nlearning progress, DK-PRACTICE allows students to take two tests: one\npre-teaching and one post-teaching. After each test, a report is generated with\ndetailed results. In addition, the platform offers functions to visualize\nlearning progress based on recorded test statistics. DK-PRACTICE promotes\nadaptive and personalized learning by empowering students with self-assessment\ncapabilities and providing instructors with valuable information about\nstudents' knowledge levels. DK-PRACTICE can be extended to various educational\nenvironments and knowledge domains, provided the necessary data is available\naccording to the educational topics. A subsequent paper will present the\nmethodology for the experimental application and evaluation of the platform.",
          "arxiv_id": "2501.10373v1"
        },
        {
          "title": "Building Collaborative Learning: Exploring Social Annotation in Introductory Programming",
          "year": "2024-06",
          "abstract": "The increasing demand for software engineering education presents learning\nchallenges in courses due to the diverse range of topics that require practical\napplications, such as programming or software design, all of which are\nsupported by group work and interaction. Social Annotation (SA) is an approach\nto teaching that can enhance collaborative learning among students. In SA, both\nstudents and teachers utilize platforms like Feedback Fruits, Perusall, and\nDiigo to collaboratively annotate and discuss course materials. This approach\nencourages students to share their thoughts and answers with their peers,\nfostering a more interactive learning environment. We share our experience of\nimplementing social annotation via Perusall as a preparatory tool for lectures\nin an introductory programming course aimed at undergraduate students in\nSoftware Engineering. We report the impact of Perusall on the examination\nresults of 112 students. Our results show that 81% of students engaged in\nmeaningful social annotation successfully passed the course. Notably, the\nproportion of students passing the exam tends to rise as they complete more\nPerusall assignments. In contrast, only 56% of students who did not participate\nin Perusall discussions managed to pass the exam. We did not enforce mandatory\nPerusall participation in the course. Yet, the feedback from our course\nevaluation questionnaire reveals that most students ranked Perusall among their\nfavorite components of the course and that their interest in the subject has\nincreased.",
          "arxiv_id": "2407.10322v1"
        }
      ],
      "1": [
        {
          "title": "Ideological Fragmentation of the Social Media Ecosystem: From echo chambers to echo platforms",
          "year": "2024-11",
          "abstract": "The entertainment-driven nature of social media encourages users to engage\nwith like-minded individuals and consume content aligned with their beliefs,\nlimiting exposure to diverse perspectives. Simultaneously, users migrate\nbetween platforms, either due to moderation policies like de-platforming or in\nsearch of environments better suited to their preferences. These dynamics drive\nthe specialization of the social media ecosystem, shifting from internal echo\nchambers to \"echo platforms\"--entire platforms functioning as ideologically\nhomogeneous niches. To systematically analyze this phenomenon in political\ndiscussions, we propose a quantitative approach based on three key dimensions:\nplatform centrality, news consumption, and user base composition. We analyze\n117 million posts related to the 2020 US Presidential elections from nine\nsocial media platforms--Facebook, Reddit, Twitter, YouTube, BitChute, Gab,\nParler, Scored, and Voat. Our findings reveal significant differences among\nplatforms in their centrality within the ecosystem, the reliability of\ncirculated news, and the ideological diversity of their users, highlighting a\nclear divide between mainstream and alt-tech platforms. The latter occupy a\nperipheral role, feature a higher prevalence of unreliable content, and exhibit\ngreater ideological uniformity. These results highlight the key dimensions\nshaping the fragmentation and polarization of the social media landscape.",
          "arxiv_id": "2411.16826v2"
        },
        {
          "title": "Sensing the Pulse of the Pandemic: Geovisualizing the Demographic Disparities of Public Sentiment toward COVID-19 through Social Media",
          "year": "2023-03",
          "abstract": "Social media offers a unique lens to observe large-scale, spatial-temporal\npatterns of users reactions toward critical events. However, social media use\nvaries across demographics, with younger users being more prevalent compared to\nolder populations. This difference introduces biases in data\nrepresentativeness, and analysis based on social media without proper\nadjustment will lead to overlooking the voices of digitally marginalized\ncommunities and inaccurate estimations. This study explores solutions to\npinpoint and alleviate the demographic biases in social media analysis through\na case study estimating the public sentiment about COVID-19 using Twitter data.\nWe analyzed the pandemic-related Twitter data in the U.S. during 2020-2021 to\n(1) elucidate the uneven social media usage among demographic groups and the\ndisparities of their sentiments toward COVID-19, (2) construct an adjusted\npublic sentiment measurement based on social media, the Sentiment Adjusted by\nDemographics (SAD) index, to evaluate the spatiotemporal varying public\nsentiment toward COVID-19. The results show higher proportions of female and\nadolescent Twitter users expressing negative emotions to COVID-19. The SAD\nindex unveils that the public sentiment toward COVID-19 was most negative in\nJanuary and February 2020 and most positive in April 2020. Vermont and Wyoming\nwere the most positive and negative states toward COVID-19.",
          "arxiv_id": "2304.06120v2"
        },
        {
          "title": "News consumption and social media regulations policy",
          "year": "2021-06",
          "abstract": "Users online tend to consume information adhering to their system of beliefs\nand to ignore dissenting information. During the COVID-19 pandemic, users get\nexposed to a massive amount of information about a new topic having a high\nlevel of uncertainty. In this paper, we analyze two social media that enforced\nopposite moderation methods, Twitter and Gab, to assess the interplay between\nnews consumption and content regulation concerning COVID-19. We compare the two\nplatforms on about three million pieces of content analyzing user interaction\nwith respect to news articles. We first describe users' consumption patterns on\nthe two platforms focusing on the political leaning of news outlets. Finally,\nwe characterize the echo chamber effect by modeling the dynamics of users'\ninteraction networks. Our results show that the presence of moderation pursued\nby Twitter produces a significant reduction of questionable content, with a\nconsequent affiliation towards reliable sources in terms of engagement and\ncomments. Conversely, the lack of clear regulation on Gab results in the\ntendency of the user to engage with both types of content, showing a slight\npreference for the questionable ones which may account for a\ndissing/endorsement behavior. Twitter users show segregation towards reliable\ncontent with a uniform narrative. Gab, instead, offers a more heterogeneous\nstructure where users, independently of their leaning, follow people who are\nslightly polarized towards questionable news.",
          "arxiv_id": "2106.03924v1"
        }
      ],
      "2": [
        {
          "title": "Transition of car-based human-mobility in the pandemic era: Data insight from a cross-border region in Europe",
          "year": "2025-09",
          "abstract": "Many transport authorities are collecting and publishing almost real-time\nroad traffic data to meet the growing trend of massive open data, a vital\nresource for foresight decision support systems considering deep data insights.\nWe explored the spatio-temporal transitions in the cross-country road traffic\nvolumes in the context of modelling behavioural transitions in car-based human\nmobility. This study reports on individual car-based daily travel behaviour\ndetected, before (2018) and during the COVID pandemic (2020), between Germany\nand neighbouring countries. In the case of Luxembourg, the Bridges and Roads\nAuthority has installed a large digital traffic observatory infrastructure\nthrough the adoption of sensor-based IoT technologies, like other European\nmember states. Since 2016, they have provided high-performance data processing\nand published open data on the country's road traffic. The dataset contains an\nhourly traffic count for different vehicle types, daily for representative\nobservation points, followed by a major road network. The original dataset\ncontains significant missing entries, so comprehensive data harmonization was\nperformed. We observed the decrease in traffic volumes during pandemic factors\n(e.g. lockdowns and remote work) period by following global trend of reduced\npersonal mobility. The understanding the dynamic adaptive travel behaviours\nprovide a potential opportunity to generate the actionable insight including\ntemporal and spatial implications. This study demonstrates that the national\nopen traffic data products can have adoption potential to address cross-border\ninsights. In relevance to the net-zero carbon transition, further study should\nshed light on the interpolation and downscaling approaches at the comprehensive\nroad-network level for identifying pollution hot spots, causal link to\nfunctional landuse patterns and calculation of spatial influence area.",
          "arxiv_id": "2509.05166v2"
        },
        {
          "title": "Twitter, human mobility, and COVID-19",
          "year": "2020-06",
          "abstract": "The outbreak of COVID-19 highlights the need for a more harmonized, less\nprivacy-concerning, easily accessible approach to monitoring the human mobility\nthat has been proved to be associated with the viral transmission. In this\nstudy, we analyzed 587 million tweets worldwide to see how global collaborative\nefforts in reducing human mobility are reflected from the user-generated\ninformation at the global, country, and the U.S. state scale. Considering the\nmultifaceted nature of mobility, we propose two types of distance: the\nsingle-day distance and the cross-day distance. To quantify the responsiveness\nin certain geographical regions, we further propose a mobility-based responsive\nindex (MRI) that captures the overall degree of mobility changes within a time\nwindow. The results suggest that mobility patterns obtained from Twitter data\nare amendable to quantitatively reflect the mobility dynamics. Globally, the\nproposed two distances had greatly deviated from their baselines after March\n11, 2020, when WHO declared COVID-19 as a pandemic. The considerably less\nperiodicity after the declaration suggests that the protection measures have\nobviously affected people's travel routines. The country scale comparisons\nreveal the discrepancies in responsiveness, evidenced by the contrasting\nmobility patterns in different epidemic phases. We find that the triggers of\nmobility changes correspond well with the national announcements of mitigation\nmeasures. In the U.S., the influence of the COVID-19 pandemic on mobility is\ndistinct. However, the impacts varied substantially among states. The strong\nmobility recovering momentum is further fueled by the Black Lives Matter\nprotests, potentially fostering the second wave of infections in the U.S.",
          "arxiv_id": "2007.01100v1"
        },
        {
          "title": "Neural Embeddings of Urban Big Data Reveal Emergent Structures in Cities",
          "year": "2021-10",
          "abstract": "In this study, we propose using a neural embedding model-graph neural network\n(GNN)- that leverages the heterogeneous features of urban areas and their\ninteractions captured by human mobility network to obtain vector\nrepresentations of these areas. Using large-scale high-resolution mobility data\nsets from millions of aggregated and anonymized mobile phone users in 16\nmetropolitan counties in the United States, we demonstrate that our embeddings\nencode complex relationships among features related to urban components (such\nas distribution of facilities) and population attributes and activities. The\nspatial gradient in each direction from city center to suburbs is measured\nusing clustered representations and the shared characteristics among urban\nareas in the same cluster. Furthermore, we show that embeddings generated by a\nmodel trained on a different county can capture 50% to 60% of the emergent\nspatial structure in another county, allowing us to make cross-county\ncomparisons in a quantitative way. Our GNN-based framework overcomes the\nlimitations of previous methods used for examining spatial structures and is\nhighly scalable. The findings reveal non-linear relationships among urban\ncomponents and anisotropic spatial gradients in cities. Since the identified\nspatial structures and gradients capture the combined effects of various\nmechanisms, such as segregation, disparate facility distribution, and human\nmobility, the findings could help identify the limitations of the current city\nstructure to inform planning decisions and policies. Also, the model and\nfindings set the stage for a variety of research in urban planning, engineering\nand social science through integrated understanding of how the complex\ninteractions between urban components and population activities and attributes\nshape the spatial structures in cities.",
          "arxiv_id": "2110.12371v1"
        }
      ],
      "3": [
        {
          "title": "Escaping the Impossibility of Fairness: From Formal to Substantive Algorithmic Fairness",
          "year": "2021-07",
          "abstract": "Efforts to promote equitable public policy with algorithms appear to be\nfundamentally constrained by the \"impossibility of fairness\" (an\nincompatibility between mathematical definitions of fairness). This technical\nlimitation raises a central question about algorithmic fairness: How can\ncomputer scientists and policymakers support equitable policy reforms with\nalgorithms? In this article, I argue that promoting justice with algorithms\nrequires reforming the methodology of algorithmic fairness. First, I diagnose\nthe problems of the current methodology for algorithmic fairness, which I call\n\"formal algorithmic fairness.\" Because formal algorithmic fairness restricts\nanalysis to isolated decision-making procedures, it leads to the impossibility\nof fairness and to models that exacerbate oppression despite appearing \"fair.\"\nSecond, I draw on theories of substantive equality from law and philosophy to\npropose an alternative methodology, which I call \"substantive algorithmic\nfairness.\" Because substantive algorithmic fairness takes a more expansive\nscope of analysis, it enables an escape from the impossibility of fairness and\nprovides a rigorous guide for alleviating injustice with algorithms. In sum,\nsubstantive algorithmic fairness presents a new direction for algorithmic\nfairness: away from formal mathematical models of \"fair\" decision-making and\ntoward substantive evaluations of whether and how algorithms can promote\njustice in practice.",
          "arxiv_id": "2107.04642v10"
        },
        {
          "title": "On the Identification of Fair Auditors to Evaluate Recommender Systems based on a Novel Non-Comparative Fairness Notion",
          "year": "2020-09",
          "abstract": "Decision-support systems are information systems that offer support to\npeople's decisions in various applications such as judiciary, real-estate and\nbanking sectors. Lately, these support systems have been found to be\ndiscriminatory in the context of many practical deployments. In an attempt to\nevaluate and mitigate these biases, algorithmic fairness literature has been\nnurtured using notions of comparative justice, which relies primarily on\ncomparing two/more individuals or groups within the society that is supported\nby such systems. However, such a fairness notion is not very useful in the\nidentification of fair auditors who are hired to evaluate latent biases within\ndecision-support systems. As a solution, we introduce a paradigm shift in\nalgorithmic fairness via proposing a new fairness notion based on the principle\nof non-comparative justice. Assuming that the auditor makes fairness\nevaluations based on some (potentially unknown) desired properties of the\ndecision-support system, the proposed fairness notion compares the system's\noutcome with that of the auditor's desired outcome. We show that the proposed\nfairness notion also provides guarantees in terms of comparative fairness\nnotions by proving that any system can be deemed fair from the perspective of\ncomparative fairness (e.g. individual fairness and statistical parity) if it is\nnon-comparatively fair with respect to an auditor who has been deemed fair with\nrespect to the same fairness notions. We also show that the converse holds true\nin the context of individual fairness. A brief discussion is also presented\nregarding how our fairness notion can be used to identify fair and reliable\nauditors, and how we can use them to quantify biases in decision-support\nsystems.",
          "arxiv_id": "2009.04383v1"
        },
        {
          "title": "Accurate Fairness: Improving Individual Fairness without Trading Accuracy",
          "year": "2022-05",
          "abstract": "Accuracy and individual fairness are both crucial for trustworthy machine\nlearning, but these two aspects are often incompatible with each other so that\nenhancing one aspect may sacrifice the other inevitably with side effects of\ntrue bias or false fairness. We propose in this paper a new fairness criterion,\naccurate fairness, to align individual fairness with accuracy. Informally, it\nrequires the treatments of an individual and the individual's similar\ncounterparts to conform to a uniform target, i.e., the ground truth of the\nindividual. We prove that accurate fairness also implies typical group fairness\ncriteria over a union of similar sub-populations. We then present a Siamese\nfairness in-processing approach to minimize the accuracy and fairness losses of\na machine learning model under the accurate fairness constraints. To the best\nof our knowledge, this is the first time that a Siamese approach is adapted for\nbias mitigation. We also propose fairness confusion matrix-based metrics,\nfair-precision, fair-recall, and fair-F1 score, to quantify a trade-off between\naccuracy and individual fairness. Comparative case studies with popular\nfairness datasets show that our Siamese fairness approach can achieve on\naverage 1.02%-8.78% higher individual fairness (in terms of fairness through\nawareness) and 8.38%-13.69% higher accuracy, as well as 10.09%-20.57% higher\ntrue fair rate, and 5.43%-10.01% higher fair-F1 score, than the\nstate-of-the-art bias mitigation techniques. This demonstrates that our Siamese\nfairness approach can indeed improve individual fairness without trading\naccuracy. Finally, the accurate fairness criterion and Siamese fairness\napproach are applied to mitigate the possible service discrimination with a\nreal Ctrip dataset, by on average fairly serving 112.33% more customers\n(specifically, 81.29% more customers in an accurately fair way) than baseline\nmodels.",
          "arxiv_id": "2205.08704v2"
        }
      ],
      "4": [
        {
          "title": "Taking AI Welfare Seriously",
          "year": "2024-11",
          "abstract": "In this report, we argue that there is a realistic possibility that some AI\nsystems will be conscious and/or robustly agentic in the near future. That\nmeans that the prospect of AI welfare and moral patienthood, i.e. of AI systems\nwith their own interests and moral significance, is no longer an issue only for\nsci-fi or the distant future. It is an issue for the near future, and AI\ncompanies and other actors have a responsibility to start taking it seriously.\nWe also recommend three early steps that AI companies and other actors can\ntake: They can (1) acknowledge that AI welfare is an important and difficult\nissue (and ensure that language model outputs do the same), (2) start assessing\nAI systems for evidence of consciousness and robust agency, and (3) prepare\npolicies and procedures for treating AI systems with an appropriate level of\nmoral concern. To be clear, our argument in this report is not that AI systems\ndefinitely are, or will be, conscious, robustly agentic, or otherwise morally\nsignificant. Instead, our argument is that there is substantial uncertainty\nabout these possibilities, and so we need to improve our understanding of AI\nwelfare and our ability to make wise decisions about this issue. Otherwise\nthere is a significant risk that we will mishandle decisions about AI welfare,\nmistakenly harming AI systems that matter morally and/or mistakenly caring for\nAI systems that do not.",
          "arxiv_id": "2411.00986v1"
        },
        {
          "title": "Why do Experts Disagree on Existential Risk and P(doom)? A Survey of AI Experts",
          "year": "2025-01",
          "abstract": "The development of artificial general intelligence (AGI) is likely to be one\nof humanity's most consequential technological advancements. Leading AI labs\nand scientists have called for the global prioritization of AI safety citing\nexistential risks comparable to nuclear war. However, research on catastrophic\nrisks and AI alignment is often met with skepticism, even by experts.\nFurthermore, online debate over the existential risk of AI has begun to turn\ntribal (e.g. name-calling such as \"doomer\" or \"accelerationist\"). Until now, no\nsystematic study has explored the patterns of belief and the levels of\nfamiliarity with AI safety concepts among experts. I surveyed 111 AI experts on\ntheir familiarity with AI safety concepts, key objections to AI safety, and\nreactions to safety arguments. My findings reveal that AI experts cluster into\ntwo viewpoints -- an \"AI as controllable tool\" and an \"AI as uncontrollable\nagent\" perspective -- diverging in beliefs toward the importance of AI safety.\nWhile most experts (78%) agreed or strongly agreed that \"technical AI\nresearchers should be concerned about catastrophic risks\", many were unfamiliar\nwith specific AI safety concepts. For example, only 21% of surveyed experts had\nheard of \"instrumental convergence,\" a fundamental concept in AI safety\npredicting that advanced AI systems will tend to pursue common sub-goals (such\nas self-preservation). The least concerned participants were the least familiar\nwith concepts like this, suggesting that effective communication of AI safety\nshould begin with establishing clear conceptual foundations in the field.",
          "arxiv_id": "2502.14870v1"
        },
        {
          "title": "An International Consortium for Evaluations of Societal-Scale Risks from Advanced AI",
          "year": "2023-10",
          "abstract": "Given rapid progress toward advanced AI and risks from frontier AI systems\n(advanced AI systems pushing the boundaries of the AI capabilities frontier),\nthe creation and implementation of AI governance and regulatory schemes\ndeserves prioritization and substantial investment. However, the status quo is\nuntenable and, frankly, dangerous. A regulatory gap has permitted AI labs to\nconduct research, development, and deployment activities with minimal\noversight. In response, frontier AI system evaluations have been proposed as a\nway of assessing risks from the development and deployment of frontier AI\nsystems. Yet, the budding AI risk evaluation ecosystem faces significant\ncoordination challenges, such as a limited diversity of evaluators, suboptimal\nallocation of effort, and perverse incentives. This paper proposes a solution\nin the form of an international consortium for AI risk evaluations, comprising\nboth AI developers and third-party AI risk evaluators. Such a consortium could\nplay a critical role in international efforts to mitigate societal-scale risks\nfrom advanced AI, including in managing responsible scaling policies and\ncoordinated evaluation-based risk response. In this paper, we discuss the\ncurrent evaluation ecosystem and its shortcomings, propose an international\nconsortium for advanced AI risk evaluations, discuss issues regarding its\nimplementation, discuss lessons that can be learnt from previous international\ninstitutions and existing proposals for international AI governance\ninstitutions, and, finally, we recommend concrete steps to advance the\nestablishment of the proposed consortium: (i) solicit feedback from\nstakeholders, (ii) conduct additional research, (iii) conduct a workshop(s) for\nstakeholders, (iv) analyze feedback and create final proposal, (v) solicit\nfunding, and (vi) create a consortium.",
          "arxiv_id": "2310.14455v3"
        }
      ],
      "5": [
        {
          "title": "A Multi-LLM Debiasing Framework",
          "year": "2024-09",
          "abstract": "Large Language Models (LLMs) are powerful tools with the potential to benefit\nsociety immensely, yet, they have demonstrated biases that perpetuate societal\ninequalities. Despite significant advancements in bias mitigation techniques\nusing data augmentation, zero-shot prompting, and model fine-tuning, biases\ncontinuously persist, including subtle biases that may elude human detection.\nRecent research has shown a growing interest in multi-LLM approaches, which\nhave been demonstrated to be effective in improving the quality of reasoning\nand factuality in LLMs. Building on this approach, we propose a novel multi-LLM\ndebiasing framework aimed at reducing bias in LLMs. Our work is the first to\nintroduce and evaluate two distinct approaches within this framework for\ndebiasing LLMs: a centralized method, where the conversation is facilitated by\na single central LLM, and a decentralized method, where all models communicate\ndirectly. Our findings reveal that our multi-LLM framework significantly\nreduces bias in LLMs, outperforming the baseline method across several social\ngroups.",
          "arxiv_id": "2409.13884v1"
        },
        {
          "title": "Gender Bias of LLM in Economics: An Existentialism Perspective",
          "year": "2024-10",
          "abstract": "Large Language Models (LLMs), such as GPT-4 and BERT, have rapidly gained\ntraction in natural language processing (NLP) and are now integral to financial\ndecision-making. However, their deployment introduces critical challenges,\nparticularly in perpetuating gender biases that can distort decision-making\noutcomes in high-stakes economic environments. This paper investigates gender\nbias in LLMs through both mathematical proofs and empirical experiments using\nthe Word Embedding Association Test (WEAT), demonstrating that LLMs inherently\nreinforce gender stereotypes even without explicit gender markers. By comparing\nthe decision-making processes of humans and LLMs, we reveal fundamental\ndifferences: while humans can override biases through ethical reasoning and\nindividualized understanding, LLMs maintain bias as a rational outcome of their\nmathematical optimization on biased data. Our analysis proves that bias in LLMs\nis not an unintended flaw but a systematic result of their rational processing,\nwhich tends to preserve and amplify existing societal biases encoded in\ntraining data. Drawing on existentialist theory, we argue that LLM-generated\nbias reflects entrenched societal structures and highlights the limitations of\npurely technical debiasing methods. This research underscores the need for new\ntheoretical frameworks and interdisciplinary methodologies that address the\nethical implications of integrating LLMs into economic and financial\ndecision-making. We advocate for a reconceptualization of how LLMs influence\neconomic decisions, emphasizing the importance of incorporating human-like\nethical considerations into AI governance to ensure fairness and equity in\nAI-driven financial systems.",
          "arxiv_id": "2410.19775v1"
        },
        {
          "title": "Large Language Models as Instruments of Power: New Regimes of Autonomous Manipulation and Control",
          "year": "2024-05",
          "abstract": "Large language models (LLMs) can reproduce a wide variety of rhetorical\nstyles and generate text that expresses a broad spectrum of sentiments. This\ncapacity, now available at low cost, makes them powerful tools for manipulation\nand control. In this paper, we consider a set of underestimated societal harms\nmade possible by the rapid and largely unregulated adoption of LLMs. Rather\nthan consider LLMs as isolated digital artefacts used to displace this or that\narea of work, we focus on the large-scale computational infrastructure upon\nwhich they are instrumentalised across domains. We begin with discussion on how\nLLMs may be used to both pollute and uniformize information environments and\nhow these modalities may be leveraged as mechanisms of control. We then draw\nattention to several areas of emerging research, each of which compounds the\ncapabilities of LLMs as instruments of power. These include (i) persuasion\nthrough the real-time design of choice architectures in conversational\ninterfaces (e.g., via \"AI personas\"), (ii) the use of LLM-agents as\ncomputational models of human agents (e.g., \"silicon subjects\"), (iii) the use\nof LLM-agents as computational models of human agent populations (e.g.,\n\"silicon societies\") and finally, (iv) the combination of LLMs with\nreinforcement learning to produce controllable and steerable strategic dialogue\nmodels. We draw these strands together to discuss how these areas may be\ncombined to build LLM-based systems that serve as powerful instruments of\nindividual, social and political control via the simulation and disingenuous\n\"prediction\" of human behaviour, intent, and action.",
          "arxiv_id": "2405.03813v1"
        }
      ],
      "6": [
        {
          "title": "Integrating Information Technology in Healthcare: Recent Developments, Challenges, and Future Prospects for Urban and Regional Health",
          "year": "2023-07",
          "abstract": "The use of technology in healthcare has become increasingly popular in recent\nyears, with the potential to improve how healthcare is delivered, patient\noutcomes, and cost-effectiveness. This review paper provides an overview of how\ntechnology has been used in healthcare, particularly in cities and for\npersonalized medicine. The paper discusses different ways technology is being\nused in healthcare, such as electronic health records, telemedicine, remote\nmonitoring, medical imaging, wearable devices, and artificial intelligence. It\nalso looks at the challenges and problems that come with using technology in\nhealthcare, such as keeping patient data private and secure, making sure\ndifferent technology systems can work together, and ensuring patients are\ncomfortable using technology. In addition, the paper explores the potential of\ntechnology in healthcare, including improving how easily patients can get care,\nthe quality of care they receive, and the cost of care. It also talks about how\ntechnology can help personalize care to individual patients. Finally, the paper\nsummarizes the main points, makes recommendations for healthcare providers and\npolicymakers, and suggests directions for future research. Overall, this review\nshows how technology can be used to improve healthcare, while also\nacknowledging the challenges that come with using technology in this way.",
          "arxiv_id": "2307.16296v3"
        },
        {
          "title": "AI Approaches in Processing and Using Data in Personalized Medicine",
          "year": "2022-07",
          "abstract": "In modern dynamic constantly developing society, more and more people suffer\nfrom chronic and serious diseases and doctors and patients need special and\nsophisticated medical and health support. Accordingly, prominent health\nstakeholders have recognized the importance of development of such services to\nmake patients life easier. Such support requires the collection of huge amount\nof patients complex data like clinical, environmental, nutritional, daily\nactivities, variety of data from smart wearable devices, data from clothing\nequipped with sensors etc. Holistic patients data must be properly aggregated,\nprocessed, analyzed, and presented to the doctors and caregivers to recommend\nadequate treatment and actions to improve patients health related parameters\nand general wellbeing. Advanced artificial intelligence techniques offer the\nopportunity to analyze such big data, consume them, and derive new knowledge to\nsupport personalized medical decisions. New approaches like those based on\nadvanced machine learning, federated learning, transfer learning, explainable\nartificial intelligence open new paths for more quality use of health and\nmedical data in future. In this paper, we will present some crucial aspects and\ncharacteristic examples in the area of application of a range of artificial\nintelligence approaches in personalized medical decisions.",
          "arxiv_id": "2208.04698v1"
        },
        {
          "title": "Developing a Robust Computable Phenotype Definition Workflow to Describe Health and Disease in Observational Health Research",
          "year": "2023-03",
          "abstract": "Health informatics can inform decisions that practitioners, patients,\npolicymakers, and researchers need to make about health and disease. Health\ninformatics is built upon patient health data leading to the need to codify\npatient health information. Such standardization is required to compute\npopulation statistics (such as prevalence, incidence, etc.) that are common\nmetrics used in fields such as epidemiology. Reliable decision-making about\nhealth and disease rests on our ability to organize, analyze, and assess data\nrepositories that contain patient health data.\n  While standards exist to structure and analyze patient data across patient\ndata sources such as health information exchanges, clinical data repositories,\nand health data marketplaces, analogous best practices for rigorously defining\npatient populations in health informatics contexts do not exist. Codifying best\npractices for developing disease definitions could support the effective\ndevelopment of clinical guidelines, inform algorithms used in clinical decision\nsupport systems, and additional patient guidelines.\n  In this paper, we present a workflow for the development of phenotype\ndefinitions. This workflow presents a series of recommendations for defining\nhealth and disease. Various examples within this paper are presented to\ndemonstrate this workflow in health informatics contexts.",
          "arxiv_id": "2304.06504v1"
        }
      ],
      "7": [
        {
          "title": "Evaluating the Effects of Digital Privacy Regulations on User Trust",
          "year": "2024-09",
          "abstract": "In today's digital society, issues related to digital privacy have become\nincreasingly important. Issues such as data breaches result in misuse of data,\nfinancial loss, and cyberbullying, which leads to less user trust in digital\nservices. This research investigates the impact of digital privacy laws on user\ntrust by comparing the regulations in the Netherlands, Ghana, and Malaysia. The\nstudy employs a comparative case study method, involving interviews with\ndigital privacy law experts, IT educators, and consumers from each country. The\nmain findings reveal that while the General Data Protection Regulation (GDPR)\nin the Netherlands is strict, its practical impact is limited by enforcement\nchallenges. In Ghana, the Data Protection Act is underutilized due to low\npublic awareness and insufficient enforcement, leading to reliance on personal\nprotective measures. In Malaysia, trust in digital services is largely\ndependent on the security practices of individual platforms rather than the\nPersonal Data Protection Act. The study highlights the importance of public\nawareness, effective enforcement, and cultural considerations in shaping the\neffectiveness of digital privacy laws. Based on these insights, a\nrecommendation framework is proposed to enhance digital privacy practices, also\naiming to provide valuable guidance for policymakers, businesses, and citizens\nin navigating the challenges of digitalization.",
          "arxiv_id": "2409.02614v1"
        },
        {
          "title": "From Cyber Security Incident Management to Cyber Security Crisis Management in the European Union",
          "year": "2025-04",
          "abstract": "Incident management is a classical topic in cyber security. Recently, the\nEuropean Union (EU) has started to consider also the relation between cyber\nsecurity incidents and cyber security crises. These considerations and\npreparations, including those specified in the EU's new cyber security laws,\nconstitute the paper's topic. According to an analysis of the laws and\nassociated policy documents, (i) cyber security crises are equated in the EU to\nlarge-scale cyber security incidents that either exceed a handling capacity of\na single member state or affect at least two member states. For this and other\npurposes, (ii) the new laws substantially increase mandatory reporting about\ncyber security incidents, including but not limited to the large-scale\nincidents. Despite the laws and new governance bodies established by them,\nhowever, (iii) the working of actual cyber security crisis management remains\nunclear particularly at the EU-level. With these policy research results, the\npaper advances the domain of cyber security incident management research by\nelaborating how European law perceives cyber security crises and their relation\nto cyber security incidents, paving the way for many relevant further research\ntopics with practical relevance, whether theoretical, conceptual, or empirical.",
          "arxiv_id": "2504.14220v1"
        },
        {
          "title": "The Challenges and Impact of Privacy Policy Comprehension",
          "year": "2020-05",
          "abstract": "The new information and communication technology providers collect increasing\namounts of personal data, a lot of which is user generated. Unless use policies\nare privacy-friendly, this leaves users vulnerable to privacy risks such as\nexposure through public data visibility or intrusive commercialisation of their\ndata through secondary data use. Due to complex privacy policies, many users of\nonline services unwillingly agree to privacy-intruding practices. To give users\nmore control over their privacy, scholars and regulators have pushed for short,\nsimple, and prominent privacy policies. The premise has been that users will\nsee and comprehend such policies, and then rationally adjust their disclosure\nbehaviour. In this paper, on a use case of social network service site, we show\nthat this premise does not hold. We invited 214 regular Facebook users to join\na new fictitious social network. We experimentally manipulated the\nprivacy-friendliness of an unavoidable and simple privacy policy. Half of our\nparticipants miscomprehended even this transparent privacy policy. When privacy\nthreats of secondary data use were present, users remembered the policies as\nmore privacy-friendly than they actually were and unwittingly uploaded more\ndata. To mitigate such behavioural pitfalls we present design recommendations\nto improve the quality of informed consent.",
          "arxiv_id": "2005.08967v1"
        }
      ],
      "8": [
        {
          "title": "Protecting the Decentralized Future: An Exploration of Common Blockchain Attacks and their Countermeasures",
          "year": "2023-06",
          "abstract": "Blockchain technology transformed the digital sphere by providing a\ntransparent, secure, and decentralized platform for data security across a\nrange of industries, including cryptocurrencies and supply chain management.\nBlockchain's integrity and dependability have been jeopardized by the rising\nnumber of security threats, which have attracted cybercriminals as a target. By\nsummarizing suggested fixes, this research aims to offer a thorough analysis of\nmitigating blockchain attacks. The objectives of the paper include identifying\nweak blockchain attacks, evaluating various solutions, and determining how\neffective and effective they are at preventing these attacks. The study also\nhighlights how crucial it is to take into account the particular needs of every\nblockchain application. This study provides beneficial perspectives and\ninsights for blockchain researchers and practitioners, making it essential\nreading for those interested in current and future trends in blockchain\nsecurity research.",
          "arxiv_id": "2306.11884v1"
        },
        {
          "title": "Blockchain in Oil and Gas Supply Chain: A Literature Review from User Security and Privacy Perspective",
          "year": "2023-06",
          "abstract": "Blockchain's influence extends beyond finance, impacting diverse sectors such\nas real estate, oil and gas, and education. This extensive reach stems from\nblockchain's intrinsic ability to reliably manage digital transactions and\nsupply chains. Within the oil and gas sector, the merger of blockchain with\nsupply chain management and data handling is a notable trend. The supply chain\nencompasses several operations: extraction, transportation, trading, and\ndistribution of resources. Unfortunately, the current supply chain structure\nmisses critical features such as transparency, traceability, flexible trading,\nand secure data storage - all of which blockchain can provide. Nevertheless, it\nis essential to investigate blockchain's security and privacy in the oil and\ngas industry. Such scrutiny enables the smooth, secure, and usable execution of\ntransactions. For this purpose, we reviewed 124 peer-reviewed academic\npublications, conducting an in-depth analysis of 21 among them. We classified\nthe articles by their relevance to various phases of the supply chain flow:\nupstream, midstream, downstream, and data management. Despite blockchain's\npotential to address existing security and privacy voids in the supply chain,\nthere is a significant lack of practical implementation of blockchain\nintegration in oil and gas operations. This deficiency substantially challenges\nthe transition from conventional methods to a blockchain-centric approach.",
          "arxiv_id": "2306.16576v1"
        },
        {
          "title": "An Overview of Forks and Coordination in Blockchain Development",
          "year": "2021-02",
          "abstract": "Blockchain is a continuously developing technology that has made digital\ntransactions and related computing operations more transparent and secure\nthrough globally distributed and decentralized management of states, as well as\nthe strong immutability of blocks mined and transactions validated in a network\nenabled by the blockchain technology. This manuscript is aimed at elaborating\nthe concept of blockchain technology alongside its coordination and\nimplementation with other emerging technologies, such as smart contract, which\nworks with different blockchain frameworks, as well as enabling anonymous\ntransactions and decentralized consensus amongst different untrusting parties.\nThe discussion of blockchain forks is also covered in this manuscript,\ndepicting fork events created in the blockchain process, their brief history,\ntypes, and impacts upon the blockchain development and operation.",
          "arxiv_id": "2102.10006v1"
        }
      ],
      "9": [
        {
          "title": "Talkin' 'Bout AI Generation: Copyright and the Generative-AI Supply Chain",
          "year": "2023-09",
          "abstract": "\"Does generative AI infringe copyright?\" is an urgent question. It is also a\ndifficult question, for two reasons. First, \"generative AI\" is not just one\nproduct from one company. It is a catch-all name for a massive ecosystem of\nloosely related technologies, including conversational text chatbots like\nChatGPT, image generators like Midjourney and DALL-E, coding assistants like\nGitHub Copilot, and systems that compose music and create videos. These systems\nbehave differently and raise different legal issues. The second problem is that\ncopyright law is notoriously complicated, and generative-AI systems manage to\ntouch on a great many corners of it: authorship, similarity, direct and\nindirect liability, fair use, and licensing, among much else. These issues\ncannot be analyzed in isolation, because there are connections everywhere.\n  In this Article, we aim to bring order to the chaos. To do so, we introduce\nthe generative-AI supply chain: an interconnected set of stages that transform\ntraining data (millions of pictures of cats) into generations (a new,\npotentially never-seen-before picture of a cat that has never existed).\nBreaking down generative AI into these constituent stages reveals all of the\nplaces at which companies and users make choices that have copyright\nconsequences. It enables us to trace the effects of upstream technical designs\non downstream uses, and to assess who in these complicated sociotechnical\nsystems bears responsibility for infringement when it happens. Because we\nengage so closely with the technology of generative AI, we are able to shed\nmore light on the copyright questions. We do not give definitive answers as to\nwho should and should not be held liable. Instead, we identify the key\ndecisions that courts will need to make as they grapple with these issues, and\npoint out the consequences that would likely flow from different liability\nregimes.",
          "arxiv_id": "2309.08133v2"
        },
        {
          "title": "Generative AI is already widespread in the public sector",
          "year": "2024-01",
          "abstract": "Generative AI has the potential to transform how public services are\ndelivered by enhancing productivity and reducing time spent on bureaucracy.\nFurthermore, unlike other types of artificial intelligence, it is a technology\nthat has quickly become widely available for bottom-up adoption: essentially\nanyone can decide to make use of it in their day to day work. But to what\nextent is generative AI already in use in the public sector? Our survey of 938\npublic service professionals within the UK (covering education, health, social\nwork and emergency services) seeks to answer this question. We find that use of\ngenerative AI systems is already widespread: 45% of respondents were aware of\ngenerative AI usage within their area of work, while 22% actively use a\ngenerative AI system. Public sector professionals were positive about both\ncurrent use of the technology and its potential to enhance their efficiency and\nreduce bureaucratic workload in the future. For example, those working in the\nNHS thought that time spent on bureaucracy could drop from 50% to 30% if\ngenerative AI was properly exploited, an equivalent of one day per week (an\nenormous potential impact). Our survey also found a high amount of trust (61%)\naround generative AI outputs, and a low fear of replacement (16%). While\nrespondents were optimistic overall, areas of concern included feeling like the\nUK is missing out on opportunities to use AI to improve public services (76%),\nand only a minority of respondents (32%) felt like there was clear guidance on\ngenerative AI usage in their workplaces. In other words, it is clear that\ngenerative AI is already transforming the public sector, but uptake is\nhappening in a disorganised fashion without clear guidelines. The UK's public\nsector urgently needs to develop more systematic methods for taking advantage\nof the technology.",
          "arxiv_id": "2401.01291v1"
        },
        {
          "title": "Foregrounding Artist Opinions: A Survey Study on Transparency, Ownership, and Fairness in AI Generative Art",
          "year": "2024-01",
          "abstract": "Generative AI tools are used to create art-like outputs and sometimes aid in\nthe creative process. These tools have potential benefits for artists, but they\nalso have the potential to harm the art workforce and infringe upon artistic\nand intellectual property rights. Without explicit consent from artists,\nGenerative AI creators scrape artists' digital work to train Generative AI\nmodels and produce art-like outputs at scale. These outputs are now being used\nto compete with human artists in the marketplace as well as being used by some\nartists in their generative processes to create art. We surveyed 459 artists to\ninvestigate the tension between artists' opinions on Generative AI art's\npotential utility and harm. This study surveys artists' opinions on the utility\nand threat of Generative AI art models, fair practices in the disclosure of\nartistic works in AI art training models, ownership and rights of AI art\nderivatives, and fair compensation. Results show that a majority of artists\nbelieve creators should disclose what art is being used in AI training, that AI\noutputs should not belong to model creators, and express concerns about AI's\nimpact on the art workforce and who profits from their art. We hope the results\nof this work will further meaningful collaboration and alignment between the\nart community and Generative AI researchers and developers.",
          "arxiv_id": "2401.15497v5"
        }
      ],
      "10": [
        {
          "title": "The Impact of Racial Distribution in Training Data on Face Recognition Bias: A Closer Look",
          "year": "2022-11",
          "abstract": "Face recognition algorithms, when used in the real world, can be very useful,\nbut they can also be dangerous when biased toward certain demographics. So, it\nis essential to understand how these algorithms are trained and what factors\naffect their accuracy and fairness to build better ones. In this study, we shed\nsome light on the effect of racial distribution in the training data on the\nperformance of face recognition models. We conduct 16 different experiments\nwith varying racial distributions of faces in the training data. We analyze\nthese trained models using accuracy metrics, clustering metrics, UMAP\nprojections, face quality, and decision thresholds. We show that a uniform\ndistribution of races in the training datasets alone does not guarantee\nbias-free face recognition algorithms and how factors like face image quality\nplay a crucial role. We also study the correlation between the clustering\nmetrics and bias to understand whether clustering is a good indicator of bias.\nFinally, we introduce a metric called racial gradation to study the inter and\nintra race correlation in facial features and how they affect the learning\nability of the face recognition models. With this study, we try to bring more\nunderstanding to an essential element of face recognition training, the data. A\nbetter understanding of the impact of training data on the bias of face\nrecognition algorithms will aid in creating better datasets and, in turn,\nbetter face recognition systems.",
          "arxiv_id": "2211.14498v1"
        },
        {
          "title": "Exploring Social Bias in Downstream Applications of Text-to-Image Foundation Models",
          "year": "2023-12",
          "abstract": "Text-to-image diffusion models have been adopted into key commercial\nworkflows, such as art generation and image editing. Characterising the\nimplicit social biases they exhibit, such as gender and racial stereotypes, is\na necessary first step in avoiding discriminatory outcomes. While existing\nstudies on social bias focus on image generation, the biases exhibited in\nalternate applications of diffusion-based foundation models remain\nunder-explored. We propose methods that use synthetic images to probe two\napplications of diffusion models, image editing and classification, for social\nbias. Using our methodology, we uncover meaningful and significant\ninter-sectional social biases in \\textit{Stable Diffusion}, a state-of-the-art\nopen-source text-to-image model. Our findings caution against the uninformed\nadoption of text-to-image foundation models for downstream tasks and services.",
          "arxiv_id": "2312.10065v1"
        },
        {
          "title": "Identifying Implicit Social Biases in Vision-Language Models",
          "year": "2024-11",
          "abstract": "Vision-language models, like CLIP (Contrastive Language Image Pretraining),\nare becoming increasingly popular for a wide range of multimodal retrieval\ntasks. However, prior work has shown that large language and deep vision models\ncan learn historical biases contained in their training sets, leading to\nperpetuation of stereotypes and potential downstream harm. In this work, we\nconduct a systematic analysis of the social biases that are present in CLIP,\nwith a focus on the interaction between image and text modalities. We first\npropose a taxonomy of social biases called So-B-IT, which contains 374 words\ncategorized across ten types of bias. Each type can lead to societal harm if\nassociated with a particular demographic group. Using this taxonomy, we examine\nimages retrieved by CLIP from a facial image dataset using each word as part of\na prompt. We find that CLIP frequently displays undesirable associations\nbetween harmful words and specific demographic groups, such as retrieving\nmostly pictures of Middle Eastern men when asked to retrieve images of a\n\"terrorist\". Finally, we conduct an analysis of the source of such biases, by\nshowing that the same harmful stereotypes are also present in a large\nimage-text dataset used to train CLIP models for examples of biases that we\nfind. Our findings highlight the importance of evaluating and addressing bias\nin vision-language models, and suggest the need for transparency and\nfairness-aware curation of large pre-training datasets.",
          "arxiv_id": "2411.00997v1"
        }
      ],
      "11": [
        {
          "title": "Towards a Systematic Survey for Carbon Neutral Data Centers",
          "year": "2021-10",
          "abstract": "Data centers are carbon-intensive enterprises due to their massive energy\nconsumption, and it is estimated that data center industry will account for 8\\%\nof global carbon emissions by 2030. However, both technological and policy\ninstruments for reducing or even neutralizing data center carbon emissions have\nnot been thoroughly investigated. To bridge this gap, this survey paper\nproposes a roadmap towards carbon-neutral data centers that takes into account\nboth policy instruments and technological methodologies. We begin by presenting\nthe carbon footprint of data centers, as well as some insights into the major\nsources of carbon emissions. Following that, carbon neutrality plans for major\nglobal cloud providers are discussed to summarize current industrial efforts in\nthis direction. In what follows, we introduce the carbon market as a policy\ninstrument to explain how to offset data center carbon emissions in a\ncost-efficient manner. On the technological front, we propose achieving\ncarbon-neutral data centers by increasing renewable energy penetration,\nimproving energy efficiency, and boosting energy circulation simultaneously. A\ncomprehensive review of existing technologies on these three topics is\nelaborated subsequently. Based on this, a multi-pronged approach towards carbon\nneutrality is envisioned and a digital twin-powered industrial artificial\nintelligence (AI) framework is proposed to make this solution a reality.\nFurthermore, three key scientific challenges for putting such a framework in\nplace are discussed. Finally, several applications for this framework are\npresented to demonstrate its enormous potential.",
          "arxiv_id": "2110.09284v3"
        },
        {
          "title": "The Sunk Carbon Fallacy: Rethinking Carbon Footprint Metrics for Effective Carbon-Aware Scheduling",
          "year": "2024-10",
          "abstract": "The rapid increase in computing demand and its corresponding energy\nconsumption have focused attention on computing's impact on the climate and\nsustainability. Prior work proposes metrics that quantify computing's carbon\nfootprint across several lifecycle phases, including its supply chain,\noperation, and end-of-life. Industry uses these metrics to optimize the carbon\nfootprint of manufacturing hardware and running computing applications.\nUnfortunately, prior work on optimizing datacenters' carbon footprint often\nsuccumbs to the \\emph{sunk cost fallacy} by considering embodied carbon\nemissions (a sunk cost) when making operational decisions (i.e., job scheduling\nand placement), which leads to operational decisions that do not always reduce\nthe total carbon footprint.\n  In this paper, we evaluate carbon-aware job scheduling and placement on a\ngiven set of servers for a number of carbon accounting metrics. Our analysis\nreveals state-of-the-art carbon accounting metrics that include embodied carbon\nemissions when making operational decisions can actually increase the total\ncarbon footprint of executing a set of jobs. We study the factors that affect\nthe added carbon cost of such suboptimal decision-making. We then use a\nreal-world case study from a datacenter to demonstrate how the sunk carbon\nfallacy manifests itself in practice. Finally, we discuss the implications of\nour findings in better guiding effective carbon-aware scheduling in on-premise\nand cloud datacenters.",
          "arxiv_id": "2410.15087v1"
        },
        {
          "title": "Chasing Carbon: The Elusive Environmental Footprint of Computing",
          "year": "2020-10",
          "abstract": "Given recent algorithm, software, and hardware innovation, computing has\nenabled a plethora of new applications. As computing becomes increasingly\nubiquitous, however, so does its environmental impact. This paper brings the\nissue to the attention of computer-systems researchers. Our analysis, built on\nindustry-reported characterization, quantifies the environmental effects of\ncomputing in terms of carbon emissions. Broadly, carbon emissions have two\nsources: operational energy consumption, and hardware manufacturing and\ninfrastructure. Although carbon emissions from the former are decreasing thanks\nto algorithmic, software, and hardware innovations that boost performance and\npower efficiency, the overall carbon footprint of computer systems continues to\ngrow. This work quantifies the carbon output of computer systems to show that\nmost emissions related to modern mobile and data-center equipment come from\nhardware manufacturing and infrastructure. We therefore outline future\ndirections for minimizing the environmental impact of computing systems.",
          "arxiv_id": "2011.02839v1"
        }
      ],
      "12": [
        {
          "title": "Risks from Language Models for Automated Mental Healthcare: Ethics and Structure for Implementation",
          "year": "2024-04",
          "abstract": "Amidst the growing interest in developing task-autonomous AI for automated\nmental health care, this paper addresses the ethical and practical challenges\nassociated with the issue and proposes a structured framework that delineates\nlevels of autonomy, outlines ethical requirements, and defines beneficial\ndefault behaviors for AI agents in the context of mental health support. We\nalso evaluate fourteen state-of-the-art language models (ten off-the-shelf,\nfour fine-tuned) using 16 mental health-related questionnaires designed to\nreflect various mental health conditions, such as psychosis, mania, depression,\nsuicidal thoughts, and homicidal tendencies. The questionnaire design and\nresponse evaluations were conducted by mental health clinicians (M.D.s). We\nfind that existing language models are insufficient to match the standard\nprovided by human professionals who can navigate nuances and appreciate\ncontext. This is due to a range of issues, including overly cautious or\nsycophantic responses and the absence of necessary safeguards. Alarmingly, we\nfind that most of the tested models could cause harm if accessed in mental\nhealth emergencies, failing to protect users and potentially exacerbating\nexisting symptoms. We explore solutions to enhance the safety of current\nmodels. Before the release of increasingly task-autonomous AI systems in mental\nhealth, it is crucial to ensure that these models can reliably detect and\nmanage symptoms of common psychiatric disorders to prevent harm to users. This\ninvolves aligning with the ethical framework and default behaviors outlined in\nour study. We contend that model developers are responsible for refining their\nsystems per these guidelines to safeguard against the risks posed by current AI\ntechnologies to user mental health and safety.\n  Trigger warning: Contains and discusses examples of sensitive mental health\ntopics, including suicide and self-harm.",
          "arxiv_id": "2406.11852v2"
        },
        {
          "title": "Harnessing Large Language Models for Mental Health: Opportunities, Challenges, and Ethical Considerations",
          "year": "2024-12",
          "abstract": "Large Language Models (LLMs) are transforming mental health care by enhancing\naccessibility, personalization, and efficiency in therapeutic interventions.\nThese AI-driven tools empower mental health professionals with real-time\nsupport, improved data integration, and the ability to encourage care-seeking\nbehaviors, particularly in underserved communities. By harnessing LLMs,\npractitioners can deliver more empathetic, tailored, and effective support,\naddressing longstanding gaps in mental health service provision. However, their\nimplementation comes with significant challenges and ethical concerns.\nPerformance limitations, data privacy risks, biased outputs, and the potential\nfor generating misleading information underscore the critical need for\nstringent ethical guidelines and robust evaluation mechanisms. The sensitive\nnature of mental health data further necessitates meticulous safeguards to\nprotect patient rights and ensure equitable access to AI-driven care.\nProponents argue that LLMs have the potential to democratize mental health\nresources, while critics warn of risks such as misuse and the diminishment of\nhuman connection in therapy. Achieving a balance between innovation and ethical\nresponsibility is imperative. This paper examines the transformative potential\nof LLMs in mental health care, highlights the associated technical and ethical\ncomplexities, and advocates for a collaborative, multidisciplinary approach to\nensure these advancements align with the goal of providing compassionate,\nequitable, and effective mental health support.",
          "arxiv_id": "2501.10370v1"
        },
        {
          "title": "The opportunities and risks of large language models in mental health",
          "year": "2024-03",
          "abstract": "Global rates of mental health concerns are rising, and there is increasing\nrealization that existing models of mental health care will not adequately\nexpand to meet the demand. With the emergence of large language models (LLMs)\nhas come great optimism regarding their promise to create novel, large-scale\nsolutions to support mental health. Despite their nascence, LLMs have already\nbeen applied to mental health related tasks. In this paper, we summarize the\nextant literature on efforts to use LLMs to provide mental health education,\nassessment, and intervention and highlight key opportunities for positive\nimpact in each area. We then highlight risks associated with LLMs' application\nto mental health and encourage the adoption of strategies to mitigate these\nrisks. The urgent need for mental health support must be balanced with\nresponsible development, testing, and deployment of mental health LLMs. It is\nespecially critical to ensure that mental health LLMs are fine-tuned for mental\nhealth, enhance mental health equity, and adhere to ethical standards and that\npeople, including those with lived experience with mental health concerns, are\ninvolved in all stages from development through deployment. Prioritizing these\nefforts will minimize potential harms to mental health and maximize the\nlikelihood that LLMs will positively impact mental health globally.",
          "arxiv_id": "2403.14814v3"
        }
      ],
      "13": [
        {
          "title": "Training Fair Models in Federated Learning without Data Privacy Infringement",
          "year": "2021-09",
          "abstract": "Training fair machine learning models becomes more and more important. As\nmany powerful models are trained by collaboration among multiple parties, each\nholding some sensitive data, it is natural to explore the feasibility of\ntraining fair models in federated learning so that the fairness of trained\nmodels, the data privacy of clients, and the collaboration between clients can\nbe fully respected simultaneously. However, the task of training fair models in\nfederated learning is challenging, since it is far from trivial to estimate the\nfairness of a model without knowing the private data of the participating\nparties, which is often constrained by privacy requirements in federated\nlearning. In this paper, we first propose a federated estimation method to\naccurately estimate the fairness of a model without infringing the data privacy\nof any party. Then, we use the fairness estimation to formulate a novel problem\nof training fair models in federated learning. We develop FedFair, a\nwell-designed federated learning framework, which can successfully train a fair\nmodel with high performance without data privacy infringement. Our extensive\nexperiments on three real-world data sets demonstrate the excellent fair model\ntraining performance of our method.",
          "arxiv_id": "2109.05662v2"
        },
        {
          "title": "Fair Differentially Private Federated Learning Framework",
          "year": "2023-05",
          "abstract": "Federated learning (FL) is a distributed machine learning strategy that\nenables participants to collaborate and train a shared model without sharing\ntheir individual datasets. Privacy and fairness are crucial considerations in\nFL. While FL promotes privacy by minimizing the amount of user data stored on\ncentral servers, it still poses privacy risks that need to be addressed.\nIndustry standards such as differential privacy, secure multi-party\ncomputation, homomorphic encryption, and secure aggregation protocols are\nfollowed to ensure privacy in FL. Fairness is also a critical issue in FL, as\nmodels can inherit biases present in local datasets, leading to unfair\npredictions. Balancing privacy and fairness in FL is a challenge, as privacy\nrequires protecting user data while fairness requires representative training\ndata. This paper presents a \"Fair Differentially Private Federated Learning\nFramework\" that addresses the challenges of generating a fair global model\nwithout validation data and creating a globally private differential model. The\nframework employs clipping techniques for biased model updates and Gaussian\nmechanisms for differential privacy. The paper also reviews related works on\nprivacy and fairness in FL, highlighting recent advancements and approaches to\nmitigate bias and ensure privacy. Achieving privacy and fairness in FL requires\ncareful consideration of specific contexts and requirements, taking into\naccount the latest developments in industry standards and techniques.",
          "arxiv_id": "2305.13878v1"
        },
        {
          "title": "Advancing Personalized Federated Learning: Group Privacy, Fairness, and Beyond",
          "year": "2023-09",
          "abstract": "Federated learning (FL) is a framework for training machine learning models\nin a distributed and collaborative manner. During training, a set of\nparticipating clients process their data stored locally, sharing only the model\nupdates obtained by minimizing a cost function over their local inputs. FL was\nproposed as a stepping-stone towards privacy-preserving machine learning, but\nit has been shown vulnerable to issues such as leakage of private information,\nlack of personalization of the model, and the possibility of having a trained\nmodel that is fairer to some groups than to others. In this paper, we address\nthe triadic interaction among personalization, privacy guarantees, and fairness\nattained by models trained within the FL framework. Differential privacy and\nits variants have been studied and applied as cutting-edge standards for\nproviding formal privacy guarantees. However, clients in FL often hold very\ndiverse datasets representing heterogeneous communities, making it important to\nprotect their sensitive information while still ensuring that the trained model\nupholds the aspect of fairness for the users. To attain this objective, a\nmethod is put forth that introduces group privacy assurances through the\nutilization of $d$-privacy (aka metric privacy). $d$-privacy represents a\nlocalized form of differential privacy that relies on a metric-oriented\nobfuscation approach to maintain the original data's topological distribution.\nThis method, besides enabling personalized model training in a federated\napproach and providing formal privacy guarantees, possesses significantly\nbetter group fairness measured under a variety of standard metrics than a\nglobal model trained within a classical FL template. Theoretical justifications\nfor the applicability are provided, as well as experimental validation on\nreal-world datasets to illustrate the working of the proposed method.",
          "arxiv_id": "2309.00416v1"
        }
      ],
      "14": [
        {
          "title": "The Value Chain of Education Metaverse",
          "year": "2022-11",
          "abstract": "Since the end of 2021, the Metaverse has been booming. Many unknown\npossibilities are gradually being realized, but many people only determined\nthat they use Virtual Reality (VR), Augmented Reality (AR), and Mixed Reality\n(MR) in the Metaverse. It is even considered that as long as the above\nrealities (VR, AR, MR) are used, it is equal to the Metaverse. However, this is\nnot true, for Reality-based display tools are only one of the presentation\nmethods of the Metaverse. If we cannot return to the three main characteristics\nof the Metaverse: \"digital avatars,\" a decentralized \"consensus value system,\"\nand \"Immersive experience,\" the practice and imagination of the Metaverse will\nbecome very narrow. Since 2022, the concept of Metaverse has also been widely\nused in classroom teaching to integrate into teaching activities. Therefore, to\nprevent teachers and students from understanding the Metaverse not only in the\n\"Using VR, AR, MR is equivalent to Metaverse\" but also pay more attention to\nthe other two characteristics of the Metaverse: \"digital avatars\" and a\ndecentralized \"consensus value system.\"",
          "arxiv_id": "2211.05833v2"
        },
        {
          "title": "Wireless Edge-Empowered Metaverse: A Learning-Based Incentive Mechanism for Virtual Reality",
          "year": "2021-11",
          "abstract": "The Metaverse is regarded as the next-generation Internet paradigm that\nallows humans to play, work, and socialize in an alternative virtual world with\nimmersive experience, for instance, via head-mounted display for Virtual\nReality (VR) rendering. With the help of ubiquitous wireless connections and\npowerful edge computing technologies, VR users in wireless edge-empowered\nMetaverse can immerse in the virtual through the access of VR services offered\nby different providers. However, VR applications are computation- and\ncommunication-intensive. The VR service providers (SPs) have to optimize the VR\nservice delivery efficiently and economically given their limited communication\nand computation resources. An incentive mechanism can be thus applied as an\neffective tool for managing VR services between providers and users. Therefore,\nin this paper, we propose a learning-based Incentive Mechanism framework for VR\nservices in the Metaverse. First, we propose the quality of perception as the\nmetric for VR users immersing in the virtual world. Second, for quick trading\nof VR services between VR users (i.e., buyers) and VR SPs (i.e., sellers), we\ndesign a double Dutch auction mechanism to determine optimal pricing and\nallocation rules in this market. Third, for auction communication reduction, we\ndesign a deep reinforcement learning-based auctioneer to accelerate this\nauction process. Experimental results demonstrate that the proposed framework\ncan achieve near-optimal social welfare while reducing at least half of the\nauction information exchange cost than baseline methods.",
          "arxiv_id": "2111.03776v1"
        },
        {
          "title": "Guidelines for the Development of Immersive Virtual Reality Software for Cognitive Neuroscience and Neuropsychology: The Development of Virtual Reality Everyday Assessment Lab (VR-EAL)",
          "year": "2021-01",
          "abstract": "Virtual reality (VR) head-mounted displays (HMD) appear to be effective\nresearch tools, which may address the problem of ecological validity in\nneuropsychological testing. However, their widespread implementation is\nhindered by VR induced symptoms and effects (VRISE) and the lack of skills in\nVR software development. This study offers guidelines for the development of VR\nsoftware in cognitive neuroscience and neuropsychology, by describing and\ndiscussing the stages of the development of Virtual Reality Everyday Assessment\nLab (VR-EAL), the first neuropsychological battery in immersive VR. Techniques\nfor evaluating cognitive functions within a realistic storyline are discussed.\nThe utility of various assets in Unity, software development kits, and other\nsoftware are described so that cognitive scientists can overcome challenges\npertinent to VRISE and the quality of the VR software. In addition, this pilot\nstudy attempts to evaluate VR-EAL in accordance with the necessary criteria for\nVR software for research purposes. The VR neuroscience questionnaire (VRNQ;\nKourtesis et al., 2019b) was implemented to appraise the quality of the three\nversions of VR-EAL in terms of user experience, game mechanics, in-game\nassistance, and VRISE. Twenty-five participants aged between 20 and 45 years\nwith 12-16 years of full-time education evaluated various versions of VR-EAL.\nThe final version of VR-EAL achieved high scores in every sub-score of the VRNQ\nand exceeded its parsimonious cut-offs. It also appeared to have better in-game\nassistance and game mechanics, while its improved graphics substantially\nincreased the quality of the user experience and almost eradicated VRISE. The\nresults substantially support the feasibility of the development of effective\nVR research and clinical software without the presence of VRISE during a\n60-minute VR session.",
          "arxiv_id": "2101.08166v1"
        }
      ],
      "15": [
        {
          "title": "Intelligent Energy Management with IoT Framework in Smart Cities Using Intelligent Analysis: An Application of Machine Learning Methods for Complex Networks and Systems",
          "year": "2023-06",
          "abstract": "This study confronts the growing challenges of energy consumption and the\ndepletion of energy resources, particularly in the context of smart buildings.\nAs the demand for energy increases alongside the necessity for efficient\nbuilding maintenance, it becomes imperative to explore innovative energy\nmanagement solutions. We present a comprehensive review of Internet of Things\n(IoT)-based frameworks aimed at smart city energy management, highlighting the\npivotal role of IoT devices in addressing these issues due to their\ncompactness, sensing, measurement, and computing capabilities. Our review\nmethodology encompasses a thorough analysis of existing literature on IoT\narchitectures and frameworks for intelligent energy management applications. We\nfocus on systems that not only collect and store data but also support\nintelligent analysis for monitoring, controlling, and enhancing system\nefficiency. Additionally, we examine the potential for these frameworks to\nserve as platforms for the development of third-party applications, thereby\nextending their utility and adaptability. The findings from our review indicate\nthat IoT-based frameworks offer significant potential to reduce energy\nconsumption and environmental impact in smart buildings. Through the adoption\nof intelligent mechanisms and solutions, these frameworks facilitate effective\nenergy management, leading to improved system efficiency and sustainability.\nConsidering these findings, we recommend further exploration and adoption of\nIoT-based wireless sensing systems in smart buildings as a strategic approach\nto energy management. Our review underscores the importance of incorporating\nintelligent analysis and enabling the development of third-party applications\nwithin the IoT framework to efficiently meet the evolving energy demands and\nmaintenance challenges",
          "arxiv_id": "2306.05567v4"
        },
        {
          "title": "Energy personas in Danish households",
          "year": "2025-05",
          "abstract": "Technologies to monitor the provision of renewable energy are part of\nemerging technologies to help address the discrepancy between renewable energy\nproduction and its related usage in households. This paper presents various\nways householders use a technological artifact for the real-time monitoring of\nrenewable energy provision. Such a monitoring thus affords householders with an\nopportunity to adjust their energy consumption according to renewable energy\nprovision. In Denmark, Ewii, previously Barry, is a Danish energy supplier\nwhich provides householders with an opportunity to monitor energy sources in\nreal time through a technological solution of the same name. This paper use\nprovision afforded by Ewii as a case for exploring how householders organize\nthemselves to use a technological artefact that supports the monitoring of\nenergy and its related usage. This study aims to inform technology design\nthrough the derivation of four personas. The derived personas highlight the\ndifferences in energy monitoring practices for the householders and their\nengagement. These personas are characterised as dedicated, organised, sporadic,\nand convenient. Understanding these differences in energy monitoring practice\nusing the technological artefact form a solid element in the design of future\nenergy technologies that interfere with the everyday practices and energy\nconsumption for households. This is paramount for future energy related\ntechnology design, and for the clarification of usage assumptions that are\nembedded in the rollout of energy related technology as a country such as\nDenmark moves through its green transition.",
          "arxiv_id": "2505.07408v1"
        },
        {
          "title": "An Extensive and Methodical Review of Smart Grids for Sustainable Energy Management-Addressing Challenges with AI, Renewable Energy Integration and Leading-edge Technologies",
          "year": "2025-01",
          "abstract": "Energy management decreases energy expenditures and consumption while\nsimultaneously increasing energy efficiency, reducing carbon emissions, and\nenhancing operational performance. Smart grids are a type of sophisticated\nenergy infrastructure that increase the generation and distribution of\nelectricity's sustainability, dependability, and efficiency by utilizing\ndigital communication technologies. They combine a number of cutting-edge\ntechniques and technology to improve energy resource management. A large amount\nof research study on the topic of smart grids for energy management has been\ncompleted in the last several years. The authors of the present study want to\ncover a number of topics, including smart grid benefits and components,\ntechnical developments, integrating renewable energy sources, using artificial\nintelligence and data analytics, cybersecurity, and privacy. Smart Grids for\nEnergy Management are an innovative field of study aiming at tackling various\ndifficulties and magnifying the efficiency, dependability, and sustainability\nof energy systems, including: 1) Renewable sources of power like solar and wind\nare intermittent and unpredictable 2) Defending smart grid system from various\ncyber-attacks 3) Incorporating an increasing number of electric vehicles into\nthe system of power grid without overwhelming it. Additionally, it is proposed\nto use AI and data analytics for better performance on the grid, reliability,\nand energy management. It also looks into how AI and data analytics can be used\nto optimize grid performance, enhance reliability, and improve energy\nmanagement. The authors will explore these significant challenges and ongoing\nresearch. Lastly, significant issues in this field are noted, and\nrecommendations for further work are provided.",
          "arxiv_id": "2501.14143v1"
        }
      ],
      "16": [
        {
          "title": "How mass surveillance can crowd out installations of COVID-19 contact tracing apps",
          "year": "2021-10",
          "abstract": "During the COVID-19 pandemic, many countries have developed and deployed\ncontact tracing technologies to curb the spread of the disease by locating and\nisolating people who have been in contact with coronavirus carriers.\nSubsequently, understanding why people install and use contact tracing apps is\nbecoming central to their effectiveness and impact. This paper analyzes\nsituations where centralized mass surveillance technologies are deployed\nsimultaneously with a voluntary contact tracing mobile app. We use this\nparallel deployment as a natural experiment that tests how attitudes toward\nmass deployments affect people's installation of the contact tracing app. Based\non a representative survey of Israelis (n=519), our findings show that positive\nattitudes toward mass surveillance were related to a reduced likelihood of\ninstalling contact tracing apps and an increased likelihood of uninstalling\nthem. These results also hold when controlling for privacy concerns about the\ncontact tracing app, attitudes toward the app, trust in authorities, and\ndemographic properties. Similar reasoning may also be relevant for crowding out\nvoluntary participation in data collection systems.",
          "arxiv_id": "2110.01567v1"
        },
        {
          "title": "How Reliable is Smartphone-based Electronic Contact Tracing for COVID-19?",
          "year": "2020-05",
          "abstract": "Smartphone-based electronic contact tracing is currently considered an\nessential tool towards easing lockdowns, curfews, and shelter-in-place orders\nissued by most governments around the world in response to the 2020 novel\ncoronavirus (SARS-CoV-2) crisis. While the focus on developing smartphone-based\ncontact tracing applications or apps has been on privacy concerns stemming from\nthe use of such apps, an important question that has not received sufficient\nattention is: How reliable will such smartphone-based electronic contact\ntracing be?\n  This is a technical question related to how two smartphones reliably register\ntheir mutual proximity. Here, we examine in detail the technical prerequisites\nrequired for effective smartphone-based contact tracing. The underlying\nmechanism that any contact tracing app relies on is called Neighbor Discovery\n(ND), which involves smartphones transmitting and scanning for Bluetooth\nsignals to record their mutual presence whenever they are in close proximity.\nThe hardware support and the software protocols used for ND in smartphones,\nhowever, were not designed for reliable contact tracing. In this paper, we\nquantitatively evaluate how reliably can smartphones do contact tracing. Our\nresults point towards the design of a wearable solution for contact tracing\nthat can overcome the shortcomings of a smartphone-based solution to provide\nmore reliable and accurate contact tracing. To the best of our knowledge, this\nis the first study that quantifies, both, the suitability and also the\ndrawbacks of smartphone-based contact tracing. Further, our results can be used\nto parameterize a ND protocol to maximize the reliability of any contact\ntracing app that uses it.",
          "arxiv_id": "2005.05625v2"
        },
        {
          "title": "A Note on Cryptographic Algorithms for Private Data Analysis in Contact Tracing Applications",
          "year": "2020-05",
          "abstract": "Contact tracing is an important measure to counter the COVID-19 pandemic. In\nthe early phase, many countries employed manual contact tracing to contain the\nrate of disease spread, however it has many issues. The manual approach is\ncumbersome, time consuming and also requires active participation of a large\nnumber of people to realize it. In order to overcome these drawbacks, digital\ncontact tracing has been proposed that typically involves deploying a contact\ntracing application on people's mobile devices which can track their movements\nand close social interactions. While studies suggest that digital contact\ntracing is more effective than manual contact tracing, it has been observed\nthat higher adoption rates of the contact tracing app may result in a better\ncontrolled epidemic. This also increases the confidence in the accuracy of the\ncollected data and the subsequent analytics. One key reason for low adoption\nrate of contact tracing applications is the concern about individual privacy.\nIn fact, several studies report that contact tracing applications deployed in\nmultiple countries are not privacy friendly and have potential to be used for\nmass surveillance by the concerned governments. Hence, privacy respecting\ncontact tracing application is the need of the hour that can lead to highly\neffective, efficient contact tracing. As part of this study, we focus on\nvarious cryptographic techniques that can help in addressing the Private Set\nIntersection problem which lies at the heart of privacy respecting contact\ntracing. We analyze the computation and communication complexities of these\ntechniques under the typical client-server architecture utilized by contact\ntracing applications. Further we evaluate those computation and communication\ncomplexity expressions for India scenario and thus identify cryptographic\ntechniques that can be more suitably deployed there.",
          "arxiv_id": "2005.10634v1"
        }
      ],
      "17": [
        {
          "title": "Interdisciplinary research and technological impact: Evidence from biomedicine",
          "year": "2020-06",
          "abstract": "Interdisciplinary research (IDR) has been considered as an important source\nfor scientific breakthroughs and as a solution to today's complex societal\nchallenges. While ample empirical evidence has suggested its benefits within\nthe academia such as better creativity and higher scientific impact and\nvisibility, its societal benefits -- a key argument originally used for\npromoting IDR -- remain relatively unexplored. Here, we study one aspect of\nsocietal benefits, that is contributing to the development of patented\ntechnologies, and examine how IDR papers are referenced as \"prior art\" by\npatents over time. We draw on a large sample of biomedical papers published in\n23 years and measure the degree of interdisciplinarity of a paper using three\npopular indicators, namely variety, balance, and disparity. We find that papers\nthat cites more fields (variety) and whose distributions over those cited\nfields are more even (balance) are more likely to receive patent citations, but\nboth effects can be offset if papers draw upon more distant fields (disparity).\nThese associations are consistent across different citation-window lengths. We\nfurther find that conditional on receiving patent citations, the intensity of\ntheir technological impact, as measured as both raw and quality-adjusted number\nof citing patents, increases with balance and disparity. Our work may have\npolicy implications for interdisciplinary research and scientific and\ntechnological impact.",
          "arxiv_id": "2006.15383v3"
        },
        {
          "title": "Diversity of Expertise is Key to Scientific Impact: a Large-Scale Analysis in the Field of Computer Science",
          "year": "2023-06",
          "abstract": "Understanding the relationship between the composition of a research team and\nthe potential impact of their research papers is crucial as it can steer the\ndevelopment of new science policies for improving the research enterprise.\nNumerous studies assess how the characteristics and diversity of research teams\ncan influence their performance across several dimensions: ethnicity,\ninternationality, size, and others. In this paper, we explore the impact of\ndiversity in terms of the authors' expertise. To this purpose, we retrieved\n114K papers in the field of Computer Science and analysed how the diversity of\nresearch fields within a research team relates to the number of citations their\npapers received in the upcoming 5 years. The results show that two different\nmetrics we defined, reflecting the diversity of expertise, are significantly\nassociated with the number of citations. This suggests that, at least in\nComputer Science, diversity of expertise is key to scientific impact.",
          "arxiv_id": "2306.15344v2"
        },
        {
          "title": "Effects of Research Paper Promotion via ArXiv and X",
          "year": "2024-01",
          "abstract": "In the evolving landscape of scientific publishing, it is important to\nunderstand the drivers of high-impact research, to equip scientists with\nactionable strategies to enhance the reach of their work, and to understand\ntrends in the use of modern scientific publishing tools to inform their further\ndevelopment. Here, we study trends in the use of early preprint publications\nand revisions on ArXiv and the use of X (formerly Twitter) for promotion of\nsuch papers in computer science and physics. We find that early submissions to\nArXiv and promotion on X have soared in recent years. Estimating the effect\nthat the use of each of these modern affordances has on the number of citations\nof scientific publications, we find that peer-reviewed conference papers in\ncomputer science that are submitted early to ArXiv gain on average $21.1 \\pm\n17.4$ more citations, revised on ArXiv gain $18.4 \\pm 17.6$ more citations, and\npromoted on X gain $44.4 \\pm 8$ more citations in the first 5 years from an\ninitial publication. In contrast, journal articles in physics experience\ncomparatively lower boosts in citation counts, with increases of $3.9 \\pm 1.1$,\n$4.3 \\pm 0.9$, and $6.9 \\pm 3.5$ citations respectively for the same\ninterventions. Our results show that promoting one's work on ArXiv or X has a\nlarge impact on the number of citations, as well as the number of influential\ncitations computed by Semantic Scholar, and thereby on the career of\nresearchers. These effects are present also for publications in physics, but\nthey are relatively smaller. The larger relative effect sizes, effects of\npromotion accumulating over time, and elevated unpredictability of the number\nof citations in computer science than in physics suggest a greater role of\nworld-of-mouth spreading in computer science than in physics.",
          "arxiv_id": "2401.11116v2"
        }
      ],
      "18": [
        {
          "title": "Usable XAI: 10 Strategies Towards Exploiting Explainability in the LLM Era",
          "year": "2024-03",
          "abstract": "Explainable AI (XAI) refers to techniques that provide human-understandable\ninsights into the workings of AI models. Recently, the focus of XAI is being\nextended toward explaining Large Language Models (LLMs). This extension calls\nfor a significant transformation in the XAI methodologies for two reasons.\nFirst, many existing XAI methods cannot be directly applied to LLMs due to\ntheir complexity and advanced capabilities. Second, as LLMs are increasingly\ndeployed in diverse applications, the role of XAI shifts from merely opening\nthe ``black box'' to actively enhancing the productivity and applicability of\nLLMs in real-world settings. Meanwhile, the conversation and generation\nabilities of LLMs can reciprocally enhance XAI. Therefore, in this paper, we\nintroduce Usable XAI in the context of LLMs by analyzing (1) how XAI can\nexplain and improve LLM-based AI systems and (2) how XAI techniques can be\nimproved by using LLMs. We introduce 10 strategies, introducing the key\ntechniques for each and discussing their associated challenges. We also provide\ncase studies to demonstrate how to obtain and leverage explanations. The code\nused in this paper can be found at:\nhttps://github.com/JacksonWuxs/UsableXAI_LLM.",
          "arxiv_id": "2403.08946v2"
        },
        {
          "title": "Explainable Artificial Intelligence: A Survey of Needs, Techniques, Applications, and Future Direction",
          "year": "2024-08",
          "abstract": "Artificial intelligence models encounter significant challenges due to their\nblack-box nature, particularly in safety-critical domains such as healthcare,\nfinance, and autonomous vehicles. Explainable Artificial Intelligence (XAI)\naddresses these challenges by providing explanations for how these models make\ndecisions and predictions, ensuring transparency, accountability, and fairness.\nExisting studies have examined the fundamental concepts of XAI, its general\nprinciples, and the scope of XAI techniques. However, there remains a gap in\nthe literature as there are no comprehensive reviews that delve into the\ndetailed mathematical representations, design methodologies of XAI models, and\nother associated aspects. This paper provides a comprehensive literature review\nencompassing common terminologies and definitions, the need for XAI,\nbeneficiaries of XAI, a taxonomy of XAI methods, and the application of XAI\nmethods in different application areas. The survey is aimed at XAI researchers,\nXAI practitioners, AI model developers, and XAI beneficiaries who are\ninterested in enhancing the trustworthiness, transparency, accountability, and\nfairness of their AI models.",
          "arxiv_id": "2409.00265v2"
        },
        {
          "title": "\"Help Me Help the AI\": Understanding How Explainability Can Support Human-AI Interaction",
          "year": "2022-10",
          "abstract": "Despite the proliferation of explainable AI (XAI) methods, little is\nunderstood about end-users' explainability needs and behaviors around XAI\nexplanations. To address this gap and contribute to understanding how\nexplainability can support human-AI interaction, we conducted a mixed-methods\nstudy with 20 end-users of a real-world AI application, the Merlin bird\nidentification app, and inquired about their XAI needs, uses, and perceptions.\nWe found that participants desire practically useful information that can\nimprove their collaboration with the AI, more so than technical system details.\nRelatedly, participants intended to use XAI explanations for various purposes\nbeyond understanding the AI's outputs: calibrating trust, improving their task\nskills, changing their behavior to supply better inputs to the AI, and giving\nconstructive feedback to developers. Finally, among existing XAI approaches,\nparticipants preferred part-based explanations that resemble human reasoning\nand explanations. We discuss the implications of our findings and provide\nrecommendations for future XAI design.",
          "arxiv_id": "2210.03735v2"
        }
      ]
    }
  },
  "metadata": {
    "lastUpdated": "2025-09-25T18:54:06Z",
    "dataVersion": "0.0.2",
    "period": {
      "start": "2020-01",
      "end": "2025-09"
    }
  }
}